{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"toc_visible":true,"machine_shape":"hm","mount_file_id":"1w6ywhJgqz_PxWrg3UQwRmx6hRJvOkBnb","authorship_tag":"ABX9TyMXzYyo+ZWqU2AVhqHDrrqG"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","gpuClass":"premium"},"cells":[{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"plWc5S-d__Gi","executionInfo":{"status":"ok","timestamp":1678961047866,"user_tz":-540,"elapsed":10243,"user":{"displayName":"HaJun Yoo","userId":"01231542744346053879"}},"outputId":"00d93f49-9b06-4b6d-ae3d-9bd4a06f2a99"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"code","source":["# !mkdir /content/drive/MyDrive/졸플/Audio/data/spectrogram_fixed\n","# !cd /content/drive/MyDrive/졸플/Audio/data/spectrogram_fixed\n","# !unzip -qq -o /content/drive/MyDrive/졸플/Audio/data/spectrogram_fixed.zip"],"metadata":{"id":"q6RVKT8yAS0o","executionInfo":{"status":"ok","timestamp":1678961047866,"user_tz":-540,"elapsed":5,"user":{"displayName":"HaJun Yoo","userId":"01231542744346053879"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","import itertools\n","from PIL import Image, ImageFile\n","\n","import os\n","import numpy as np\n","import torch\n","import torchvision.transforms as transforms\n","from torch.utils.data import Dataset, DataLoader\n","from PIL import Image\n","\n","import torch.nn as nn\n","import torch.nn.functional as F\n","from copy import deepcopy\n","\n","plt.style.use('seaborn-white')"],"metadata":{"id":"F1_BYEloB0kj","executionInfo":{"status":"ok","timestamp":1678961051495,"user_tz":-540,"elapsed":3633,"user":{"displayName":"HaJun Yoo","userId":"01231542744346053879"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["device = 'cuda' if torch.cuda.is_available() else 'cpu'\n","torch.manual_seed(1)\n","if device == 'cuda':\n","    torch.cuda.manual_seed_all(1)\n","print (device)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DAKsFxuNYXYk","executionInfo":{"status":"ok","timestamp":1678961051496,"user_tz":-540,"elapsed":14,"user":{"displayName":"HaJun Yoo","userId":"01231542744346053879"}},"outputId":"f67dc471-527a-4396-b67d-15502ad7b525"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["cuda\n"]}]},{"cell_type":"markdown","source":["### Dataset, Dataloader"],"metadata":{"id":"S0XbNyPg7Jvb"}},{"cell_type":"code","execution_count":5,"metadata":{"id":"cE7GjH9p8quN","executionInfo":{"status":"ok","timestamp":1678961167732,"user_tz":-540,"elapsed":111326,"user":{"displayName":"HaJun Yoo","userId":"01231542744346053879"}}},"outputs":[],"source":["class AudioDataset(Dataset):\n","    def __init__(self, data_dir, label_names, transform=None):\n","        self.data_dir = data_dir\n","        self.label_names = label_names\n","        self.transform = transform\n","        self.data = []\n","        self.labels = []\n","        for i, label in enumerate(self.label_names):\n","            path = os.path.join(self.data_dir, label)\n","            for img_file in os.listdir(path):\n","                img_path = os.path.join(path, img_file)\n","                img = Image.open(img_path)\n","                if self.transform:\n","                    img = self.transform(img)\n","                self.data.append(img)\n","                self.labels.append(i)\n","\n","    def __len__(self):\n","        return len(self.labels)\n","\n","    def __getitem__(self, idx):\n","        sample = self.data[idx]\n","        label = self.labels[idx]\n","        return sample, label\n","\n","# Set the input shape\n","input_shape = (128, 128)\n","\n","# Define the number of classes\n","num_classes = 6\n","\n","# Define the path to the directory containing the spectrogram images\n","data_dir = '/content/drive/MyDrive/졸플/Audio/output_128/spectrogram_fixed'\n","\n","# Define a list of the label names\n","label_names = ['regular', 'help', 'robbery', 'sexual', 'theft', 'violence']\n","\n","# Define the batch size for training and validation\n","batch_size = 32\n","\n","# Define the data transformations\n","transform = transforms.Compose([\n","    transforms.Resize(input_shape),\n","    transforms.ToTensor(),\n","    transforms.Normalize(mean=[0.5], std=[0.5])\n","])\n","\n","# Create the datasets\n","train_dataset = AudioDataset(os.path.join(data_dir), label_names, transform=transform)\n","val_dataset = AudioDataset(os.path.join(data_dir), label_names, transform=transform)\n","\n","# Split the datasets into training and validation sets\n","train_size = int(len(train_dataset) * 0.8)\n","val_size = len(train_dataset) - train_size\n","train_dataset, val_dataset = torch.utils.data.random_split(train_dataset, [train_size, val_size])\n","\n","# Create the data loaders\n","train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n","val_loader = DataLoader(val_dataset, batch_size=batch_size)"]},{"cell_type":"code","source":["print (len(train_dataset), len(val_dataset))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"i0mZoCzjBi7l","executionInfo":{"status":"ok","timestamp":1678961167732,"user_tz":-540,"elapsed":12,"user":{"displayName":"HaJun Yoo","userId":"01231542744346053879"}},"outputId":"0f2689d9-a5f8-4f5c-d485-36b4743cc778"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["6436 1610\n"]}]},{"cell_type":"code","source":["for x, y in train_loader:\n","    print(x.shape)\n","    break"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yCFhZ5kvUGlp","executionInfo":{"status":"ok","timestamp":1678961167733,"user_tz":-540,"elapsed":11,"user":{"displayName":"HaJun Yoo","userId":"01231542744346053879"}},"outputId":"45643e46-20a6-4843-8a49-d6b46f4f9fa8"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["torch.Size([32, 4, 128, 128])\n"]}]},{"cell_type":"code","source":["class CNNModel(nn.Module):\n","    def __init__(self):\n","        super(CNNModel, self).__init__()\n","        self.conv1 = nn.Conv2d(4, 32, kernel_size=3, stride=1, padding=1)\n","        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1)\n","        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1)\n","        self.pool = nn.MaxPool2d(2, 2)\n","        self.fc1 = nn.Linear(128 * 16 * 16, 512)\n","        self.fc2 = nn.Linear(512, 6)\n","        self.dropout = nn.Dropout(0.25)\n","\n","    def forward(self, x):\n","        x = self.pool(F.leaky_relu(self.conv1(x)))\n","        x = self.pool(F.leaky_relu(self.conv2(x)))\n","        x = self.pool(F.leaky_relu(self.conv3(x)))\n","        x = x.view(-1, 128 * 16 * 16)\n","        x = self.dropout(x)\n","        x = F.leaky_relu(self.fc1(x))\n","        x = self.dropout(x)\n","        x = self.fc2(x)\n","        return x"],"metadata":{"id":"5Z5NqXZrPWet","executionInfo":{"status":"ok","timestamp":1678953132521,"user_tz":-540,"elapsed":3,"user":{"displayName":"HaJun Yoo","userId":"01231542744346053879"}}},"execution_count":13,"outputs":[]},{"cell_type":"markdown","source":["### resnet"],"metadata":{"id":"gag5eSwR7G6j"}},{"cell_type":"code","source":["import torch.nn as nn\n","import torch.nn.functional as F\n","from torchvision.models.resnet import ResNet, BasicBlock\n","\n","class ResNetModel(ResNet):\n","    def __init__(self, num_classes=6):\n","        super(ResNetModel, self).__init__(BasicBlock, [2, 2, 2, 2], num_classes=num_classes)\n","        self.conv1 = nn.Conv2d(4, 64, kernel_size=7, stride=2, padding=3, bias=False)\n","\n","    def forward(self, x):\n","        x = self.conv1(x)\n","        x = self.bn1(x)\n","        x = self.relu(x)\n","        x = self.maxpool(x)\n","\n","        x = self.layer1(x)\n","        x = self.layer2(x)\n","        x = self.layer3(x)\n","        x = self.layer4(x)\n","\n","        x = self.avgpool(x)\n","        x = x.view(x.size(0), -1)\n","        x = self.fc(x)\n","        return x\n","\n","\n","'''\n","이것은 4채널 입력을 받아들여 지정된 수의 클래스를 출력하는 torchvision.models의 ResNet18 아키텍처의 수정된 버전입니다. \n","우리는 입력 크기와 일치하도록 첫 번째 컨볼루션 레이어의 입력 채널을 4로 변경하고, \n","완전히 연결된 레이어를 원하는 클래스 수를 출력하는 것으로 대체한다는 것에 주목한다.\n","'''"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":71},"id":"boQ82a8akNO1","executionInfo":{"status":"ok","timestamp":1678961167733,"user_tz":-540,"elapsed":8,"user":{"displayName":"HaJun Yoo","userId":"01231542744346053879"}},"outputId":"dc0023fc-5fc6-44a9-d221-aba7a0af4a5f"},"execution_count":8,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'\\n이것은 4채널 입력을 받아들여 지정된 수의 클래스를 출력하는 torchvision.models의 ResNet18 아키텍처의 수정된 버전입니다. \\n우리는 입력 크기와 일치하도록 첫 번째 컨볼루션 레이어의 입력 채널을 4로 변경하고, \\n완전히 연결된 레이어를 원하는 클래스 수를 출력하는 것으로 대체한다는 것에 주목한다.\\n'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":8}]},{"cell_type":"code","source":["class DeepCNNModel(nn.Module):\n","    def __init__(self):\n","        super(DeepCNNModel, self).__init__()\n","        self.conv1 = nn.Conv2d(4, 32, kernel_size=3, stride=1, padding=1)\n","        self.bn1 = nn.BatchNorm2d(32)\n","        self.conv2 = nn.Conv2d(32, 32, kernel_size=3, stride=1, padding=1)\n","        self.bn2 = nn.BatchNorm2d(32)\n","        self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2)\n","        self.dropout1 = nn.Dropout2d(0.25)\n","        \n","        self.conv3 = nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1)\n","        self.bn3 = nn.BatchNorm2d(64)\n","        self.conv4 = nn.Conv2d(64, 64, kernel_size=3, stride=1, padding=1)\n","        self.bn4 = nn.BatchNorm2d(64)\n","        self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2)\n","        self.dropout2 = nn.Dropout2d(0.25)\n","        \n","        self.conv5 = nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1)\n","        self.bn5 = nn.BatchNorm2d(128)\n","        self.conv6 = nn.Conv2d(128, 128, kernel_size=3, stride=1, padding=1)\n","        self.bn6 = nn.BatchNorm2d(128)\n","        self.pool3 = nn.MaxPool2d(kernel_size=2, stride=2)\n","        self.dropout3 = nn.Dropout2d(0.25)\n","        \n","        self.fc1 = nn.Linear(128 * 16 * 16, 512)\n","        self.dropout4 = nn.Dropout(0.5)\n","        self.fc2 = nn.Linear(512, 6)\n","\n","    def forward(self, x):\n","        x = self.conv1(x)\n","        x = self.bn1(x)\n","        x = F.relu(x)\n","        x = self.conv2(x)\n","        x = self.bn2(x)\n","        x = F.relu(x)\n","        x = self.pool1(x)\n","        x = self.dropout1(x)\n","        \n","        x = self.conv3(x)\n","        x = self.bn3(x)\n","        x = F.relu(x)\n","        x = self.conv4(x)\n","        x = self.bn4(x)\n","        x = F.relu(x)\n","        x = self.pool2(x)\n","        x = self.dropout2(x)\n","        \n","        x = self.conv5(x)\n","        x = self.bn5(x)\n","        x = F.relu(x)\n","        x = self.conv6(x)\n","        x = self.bn6(x)\n","        x = F.relu(x)\n","        x = self.pool3(x)\n","        x = self.dropout3(x)\n","        \n","        x = x.view(-1, 128 * 16 * 16)\n","        x = self.fc1(x)\n","        x = F.relu(x)\n","        x = self.dropout4(x)\n","        x = self.fc2(x)\n","        return x"],"metadata":{"id":"x39BkmXcljsG","executionInfo":{"status":"ok","timestamp":1678956697959,"user_tz":-540,"elapsed":1,"user":{"displayName":"HaJun Yoo","userId":"01231542744346053879"}}},"execution_count":54,"outputs":[]},{"cell_type":"markdown","source":["  \"\"\"\n","    Train a CNN model using the given train and validation data loaders.\n","\n","    Args:\n","        model: CNN model to train.\n","        train_loader: Data loader for training data.\n","        val_loader: Data loader for validation data.\n","        loss_func: Loss function to use.\n","        optimizer: Optimizer to use for training.\n","        n_epochs: Number of epochs to train for.\n","        device: Device to use for training (e.g. 'cpu', 'cuda').\n","        early_stop: Number of epochs of no improvement in validation loss to stop training early. If None, do not perform early stopping.\n","        verbose: If True, print loss and accuracy metrics during training.\n","\n","    Returns:\n","        trained_model: The trained model.\n","        best_params: The best hyperparameters found during training.\n","        train_losses: List of training losses per epoch.\n","        val_losses: List of validation losses per epoch.\n","        train_accuracies: List of training accuracies per epoch.\n","        val_accuracies: List of validation accuracies per epoch.\n","    \"\"\""],"metadata":{"id":"b3Yw6x-vW0XB"}},{"cell_type":"code","source":["def accuracy(y_pred, y_true):\n","  pred_labels = torch.argmax(y_pred, dim=1)\n","  correct = pred_labels.eq(y_true).sum().item()\n","  return correct / len(y_true)"],"metadata":{"id":"9xOzHNBPbYKb","executionInfo":{"status":"ok","timestamp":1678961167733,"user_tz":-540,"elapsed":6,"user":{"displayName":"HaJun Yoo","userId":"01231542744346053879"}}},"execution_count":9,"outputs":[]},{"cell_type":"code","source":["def train_model(model, train_loader, val_loader, optimizer, loss_func, early_stop, n_epochs, progress_interval, device):\n","\n","    train_losses, valid_losses, train_accs, valid_accs, lowest_loss = list(), list(), list(), list(), np.inf\n","\n","    # Move the model to the GPU\n","    model = model.to(device)\n","    # Move the loss function to the GPU\n","    criterion = loss_func.to(device)\n","\n","    for epoch in range(n_epochs):\n","        \n","        train_loss, valid_loss, train_acc, valid_acc = 0, 0, 0, 0\n","        \n","        # train the model\n","        model.train() # prep model for training\n","        for i, (x_minibatch, y_minibatch) in enumerate(train_loader):\n","            x_minibatch = x_minibatch.to(device)\n","            y_minibatch = y_minibatch.to(device)\n","            y_minibatch_pred = model(x_minibatch)\n","            loss = criterion(y_minibatch_pred, y_minibatch)\n","\n","            optimizer.zero_grad()\n","            loss.backward()\n","            optimizer.step()\n","            train_loss += loss.item()\n","            train_acc += accuracy(y_minibatch_pred, y_minibatch)\n","            \n","            # print progress every 10 batches\n","            if (i+1) % 10 == 0:\n","                print(f\"Epoch [{epoch+1}/{n_epochs}], Step [{i+1}/{len(train_loader)}], Train Loss: {train_loss/(i+1):.4f}, Train Acc: {train_acc/(i+1)*100:.2f}%\")\n","        \n","        train_loss = train_loss / len(train_loader)\n","        train_losses.append(train_loss)\n","        train_acc = train_acc / len(train_loader)\n","        train_accs.append(train_acc)   \n","        \n","        # validate the model\n","        model.eval()\n","        with torch.no_grad():\n","            for x_minibatch, y_minibatch in val_loader:\n","                x_minibatch = x_minibatch.to(device)\n","                y_minibatch = y_minibatch.to(device)\n","                y_minibatch_pred = model(x_minibatch)\n","                loss = criterion(y_minibatch_pred, y_minibatch)\n","                valid_loss += loss.item()\n","                valid_acc += accuracy(y_minibatch_pred, y_minibatch)\n","                \n","        valid_loss = valid_loss / len(val_loader)\n","        valid_losses.append(valid_loss)\n","        valid_acc = valid_acc / len(val_loader)\n","        valid_accs.append(valid_acc)\n","\n","        if valid_losses[-1] < lowest_loss:\n","            lowest_loss = valid_losses[-1]\n","            lowest_epoch = epoch\n","            best_model = deepcopy(model.state_dict())\n","        else:\n","            if early_stop > 0 and lowest_epoch + early_stop < epoch:\n","                print (\"Early Stopped\", epoch, \"epochs\")\n","                model.load_state_dict(best_model)\n","                break\n","                \n","        if (epoch % progress_interval) == 0:\n","            print (f\"Epoch [{epoch+1}/{n_epochs}], Train Loss: {train_losses[-1]:.4f}, Train Acc: {train_accs[-1]*100:.2f}%, Val Loss: {valid_losses[-1]:.4f}, Val Acc: {valid_accs[-1]*100:.2f}%\")\n","            \n","            \n","    model.load_state_dict(best_model)        \n","    return model, lowest_loss, train_losses, valid_losses, train_accs, valid_accs"],"metadata":{"id":"0u7_E_TbUvp0","executionInfo":{"status":"ok","timestamp":1678961167733,"user_tz":-540,"elapsed":6,"user":{"displayName":"HaJun Yoo","userId":"01231542744346053879"}}},"execution_count":10,"outputs":[]},{"cell_type":"code","source":["import torch.optim as optim\n","\n","model = ResNetModel()\n","# Define the loss function and optimizer\n","optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n","loss_func = nn.CrossEntropyLoss()\n","\n","# Train the model\n","n_epochs = 30\n","early_stop = 20\n","progress_interval = 1\n","\n","\n","trained_model, lowest_loss, train_losses, valid_losses, train_accs, valid_accs = train_model(model, train_loader, val_loader, optimizer, loss_func, early_stop, n_epochs, progress_interval, device)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cyNJSnEYTVHX","executionInfo":{"status":"ok","timestamp":1678961317756,"user_tz":-540,"elapsed":150029,"user":{"displayName":"HaJun Yoo","userId":"01231542744346053879"}},"outputId":"f3146dc7-6da4-40cd-8628-b2e43a694e5e"},"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch [1/30], Step [10/202], Train Loss: 1.6446, Train Acc: 35.94%\n","Epoch [1/30], Step [20/202], Train Loss: 1.4658, Train Acc: 42.34%\n","Epoch [1/30], Step [30/202], Train Loss: 1.4118, Train Acc: 44.27%\n","Epoch [1/30], Step [40/202], Train Loss: 1.3337, Train Acc: 47.89%\n","Epoch [1/30], Step [50/202], Train Loss: 1.2708, Train Acc: 50.69%\n","Epoch [1/30], Step [60/202], Train Loss: 1.2246, Train Acc: 52.97%\n","Epoch [1/30], Step [70/202], Train Loss: 1.2005, Train Acc: 54.29%\n","Epoch [1/30], Step [80/202], Train Loss: 1.1802, Train Acc: 54.77%\n","Epoch [1/30], Step [90/202], Train Loss: 1.1404, Train Acc: 56.46%\n","Epoch [1/30], Step [100/202], Train Loss: 1.1184, Train Acc: 57.28%\n","Epoch [1/30], Step [110/202], Train Loss: 1.1012, Train Acc: 58.41%\n","Epoch [1/30], Step [120/202], Train Loss: 1.0854, Train Acc: 58.98%\n","Epoch [1/30], Step [130/202], Train Loss: 1.0568, Train Acc: 60.05%\n","Epoch [1/30], Step [140/202], Train Loss: 1.0408, Train Acc: 60.74%\n","Epoch [1/30], Step [150/202], Train Loss: 1.0219, Train Acc: 61.46%\n","Epoch [1/30], Step [160/202], Train Loss: 1.0025, Train Acc: 62.21%\n","Epoch [1/30], Step [170/202], Train Loss: 0.9847, Train Acc: 62.81%\n","Epoch [1/30], Step [180/202], Train Loss: 0.9713, Train Acc: 63.45%\n","Epoch [1/30], Step [190/202], Train Loss: 0.9520, Train Acc: 64.06%\n","Epoch [1/30], Step [200/202], Train Loss: 0.9324, Train Acc: 64.70%\n","Epoch [1/30], Train Loss: 0.9296, Train Acc: 64.73%, Val Loss: 0.8725, Val Acc: 67.90%\n","Epoch [2/30], Step [10/202], Train Loss: 0.7767, Train Acc: 68.44%\n","Epoch [2/30], Step [20/202], Train Loss: 0.7180, Train Acc: 72.34%\n","Epoch [2/30], Step [30/202], Train Loss: 0.6892, Train Acc: 74.27%\n","Epoch [2/30], Step [40/202], Train Loss: 0.6657, Train Acc: 75.39%\n","Epoch [2/30], Step [50/202], Train Loss: 0.6531, Train Acc: 75.69%\n","Epoch [2/30], Step [60/202], Train Loss: 0.6332, Train Acc: 76.93%\n","Epoch [2/30], Step [70/202], Train Loss: 0.6187, Train Acc: 77.81%\n","Epoch [2/30], Step [80/202], Train Loss: 0.6044, Train Acc: 78.48%\n","Epoch [2/30], Step [90/202], Train Loss: 0.6028, Train Acc: 78.47%\n","Epoch [2/30], Step [100/202], Train Loss: 0.5910, Train Acc: 78.75%\n","Epoch [2/30], Step [110/202], Train Loss: 0.5823, Train Acc: 79.29%\n","Epoch [2/30], Step [120/202], Train Loss: 0.5808, Train Acc: 79.43%\n","Epoch [2/30], Step [130/202], Train Loss: 0.5723, Train Acc: 79.66%\n","Epoch [2/30], Step [140/202], Train Loss: 0.5647, Train Acc: 79.87%\n","Epoch [2/30], Step [150/202], Train Loss: 0.5666, Train Acc: 79.90%\n","Epoch [2/30], Step [160/202], Train Loss: 0.5618, Train Acc: 80.08%\n","Epoch [2/30], Step [170/202], Train Loss: 0.5644, Train Acc: 80.02%\n","Epoch [2/30], Step [180/202], Train Loss: 0.5622, Train Acc: 80.14%\n","Epoch [2/30], Step [190/202], Train Loss: 0.5587, Train Acc: 80.28%\n","Epoch [2/30], Step [200/202], Train Loss: 0.5507, Train Acc: 80.56%\n","Epoch [2/30], Train Loss: 0.5491, Train Acc: 80.57%, Val Loss: 0.5443, Val Acc: 77.99%\n","Epoch [3/30], Step [10/202], Train Loss: 0.4031, Train Acc: 86.88%\n","Epoch [3/30], Step [20/202], Train Loss: 0.3592, Train Acc: 87.97%\n","Epoch [3/30], Step [30/202], Train Loss: 0.3602, Train Acc: 87.81%\n","Epoch [3/30], Step [40/202], Train Loss: 0.3585, Train Acc: 87.27%\n","Epoch [3/30], Step [50/202], Train Loss: 0.3566, Train Acc: 87.62%\n","Epoch [3/30], Step [60/202], Train Loss: 0.3517, Train Acc: 87.81%\n","Epoch [3/30], Step [70/202], Train Loss: 0.3560, Train Acc: 87.86%\n","Epoch [3/30], Step [80/202], Train Loss: 0.3583, Train Acc: 87.62%\n","Epoch [3/30], Step [90/202], Train Loss: 0.3601, Train Acc: 87.71%\n","Epoch [3/30], Step [100/202], Train Loss: 0.3703, Train Acc: 87.28%\n","Epoch [3/30], Step [110/202], Train Loss: 0.3748, Train Acc: 86.96%\n","Epoch [3/30], Step [120/202], Train Loss: 0.3724, Train Acc: 86.88%\n","Epoch [3/30], Step [130/202], Train Loss: 0.3697, Train Acc: 87.02%\n","Epoch [3/30], Step [140/202], Train Loss: 0.3669, Train Acc: 87.14%\n","Epoch [3/30], Step [150/202], Train Loss: 0.3600, Train Acc: 87.35%\n","Epoch [3/30], Step [160/202], Train Loss: 0.3572, Train Acc: 87.38%\n","Epoch [3/30], Step [170/202], Train Loss: 0.3548, Train Acc: 87.43%\n","Epoch [3/30], Step [180/202], Train Loss: 0.3525, Train Acc: 87.43%\n","Epoch [3/30], Step [190/202], Train Loss: 0.3553, Train Acc: 87.40%\n","Epoch [3/30], Step [200/202], Train Loss: 0.3555, Train Acc: 87.44%\n","Epoch [3/30], Train Loss: 0.3568, Train Acc: 87.41%, Val Loss: 0.3532, Val Acc: 87.56%\n","Epoch [4/30], Step [10/202], Train Loss: 0.2968, Train Acc: 91.25%\n","Epoch [4/30], Step [20/202], Train Loss: 0.3077, Train Acc: 90.00%\n","Epoch [4/30], Step [30/202], Train Loss: 0.2932, Train Acc: 90.21%\n","Epoch [4/30], Step [40/202], Train Loss: 0.2804, Train Acc: 90.39%\n","Epoch [4/30], Step [50/202], Train Loss: 0.2805, Train Acc: 90.06%\n","Epoch [4/30], Step [60/202], Train Loss: 0.2701, Train Acc: 90.26%\n","Epoch [4/30], Step [70/202], Train Loss: 0.2594, Train Acc: 90.71%\n","Epoch [4/30], Step [80/202], Train Loss: 0.2591, Train Acc: 90.70%\n","Epoch [4/30], Step [90/202], Train Loss: 0.2519, Train Acc: 90.90%\n","Epoch [4/30], Step [100/202], Train Loss: 0.2548, Train Acc: 90.78%\n","Epoch [4/30], Step [110/202], Train Loss: 0.2483, Train Acc: 90.99%\n","Epoch [4/30], Step [120/202], Train Loss: 0.2420, Train Acc: 91.22%\n","Epoch [4/30], Step [130/202], Train Loss: 0.2393, Train Acc: 91.32%\n","Epoch [4/30], Step [140/202], Train Loss: 0.2380, Train Acc: 91.38%\n","Epoch [4/30], Step [150/202], Train Loss: 0.2397, Train Acc: 91.38%\n","Epoch [4/30], Step [160/202], Train Loss: 0.2375, Train Acc: 91.41%\n","Epoch [4/30], Step [170/202], Train Loss: 0.2389, Train Acc: 91.25%\n","Epoch [4/30], Step [180/202], Train Loss: 0.2388, Train Acc: 91.30%\n","Epoch [4/30], Step [190/202], Train Loss: 0.2382, Train Acc: 91.35%\n","Epoch [4/30], Step [200/202], Train Loss: 0.2373, Train Acc: 91.38%\n","Epoch [4/30], Train Loss: 0.2370, Train Acc: 91.43%, Val Loss: 0.6071, Val Acc: 81.79%\n","Epoch [5/30], Step [10/202], Train Loss: 0.2270, Train Acc: 92.81%\n","Epoch [5/30], Step [20/202], Train Loss: 0.2230, Train Acc: 92.50%\n","Epoch [5/30], Step [30/202], Train Loss: 0.2118, Train Acc: 92.60%\n","Epoch [5/30], Step [40/202], Train Loss: 0.2113, Train Acc: 92.34%\n","Epoch [5/30], Step [50/202], Train Loss: 0.1986, Train Acc: 92.88%\n","Epoch [5/30], Step [60/202], Train Loss: 0.1880, Train Acc: 93.49%\n","Epoch [5/30], Step [70/202], Train Loss: 0.1831, Train Acc: 93.79%\n","Epoch [5/30], Step [80/202], Train Loss: 0.1807, Train Acc: 94.02%\n","Epoch [5/30], Step [90/202], Train Loss: 0.1827, Train Acc: 93.96%\n","Epoch [5/30], Step [100/202], Train Loss: 0.1873, Train Acc: 93.78%\n","Epoch [5/30], Step [110/202], Train Loss: 0.1865, Train Acc: 93.66%\n","Epoch [5/30], Step [120/202], Train Loss: 0.1820, Train Acc: 93.80%\n","Epoch [5/30], Step [130/202], Train Loss: 0.1790, Train Acc: 93.85%\n","Epoch [5/30], Step [140/202], Train Loss: 0.1749, Train Acc: 94.00%\n","Epoch [5/30], Step [150/202], Train Loss: 0.1727, Train Acc: 94.06%\n","Epoch [5/30], Step [160/202], Train Loss: 0.1694, Train Acc: 94.16%\n","Epoch [5/30], Step [170/202], Train Loss: 0.1672, Train Acc: 94.23%\n","Epoch [5/30], Step [180/202], Train Loss: 0.1667, Train Acc: 94.27%\n","Epoch [5/30], Step [190/202], Train Loss: 0.1660, Train Acc: 94.29%\n","Epoch [5/30], Step [200/202], Train Loss: 0.1648, Train Acc: 94.36%\n","Epoch [5/30], Train Loss: 0.1648, Train Acc: 94.26%, Val Loss: 0.2460, Val Acc: 92.03%\n","Epoch [6/30], Step [10/202], Train Loss: 0.2455, Train Acc: 91.88%\n","Epoch [6/30], Step [20/202], Train Loss: 0.2129, Train Acc: 92.50%\n","Epoch [6/30], Step [30/202], Train Loss: 0.1836, Train Acc: 93.65%\n","Epoch [6/30], Step [40/202], Train Loss: 0.1661, Train Acc: 94.14%\n","Epoch [6/30], Step [50/202], Train Loss: 0.1657, Train Acc: 94.19%\n","Epoch [6/30], Step [60/202], Train Loss: 0.1583, Train Acc: 94.43%\n","Epoch [6/30], Step [70/202], Train Loss: 0.1663, Train Acc: 94.20%\n","Epoch [6/30], Step [80/202], Train Loss: 0.1640, Train Acc: 94.30%\n","Epoch [6/30], Step [90/202], Train Loss: 0.1592, Train Acc: 94.51%\n","Epoch [6/30], Step [100/202], Train Loss: 0.1559, Train Acc: 94.62%\n","Epoch [6/30], Step [110/202], Train Loss: 0.1532, Train Acc: 94.89%\n","Epoch [6/30], Step [120/202], Train Loss: 0.1470, Train Acc: 95.16%\n","Epoch [6/30], Step [130/202], Train Loss: 0.1418, Train Acc: 95.38%\n","Epoch [6/30], Step [140/202], Train Loss: 0.1356, Train Acc: 95.51%\n","Epoch [6/30], Step [150/202], Train Loss: 0.1338, Train Acc: 95.58%\n","Epoch [6/30], Step [160/202], Train Loss: 0.1301, Train Acc: 95.66%\n","Epoch [6/30], Step [170/202], Train Loss: 0.1291, Train Acc: 95.68%\n","Epoch [6/30], Step [180/202], Train Loss: 0.1297, Train Acc: 95.68%\n","Epoch [6/30], Step [190/202], Train Loss: 0.1307, Train Acc: 95.67%\n","Epoch [6/30], Step [200/202], Train Loss: 0.1311, Train Acc: 95.69%\n","Epoch [6/30], Train Loss: 0.1306, Train Acc: 95.70%, Val Loss: 0.2952, Val Acc: 89.22%\n","Epoch [7/30], Step [10/202], Train Loss: 0.1103, Train Acc: 96.25%\n","Epoch [7/30], Step [20/202], Train Loss: 0.0917, Train Acc: 96.88%\n","Epoch [7/30], Step [30/202], Train Loss: 0.0824, Train Acc: 97.08%\n","Epoch [7/30], Step [40/202], Train Loss: 0.0863, Train Acc: 97.03%\n","Epoch [7/30], Step [50/202], Train Loss: 0.0833, Train Acc: 97.12%\n","Epoch [7/30], Step [60/202], Train Loss: 0.0815, Train Acc: 97.19%\n","Epoch [7/30], Step [70/202], Train Loss: 0.0789, Train Acc: 97.28%\n","Epoch [7/30], Step [80/202], Train Loss: 0.0833, Train Acc: 97.03%\n","Epoch [7/30], Step [90/202], Train Loss: 0.0823, Train Acc: 97.08%\n","Epoch [7/30], Step [100/202], Train Loss: 0.0842, Train Acc: 97.06%\n","Epoch [7/30], Step [110/202], Train Loss: 0.0822, Train Acc: 97.13%\n","Epoch [7/30], Step [120/202], Train Loss: 0.0810, Train Acc: 97.14%\n","Epoch [7/30], Step [130/202], Train Loss: 0.0801, Train Acc: 97.14%\n","Epoch [7/30], Step [140/202], Train Loss: 0.0822, Train Acc: 97.05%\n","Epoch [7/30], Step [150/202], Train Loss: 0.0822, Train Acc: 97.06%\n","Epoch [7/30], Step [160/202], Train Loss: 0.0842, Train Acc: 97.03%\n","Epoch [7/30], Step [170/202], Train Loss: 0.0884, Train Acc: 96.89%\n","Epoch [7/30], Step [180/202], Train Loss: 0.0895, Train Acc: 96.86%\n","Epoch [7/30], Step [190/202], Train Loss: 0.0914, Train Acc: 96.76%\n","Epoch [7/30], Step [200/202], Train Loss: 0.0939, Train Acc: 96.67%\n","Epoch [7/30], Train Loss: 0.0947, Train Acc: 96.67%, Val Loss: 0.2945, Val Acc: 89.57%\n","Epoch [8/30], Step [10/202], Train Loss: 0.1706, Train Acc: 94.06%\n","Epoch [8/30], Step [20/202], Train Loss: 0.1423, Train Acc: 95.00%\n","Epoch [8/30], Step [30/202], Train Loss: 0.1349, Train Acc: 95.10%\n","Epoch [8/30], Step [40/202], Train Loss: 0.1361, Train Acc: 95.16%\n","Epoch [8/30], Step [50/202], Train Loss: 0.1313, Train Acc: 95.19%\n","Epoch [8/30], Step [60/202], Train Loss: 0.1201, Train Acc: 95.73%\n","Epoch [8/30], Step [70/202], Train Loss: 0.1077, Train Acc: 96.25%\n","Epoch [8/30], Step [80/202], Train Loss: 0.0990, Train Acc: 96.60%\n","Epoch [8/30], Step [90/202], Train Loss: 0.0930, Train Acc: 96.84%\n","Epoch [8/30], Step [100/202], Train Loss: 0.0904, Train Acc: 96.84%\n","Epoch [8/30], Step [110/202], Train Loss: 0.0881, Train Acc: 96.82%\n","Epoch [8/30], Step [120/202], Train Loss: 0.0872, Train Acc: 96.82%\n","Epoch [8/30], Step [130/202], Train Loss: 0.0860, Train Acc: 96.83%\n","Epoch [8/30], Step [140/202], Train Loss: 0.0836, Train Acc: 96.94%\n","Epoch [8/30], Step [150/202], Train Loss: 0.0806, Train Acc: 97.08%\n","Epoch [8/30], Step [160/202], Train Loss: 0.0800, Train Acc: 97.13%\n","Epoch [8/30], Step [170/202], Train Loss: 0.0799, Train Acc: 97.17%\n","Epoch [8/30], Step [180/202], Train Loss: 0.0785, Train Acc: 97.24%\n","Epoch [8/30], Step [190/202], Train Loss: 0.0794, Train Acc: 97.25%\n","Epoch [8/30], Step [200/202], Train Loss: 0.0776, Train Acc: 97.30%\n","Epoch [8/30], Train Loss: 0.0774, Train Acc: 97.32%, Val Loss: 0.1242, Val Acc: 96.08%\n","Epoch [9/30], Step [10/202], Train Loss: 0.1055, Train Acc: 96.56%\n","Epoch [9/30], Step [20/202], Train Loss: 0.1141, Train Acc: 96.56%\n","Epoch [9/30], Step [30/202], Train Loss: 0.0979, Train Acc: 96.98%\n","Epoch [9/30], Step [40/202], Train Loss: 0.0871, Train Acc: 97.42%\n","Epoch [9/30], Step [50/202], Train Loss: 0.0827, Train Acc: 97.25%\n","Epoch [9/30], Step [60/202], Train Loss: 0.0814, Train Acc: 97.29%\n","Epoch [9/30], Step [70/202], Train Loss: 0.0735, Train Acc: 97.54%\n","Epoch [9/30], Step [80/202], Train Loss: 0.0734, Train Acc: 97.54%\n","Epoch [9/30], Step [90/202], Train Loss: 0.0688, Train Acc: 97.74%\n","Epoch [9/30], Step [100/202], Train Loss: 0.0674, Train Acc: 97.72%\n","Epoch [9/30], Step [110/202], Train Loss: 0.0652, Train Acc: 97.73%\n","Epoch [9/30], Step [120/202], Train Loss: 0.0649, Train Acc: 97.73%\n","Epoch [9/30], Step [130/202], Train Loss: 0.0656, Train Acc: 97.62%\n","Epoch [9/30], Step [140/202], Train Loss: 0.0667, Train Acc: 97.59%\n","Epoch [9/30], Step [150/202], Train Loss: 0.0706, Train Acc: 97.54%\n","Epoch [9/30], Step [160/202], Train Loss: 0.0730, Train Acc: 97.46%\n","Epoch [9/30], Step [170/202], Train Loss: 0.0742, Train Acc: 97.44%\n","Epoch [9/30], Step [180/202], Train Loss: 0.0737, Train Acc: 97.47%\n","Epoch [9/30], Step [190/202], Train Loss: 0.0743, Train Acc: 97.40%\n","Epoch [9/30], Step [200/202], Train Loss: 0.0734, Train Acc: 97.48%\n","Epoch [9/30], Train Loss: 0.0730, Train Acc: 97.49%, Val Loss: 0.1261, Val Acc: 95.77%\n","Epoch [10/30], Step [10/202], Train Loss: 0.0245, Train Acc: 99.69%\n","Epoch [10/30], Step [20/202], Train Loss: 0.0299, Train Acc: 99.22%\n","Epoch [10/30], Step [30/202], Train Loss: 0.0277, Train Acc: 99.27%\n","Epoch [10/30], Step [40/202], Train Loss: 0.0276, Train Acc: 99.14%\n","Epoch [10/30], Step [50/202], Train Loss: 0.0295, Train Acc: 99.06%\n","Epoch [10/30], Step [60/202], Train Loss: 0.0292, Train Acc: 99.11%\n","Epoch [10/30], Step [70/202], Train Loss: 0.0284, Train Acc: 99.11%\n","Epoch [10/30], Step [80/202], Train Loss: 0.0286, Train Acc: 99.10%\n","Epoch [10/30], Step [90/202], Train Loss: 0.0313, Train Acc: 98.96%\n","Epoch [10/30], Step [100/202], Train Loss: 0.0312, Train Acc: 98.97%\n","Epoch [10/30], Step [110/202], Train Loss: 0.0324, Train Acc: 98.89%\n","Epoch [10/30], Step [120/202], Train Loss: 0.0317, Train Acc: 98.93%\n","Epoch [10/30], Step [130/202], Train Loss: 0.0320, Train Acc: 98.92%\n","Epoch [10/30], Step [140/202], Train Loss: 0.0339, Train Acc: 98.86%\n","Epoch [10/30], Step [150/202], Train Loss: 0.0363, Train Acc: 98.81%\n","Epoch [10/30], Step [160/202], Train Loss: 0.0359, Train Acc: 98.83%\n","Epoch [10/30], Step [170/202], Train Loss: 0.0359, Train Acc: 98.82%\n","Epoch [10/30], Step [180/202], Train Loss: 0.0366, Train Acc: 98.78%\n","Epoch [10/30], Step [190/202], Train Loss: 0.0368, Train Acc: 98.77%\n","Epoch [10/30], Step [200/202], Train Loss: 0.0375, Train Acc: 98.75%\n","Epoch [10/30], Train Loss: 0.0373, Train Acc: 98.76%, Val Loss: 0.2181, Val Acc: 93.68%\n","Epoch [11/30], Step [10/202], Train Loss: 0.0765, Train Acc: 97.19%\n","Epoch [11/30], Step [20/202], Train Loss: 0.0465, Train Acc: 98.44%\n","Epoch [11/30], Step [30/202], Train Loss: 0.0553, Train Acc: 98.02%\n","Epoch [11/30], Step [40/202], Train Loss: 0.0796, Train Acc: 97.66%\n","Epoch [11/30], Step [50/202], Train Loss: 0.0932, Train Acc: 97.25%\n","Epoch [11/30], Step [60/202], Train Loss: 0.1090, Train Acc: 96.77%\n","Epoch [11/30], Step [70/202], Train Loss: 0.1099, Train Acc: 96.56%\n","Epoch [11/30], Step [80/202], Train Loss: 0.1094, Train Acc: 96.41%\n","Epoch [11/30], Step [90/202], Train Loss: 0.1050, Train Acc: 96.49%\n","Epoch [11/30], Step [100/202], Train Loss: 0.0973, Train Acc: 96.75%\n","Epoch [11/30], Step [110/202], Train Loss: 0.0915, Train Acc: 96.96%\n","Epoch [11/30], Step [120/202], Train Loss: 0.0872, Train Acc: 97.14%\n","Epoch [11/30], Step [130/202], Train Loss: 0.0834, Train Acc: 97.24%\n","Epoch [11/30], Step [140/202], Train Loss: 0.0814, Train Acc: 97.30%\n","Epoch [11/30], Step [150/202], Train Loss: 0.0804, Train Acc: 97.29%\n","Epoch [11/30], Step [160/202], Train Loss: 0.0778, Train Acc: 97.34%\n","Epoch [11/30], Step [170/202], Train Loss: 0.0774, Train Acc: 97.37%\n","Epoch [11/30], Step [180/202], Train Loss: 0.0750, Train Acc: 97.45%\n","Epoch [11/30], Step [190/202], Train Loss: 0.0723, Train Acc: 97.53%\n","Epoch [11/30], Step [200/202], Train Loss: 0.0698, Train Acc: 97.62%\n","Epoch [11/30], Train Loss: 0.0698, Train Acc: 97.65%, Val Loss: 0.1536, Val Acc: 95.58%\n","Epoch [12/30], Step [10/202], Train Loss: 0.0219, Train Acc: 99.38%\n","Epoch [12/30], Step [20/202], Train Loss: 0.0438, Train Acc: 98.59%\n","Epoch [12/30], Step [30/202], Train Loss: 0.0547, Train Acc: 98.44%\n","Epoch [12/30], Step [40/202], Train Loss: 0.0463, Train Acc: 98.67%\n","Epoch [12/30], Step [50/202], Train Loss: 0.0486, Train Acc: 98.62%\n","Epoch [12/30], Step [60/202], Train Loss: 0.0478, Train Acc: 98.59%\n","Epoch [12/30], Step [70/202], Train Loss: 0.0487, Train Acc: 98.57%\n","Epoch [12/30], Step [80/202], Train Loss: 0.0457, Train Acc: 98.63%\n","Epoch [12/30], Step [90/202], Train Loss: 0.0440, Train Acc: 98.65%\n","Epoch [12/30], Step [100/202], Train Loss: 0.0419, Train Acc: 98.69%\n","Epoch [12/30], Step [110/202], Train Loss: 0.0410, Train Acc: 98.58%\n","Epoch [12/30], Step [120/202], Train Loss: 0.0465, Train Acc: 98.46%\n","Epoch [12/30], Step [130/202], Train Loss: 0.0467, Train Acc: 98.41%\n","Epoch [12/30], Step [140/202], Train Loss: 0.0464, Train Acc: 98.44%\n","Epoch [12/30], Step [150/202], Train Loss: 0.0462, Train Acc: 98.46%\n","Epoch [12/30], Step [160/202], Train Loss: 0.0464, Train Acc: 98.46%\n","Epoch [12/30], Step [170/202], Train Loss: 0.0457, Train Acc: 98.46%\n","Epoch [12/30], Step [180/202], Train Loss: 0.0456, Train Acc: 98.47%\n","Epoch [12/30], Step [190/202], Train Loss: 0.0477, Train Acc: 98.39%\n","Epoch [12/30], Step [200/202], Train Loss: 0.0491, Train Acc: 98.33%\n","Epoch [12/30], Train Loss: 0.0499, Train Acc: 98.31%, Val Loss: 0.2862, Val Acc: 92.88%\n","Epoch [13/30], Step [10/202], Train Loss: 0.1117, Train Acc: 97.19%\n","Epoch [13/30], Step [20/202], Train Loss: 0.0798, Train Acc: 97.81%\n","Epoch [13/30], Step [30/202], Train Loss: 0.0697, Train Acc: 98.02%\n","Epoch [13/30], Step [40/202], Train Loss: 0.0678, Train Acc: 98.20%\n","Epoch [13/30], Step [50/202], Train Loss: 0.0655, Train Acc: 98.25%\n","Epoch [13/30], Step [60/202], Train Loss: 0.0615, Train Acc: 98.33%\n","Epoch [13/30], Step [70/202], Train Loss: 0.0557, Train Acc: 98.48%\n","Epoch [13/30], Step [80/202], Train Loss: 0.0518, Train Acc: 98.63%\n","Epoch [13/30], Step [90/202], Train Loss: 0.0498, Train Acc: 98.65%\n","Epoch [13/30], Step [100/202], Train Loss: 0.0473, Train Acc: 98.69%\n","Epoch [13/30], Step [110/202], Train Loss: 0.0472, Train Acc: 98.64%\n","Epoch [13/30], Step [120/202], Train Loss: 0.0454, Train Acc: 98.72%\n","Epoch [13/30], Step [130/202], Train Loss: 0.0433, Train Acc: 98.77%\n","Epoch [13/30], Step [140/202], Train Loss: 0.0436, Train Acc: 98.77%\n","Epoch [13/30], Step [150/202], Train Loss: 0.0416, Train Acc: 98.85%\n","Epoch [13/30], Step [160/202], Train Loss: 0.0401, Train Acc: 98.89%\n","Epoch [13/30], Step [170/202], Train Loss: 0.0384, Train Acc: 98.93%\n","Epoch [13/30], Step [180/202], Train Loss: 0.0378, Train Acc: 98.91%\n","Epoch [13/30], Step [190/202], Train Loss: 0.0368, Train Acc: 98.93%\n","Epoch [13/30], Step [200/202], Train Loss: 0.0366, Train Acc: 98.92%\n","Epoch [13/30], Train Loss: 0.0365, Train Acc: 98.93%, Val Loss: 0.1213, Val Acc: 97.05%\n","Epoch [14/30], Step [10/202], Train Loss: 0.0109, Train Acc: 99.38%\n","Epoch [14/30], Step [20/202], Train Loss: 0.0253, Train Acc: 99.06%\n","Epoch [14/30], Step [30/202], Train Loss: 0.0235, Train Acc: 99.06%\n","Epoch [14/30], Step [40/202], Train Loss: 0.0255, Train Acc: 99.14%\n","Epoch [14/30], Step [50/202], Train Loss: 0.0279, Train Acc: 99.06%\n","Epoch [14/30], Step [60/202], Train Loss: 0.0252, Train Acc: 99.22%\n","Epoch [14/30], Step [70/202], Train Loss: 0.0264, Train Acc: 99.11%\n","Epoch [14/30], Step [80/202], Train Loss: 0.0279, Train Acc: 99.10%\n","Epoch [14/30], Step [90/202], Train Loss: 0.0305, Train Acc: 99.03%\n","Epoch [14/30], Step [100/202], Train Loss: 0.0368, Train Acc: 99.03%\n","Epoch [14/30], Step [110/202], Train Loss: 0.0453, Train Acc: 98.69%\n","Epoch [14/30], Step [120/202], Train Loss: 0.0509, Train Acc: 98.52%\n","Epoch [14/30], Step [130/202], Train Loss: 0.0545, Train Acc: 98.51%\n","Epoch [14/30], Step [140/202], Train Loss: 0.0532, Train Acc: 98.55%\n","Epoch [14/30], Step [150/202], Train Loss: 0.0572, Train Acc: 98.44%\n","Epoch [14/30], Step [160/202], Train Loss: 0.0565, Train Acc: 98.42%\n","Epoch [14/30], Step [170/202], Train Loss: 0.0563, Train Acc: 98.42%\n","Epoch [14/30], Step [180/202], Train Loss: 0.0550, Train Acc: 98.44%\n","Epoch [14/30], Step [190/202], Train Loss: 0.0551, Train Acc: 98.39%\n","Epoch [14/30], Step [200/202], Train Loss: 0.0543, Train Acc: 98.41%\n","Epoch [14/30], Train Loss: 0.0542, Train Acc: 98.41%, Val Loss: 0.1183, Val Acc: 96.51%\n","Epoch [15/30], Step [10/202], Train Loss: 0.0236, Train Acc: 99.06%\n","Epoch [15/30], Step [20/202], Train Loss: 0.0488, Train Acc: 98.28%\n","Epoch [15/30], Step [30/202], Train Loss: 0.0522, Train Acc: 98.44%\n","Epoch [15/30], Step [40/202], Train Loss: 0.0546, Train Acc: 98.52%\n","Epoch [15/30], Step [50/202], Train Loss: 0.0473, Train Acc: 98.69%\n","Epoch [15/30], Step [60/202], Train Loss: 0.0453, Train Acc: 98.70%\n","Epoch [15/30], Step [70/202], Train Loss: 0.0430, Train Acc: 98.66%\n","Epoch [15/30], Step [80/202], Train Loss: 0.0410, Train Acc: 98.63%\n","Epoch [15/30], Step [90/202], Train Loss: 0.0387, Train Acc: 98.72%\n","Epoch [15/30], Step [100/202], Train Loss: 0.0368, Train Acc: 98.75%\n","Epoch [15/30], Step [110/202], Train Loss: 0.0350, Train Acc: 98.81%\n","Epoch [15/30], Step [120/202], Train Loss: 0.0367, Train Acc: 98.78%\n","Epoch [15/30], Step [130/202], Train Loss: 0.0378, Train Acc: 98.70%\n","Epoch [15/30], Step [140/202], Train Loss: 0.0379, Train Acc: 98.73%\n","Epoch [15/30], Step [150/202], Train Loss: 0.0361, Train Acc: 98.81%\n","Epoch [15/30], Step [160/202], Train Loss: 0.0358, Train Acc: 98.77%\n","Epoch [15/30], Step [170/202], Train Loss: 0.0347, Train Acc: 98.81%\n","Epoch [15/30], Step [180/202], Train Loss: 0.0357, Train Acc: 98.78%\n","Epoch [15/30], Step [190/202], Train Loss: 0.0358, Train Acc: 98.77%\n","Epoch [15/30], Step [200/202], Train Loss: 0.0363, Train Acc: 98.75%\n","Epoch [15/30], Train Loss: 0.0360, Train Acc: 98.76%, Val Loss: 0.1731, Val Acc: 94.96%\n","Epoch [16/30], Step [10/202], Train Loss: 0.0425, Train Acc: 99.06%\n","Epoch [16/30], Step [20/202], Train Loss: 0.0326, Train Acc: 99.22%\n","Epoch [16/30], Step [30/202], Train Loss: 0.0445, Train Acc: 99.17%\n","Epoch [16/30], Step [40/202], Train Loss: 0.0402, Train Acc: 99.14%\n","Epoch [16/30], Step [50/202], Train Loss: 0.0392, Train Acc: 98.88%\n","Epoch [16/30], Step [60/202], Train Loss: 0.0342, Train Acc: 99.01%\n","Epoch [16/30], Step [70/202], Train Loss: 0.0368, Train Acc: 98.93%\n","Epoch [16/30], Step [80/202], Train Loss: 0.0351, Train Acc: 98.95%\n","Epoch [16/30], Step [90/202], Train Loss: 0.0345, Train Acc: 98.92%\n","Epoch [16/30], Step [100/202], Train Loss: 0.0326, Train Acc: 99.00%\n","Epoch [16/30], Step [110/202], Train Loss: 0.0302, Train Acc: 99.09%\n","Epoch [16/30], Step [120/202], Train Loss: 0.0284, Train Acc: 99.17%\n","Epoch [16/30], Step [130/202], Train Loss: 0.0270, Train Acc: 99.21%\n","Epoch [16/30], Step [140/202], Train Loss: 0.0262, Train Acc: 99.22%\n","Epoch [16/30], Step [150/202], Train Loss: 0.0253, Train Acc: 99.27%\n","Epoch [16/30], Step [160/202], Train Loss: 0.0243, Train Acc: 99.30%\n","Epoch [16/30], Step [170/202], Train Loss: 0.0237, Train Acc: 99.28%\n","Epoch [16/30], Step [180/202], Train Loss: 0.0240, Train Acc: 99.27%\n","Epoch [16/30], Step [190/202], Train Loss: 0.0241, Train Acc: 99.24%\n","Epoch [16/30], Step [200/202], Train Loss: 0.0234, Train Acc: 99.28%\n","Epoch [16/30], Train Loss: 0.0234, Train Acc: 99.27%, Val Loss: 0.1197, Val Acc: 96.75%\n","Epoch [17/30], Step [10/202], Train Loss: 0.0181, Train Acc: 99.38%\n","Epoch [17/30], Step [20/202], Train Loss: 0.0156, Train Acc: 99.53%\n","Epoch [17/30], Step [30/202], Train Loss: 0.0142, Train Acc: 99.48%\n","Epoch [17/30], Step [40/202], Train Loss: 0.0136, Train Acc: 99.53%\n","Epoch [17/30], Step [50/202], Train Loss: 0.0133, Train Acc: 99.50%\n","Epoch [17/30], Step [60/202], Train Loss: 0.0146, Train Acc: 99.48%\n","Epoch [17/30], Step [70/202], Train Loss: 0.0160, Train Acc: 99.46%\n","Epoch [17/30], Step [80/202], Train Loss: 0.0237, Train Acc: 99.41%\n","Epoch [17/30], Step [90/202], Train Loss: 0.0241, Train Acc: 99.41%\n","Epoch [17/30], Step [100/202], Train Loss: 0.0238, Train Acc: 99.38%\n","Epoch [17/30], Step [110/202], Train Loss: 0.0228, Train Acc: 99.38%\n","Epoch [17/30], Step [120/202], Train Loss: 0.0227, Train Acc: 99.38%\n","Epoch [17/30], Step [130/202], Train Loss: 0.0228, Train Acc: 99.33%\n","Epoch [17/30], Step [140/202], Train Loss: 0.0234, Train Acc: 99.31%\n","Epoch [17/30], Step [150/202], Train Loss: 0.0262, Train Acc: 99.27%\n","Epoch [17/30], Step [160/202], Train Loss: 0.0282, Train Acc: 99.16%\n","Epoch [17/30], Step [170/202], Train Loss: 0.0299, Train Acc: 99.10%\n","Epoch [17/30], Step [180/202], Train Loss: 0.0312, Train Acc: 99.05%\n","Epoch [17/30], Step [190/202], Train Loss: 0.0314, Train Acc: 99.00%\n","Epoch [17/30], Step [200/202], Train Loss: 0.0332, Train Acc: 98.89%\n","Epoch [17/30], Train Loss: 0.0331, Train Acc: 98.90%, Val Loss: 0.2598, Val Acc: 93.01%\n","Epoch [18/30], Step [10/202], Train Loss: 0.0375, Train Acc: 98.75%\n","Epoch [18/30], Step [20/202], Train Loss: 0.0275, Train Acc: 98.91%\n","Epoch [18/30], Step [30/202], Train Loss: 0.0272, Train Acc: 98.96%\n","Epoch [18/30], Step [40/202], Train Loss: 0.0267, Train Acc: 99.06%\n","Epoch [18/30], Step [50/202], Train Loss: 0.0266, Train Acc: 99.12%\n","Epoch [18/30], Step [60/202], Train Loss: 0.0261, Train Acc: 99.17%\n","Epoch [18/30], Step [70/202], Train Loss: 0.0257, Train Acc: 99.20%\n","Epoch [18/30], Step [80/202], Train Loss: 0.0269, Train Acc: 99.14%\n","Epoch [18/30], Step [90/202], Train Loss: 0.0263, Train Acc: 99.17%\n","Epoch [18/30], Step [100/202], Train Loss: 0.0245, Train Acc: 99.22%\n","Epoch [18/30], Step [110/202], Train Loss: 0.0283, Train Acc: 99.09%\n","Epoch [18/30], Step [120/202], Train Loss: 0.0293, Train Acc: 99.06%\n","Epoch [18/30], Step [130/202], Train Loss: 0.0287, Train Acc: 99.09%\n","Epoch [18/30], Step [140/202], Train Loss: 0.0271, Train Acc: 99.15%\n","Epoch [18/30], Step [150/202], Train Loss: 0.0273, Train Acc: 99.19%\n","Epoch [18/30], Step [160/202], Train Loss: 0.0262, Train Acc: 99.24%\n","Epoch [18/30], Step [170/202], Train Loss: 0.0250, Train Acc: 99.28%\n","Epoch [18/30], Step [180/202], Train Loss: 0.0241, Train Acc: 99.31%\n","Epoch [18/30], Step [190/202], Train Loss: 0.0231, Train Acc: 99.34%\n","Epoch [18/30], Step [200/202], Train Loss: 0.0221, Train Acc: 99.38%\n","Epoch [18/30], Train Loss: 0.0236, Train Acc: 99.26%, Val Loss: 0.0842, Val Acc: 97.48%\n","Epoch [19/30], Step [10/202], Train Loss: 0.0849, Train Acc: 97.81%\n","Epoch [19/30], Step [20/202], Train Loss: 0.2087, Train Acc: 94.84%\n","Epoch [19/30], Step [30/202], Train Loss: 0.1717, Train Acc: 95.21%\n","Epoch [19/30], Step [40/202], Train Loss: 0.1532, Train Acc: 95.55%\n","Epoch [19/30], Step [50/202], Train Loss: 0.1459, Train Acc: 95.69%\n","Epoch [19/30], Step [60/202], Train Loss: 0.1374, Train Acc: 95.89%\n","Epoch [19/30], Step [70/202], Train Loss: 0.1208, Train Acc: 96.43%\n","Epoch [19/30], Step [80/202], Train Loss: 0.1102, Train Acc: 96.72%\n","Epoch [19/30], Step [90/202], Train Loss: 0.1009, Train Acc: 97.01%\n","Epoch [19/30], Step [100/202], Train Loss: 0.0919, Train Acc: 97.28%\n","Epoch [19/30], Step [110/202], Train Loss: 0.0891, Train Acc: 97.39%\n","Epoch [19/30], Step [120/202], Train Loss: 0.0846, Train Acc: 97.53%\n","Epoch [19/30], Step [130/202], Train Loss: 0.0811, Train Acc: 97.60%\n","Epoch [19/30], Step [140/202], Train Loss: 0.0809, Train Acc: 97.57%\n","Epoch [19/30], Step [150/202], Train Loss: 0.0809, Train Acc: 97.52%\n","Epoch [19/30], Step [160/202], Train Loss: 0.0795, Train Acc: 97.56%\n","Epoch [19/30], Step [170/202], Train Loss: 0.0787, Train Acc: 97.57%\n","Epoch [19/30], Step [180/202], Train Loss: 0.0788, Train Acc: 97.57%\n","Epoch [19/30], Step [190/202], Train Loss: 0.0800, Train Acc: 97.53%\n","Epoch [19/30], Step [200/202], Train Loss: 0.0790, Train Acc: 97.53%\n","Epoch [19/30], Train Loss: 0.0784, Train Acc: 97.56%, Val Loss: 0.1785, Val Acc: 94.85%\n","Epoch [20/30], Step [10/202], Train Loss: 0.0289, Train Acc: 99.06%\n","Epoch [20/30], Step [20/202], Train Loss: 0.0398, Train Acc: 98.75%\n","Epoch [20/30], Step [30/202], Train Loss: 0.0318, Train Acc: 99.06%\n","Epoch [20/30], Step [40/202], Train Loss: 0.0295, Train Acc: 99.06%\n","Epoch [20/30], Step [50/202], Train Loss: 0.0281, Train Acc: 99.12%\n","Epoch [20/30], Step [60/202], Train Loss: 0.0256, Train Acc: 99.22%\n","Epoch [20/30], Step [70/202], Train Loss: 0.0240, Train Acc: 99.29%\n","Epoch [20/30], Step [80/202], Train Loss: 0.0248, Train Acc: 99.30%\n","Epoch [20/30], Step [90/202], Train Loss: 0.0229, Train Acc: 99.38%\n","Epoch [20/30], Step [100/202], Train Loss: 0.0225, Train Acc: 99.34%\n","Epoch [20/30], Step [110/202], Train Loss: 0.0219, Train Acc: 99.35%\n","Epoch [20/30], Step [120/202], Train Loss: 0.0212, Train Acc: 99.35%\n","Epoch [20/30], Step [130/202], Train Loss: 0.0218, Train Acc: 99.38%\n","Epoch [20/30], Step [140/202], Train Loss: 0.0220, Train Acc: 99.38%\n","Epoch [20/30], Step [150/202], Train Loss: 0.0242, Train Acc: 99.29%\n","Epoch [20/30], Step [160/202], Train Loss: 0.0267, Train Acc: 99.22%\n","Epoch [20/30], Step [170/202], Train Loss: 0.0279, Train Acc: 99.15%\n","Epoch [20/30], Step [180/202], Train Loss: 0.0298, Train Acc: 99.10%\n","Epoch [20/30], Step [190/202], Train Loss: 0.0303, Train Acc: 99.08%\n","Epoch [20/30], Step [200/202], Train Loss: 0.0302, Train Acc: 99.08%\n","Epoch [20/30], Train Loss: 0.0300, Train Acc: 99.09%, Val Loss: 0.1650, Val Acc: 95.64%\n","Epoch [21/30], Step [10/202], Train Loss: 0.0215, Train Acc: 99.38%\n","Epoch [21/30], Step [20/202], Train Loss: 0.0150, Train Acc: 99.53%\n","Epoch [21/30], Step [30/202], Train Loss: 0.0218, Train Acc: 99.06%\n","Epoch [21/30], Step [40/202], Train Loss: 0.0183, Train Acc: 99.30%\n","Epoch [21/30], Step [50/202], Train Loss: 0.0183, Train Acc: 99.31%\n","Epoch [21/30], Step [60/202], Train Loss: 0.0161, Train Acc: 99.43%\n","Epoch [21/30], Step [70/202], Train Loss: 0.0152, Train Acc: 99.46%\n","Epoch [21/30], Step [80/202], Train Loss: 0.0139, Train Acc: 99.53%\n","Epoch [21/30], Step [90/202], Train Loss: 0.0142, Train Acc: 99.55%\n","Epoch [21/30], Step [100/202], Train Loss: 0.0134, Train Acc: 99.59%\n","Epoch [21/30], Step [110/202], Train Loss: 0.0124, Train Acc: 99.63%\n","Epoch [21/30], Step [120/202], Train Loss: 0.0117, Train Acc: 99.66%\n","Epoch [21/30], Step [130/202], Train Loss: 0.0117, Train Acc: 99.66%\n","Epoch [21/30], Step [140/202], Train Loss: 0.0110, Train Acc: 99.69%\n","Epoch [21/30], Step [150/202], Train Loss: 0.0105, Train Acc: 99.71%\n","Epoch [21/30], Step [160/202], Train Loss: 0.0102, Train Acc: 99.71%\n","Epoch [21/30], Step [170/202], Train Loss: 0.0100, Train Acc: 99.71%\n","Epoch [21/30], Step [180/202], Train Loss: 0.0095, Train Acc: 99.72%\n","Epoch [21/30], Step [190/202], Train Loss: 0.0094, Train Acc: 99.74%\n","Epoch [21/30], Step [200/202], Train Loss: 0.0090, Train Acc: 99.75%\n","Epoch [21/30], Train Loss: 0.0090, Train Acc: 99.75%, Val Loss: 0.0897, Val Acc: 97.92%\n","Epoch [22/30], Step [10/202], Train Loss: 0.0066, Train Acc: 99.69%\n","Epoch [22/30], Step [20/202], Train Loss: 0.0043, Train Acc: 99.84%\n","Epoch [22/30], Step [30/202], Train Loss: 0.0035, Train Acc: 99.90%\n","Epoch [22/30], Step [40/202], Train Loss: 0.0029, Train Acc: 99.92%\n","Epoch [22/30], Step [50/202], Train Loss: 0.0026, Train Acc: 99.94%\n","Epoch [22/30], Step [60/202], Train Loss: 0.0022, Train Acc: 99.95%\n","Epoch [22/30], Step [70/202], Train Loss: 0.0022, Train Acc: 99.96%\n","Epoch [22/30], Step [80/202], Train Loss: 0.0023, Train Acc: 99.96%\n","Epoch [22/30], Step [90/202], Train Loss: 0.0022, Train Acc: 99.97%\n","Epoch [22/30], Step [100/202], Train Loss: 0.0022, Train Acc: 99.97%\n","Epoch [22/30], Step [110/202], Train Loss: 0.0022, Train Acc: 99.97%\n","Epoch [22/30], Step [120/202], Train Loss: 0.0021, Train Acc: 99.97%\n","Epoch [22/30], Step [130/202], Train Loss: 0.0020, Train Acc: 99.98%\n","Epoch [22/30], Step [140/202], Train Loss: 0.0024, Train Acc: 99.96%\n","Epoch [22/30], Step [150/202], Train Loss: 0.0023, Train Acc: 99.96%\n","Epoch [22/30], Step [160/202], Train Loss: 0.0022, Train Acc: 99.96%\n","Epoch [22/30], Step [170/202], Train Loss: 0.0021, Train Acc: 99.96%\n","Epoch [22/30], Step [180/202], Train Loss: 0.0020, Train Acc: 99.97%\n","Epoch [22/30], Step [190/202], Train Loss: 0.0019, Train Acc: 99.97%\n","Epoch [22/30], Step [200/202], Train Loss: 0.0019, Train Acc: 99.97%\n","Epoch [22/30], Train Loss: 0.0020, Train Acc: 99.95%, Val Loss: 0.0694, Val Acc: 98.10%\n","Epoch [23/30], Step [10/202], Train Loss: 0.0002, Train Acc: 100.00%\n","Epoch [23/30], Step [20/202], Train Loss: 0.0004, Train Acc: 100.00%\n","Epoch [23/30], Step [30/202], Train Loss: 0.0011, Train Acc: 100.00%\n","Epoch [23/30], Step [40/202], Train Loss: 0.0009, Train Acc: 100.00%\n","Epoch [23/30], Step [50/202], Train Loss: 0.0008, Train Acc: 100.00%\n","Epoch [23/30], Step [60/202], Train Loss: 0.0007, Train Acc: 100.00%\n","Epoch [23/30], Step [70/202], Train Loss: 0.0007, Train Acc: 100.00%\n","Epoch [23/30], Step [80/202], Train Loss: 0.0007, Train Acc: 100.00%\n","Epoch [23/30], Step [90/202], Train Loss: 0.0007, Train Acc: 100.00%\n","Epoch [23/30], Step [100/202], Train Loss: 0.0007, Train Acc: 100.00%\n","Epoch [23/30], Step [110/202], Train Loss: 0.0006, Train Acc: 100.00%\n","Epoch [23/30], Step [120/202], Train Loss: 0.0006, Train Acc: 100.00%\n","Epoch [23/30], Step [130/202], Train Loss: 0.0007, Train Acc: 100.00%\n","Epoch [23/30], Step [140/202], Train Loss: 0.0007, Train Acc: 100.00%\n","Epoch [23/30], Step [150/202], Train Loss: 0.0006, Train Acc: 100.00%\n","Epoch [23/30], Step [160/202], Train Loss: 0.0007, Train Acc: 100.00%\n","Epoch [23/30], Step [170/202], Train Loss: 0.0007, Train Acc: 100.00%\n","Epoch [23/30], Step [180/202], Train Loss: 0.0006, Train Acc: 100.00%\n","Epoch [23/30], Step [190/202], Train Loss: 0.0006, Train Acc: 100.00%\n","Epoch [23/30], Step [200/202], Train Loss: 0.0006, Train Acc: 100.00%\n","Epoch [23/30], Train Loss: 0.0006, Train Acc: 100.00%, Val Loss: 0.0534, Val Acc: 98.47%\n","Epoch [24/30], Step [10/202], Train Loss: 0.0006, Train Acc: 100.00%\n","Epoch [24/30], Step [20/202], Train Loss: 0.0003, Train Acc: 100.00%\n","Epoch [24/30], Step [30/202], Train Loss: 0.0004, Train Acc: 100.00%\n","Epoch [24/30], Step [40/202], Train Loss: 0.0003, Train Acc: 100.00%\n","Epoch [24/30], Step [50/202], Train Loss: 0.0006, Train Acc: 100.00%\n","Epoch [24/30], Step [60/202], Train Loss: 0.0005, Train Acc: 100.00%\n","Epoch [24/30], Step [70/202], Train Loss: 0.0005, Train Acc: 100.00%\n","Epoch [24/30], Step [80/202], Train Loss: 0.0005, Train Acc: 100.00%\n","Epoch [24/30], Step [90/202], Train Loss: 0.0005, Train Acc: 100.00%\n","Epoch [24/30], Step [100/202], Train Loss: 0.0005, Train Acc: 100.00%\n","Epoch [24/30], Step [110/202], Train Loss: 0.0004, Train Acc: 100.00%\n","Epoch [24/30], Step [120/202], Train Loss: 0.0004, Train Acc: 100.00%\n","Epoch [24/30], Step [130/202], Train Loss: 0.0004, Train Acc: 100.00%\n","Epoch [24/30], Step [140/202], Train Loss: 0.0004, Train Acc: 100.00%\n","Epoch [24/30], Step [150/202], Train Loss: 0.0004, Train Acc: 100.00%\n","Epoch [24/30], Step [160/202], Train Loss: 0.0004, Train Acc: 100.00%\n","Epoch [24/30], Step [170/202], Train Loss: 0.0004, Train Acc: 100.00%\n","Epoch [24/30], Step [180/202], Train Loss: 0.0004, Train Acc: 100.00%\n","Epoch [24/30], Step [190/202], Train Loss: 0.0004, Train Acc: 100.00%\n","Epoch [24/30], Step [200/202], Train Loss: 0.0005, Train Acc: 100.00%\n","Epoch [24/30], Train Loss: 0.0056, Train Acc: 99.88%, Val Loss: 0.1365, Val Acc: 96.75%\n","Epoch [25/30], Step [10/202], Train Loss: 0.4910, Train Acc: 92.19%\n","Epoch [25/30], Step [20/202], Train Loss: 0.5024, Train Acc: 89.69%\n","Epoch [25/30], Step [30/202], Train Loss: 0.4309, Train Acc: 90.21%\n","Epoch [25/30], Step [40/202], Train Loss: 0.3722, Train Acc: 91.09%\n","Epoch [25/30], Step [50/202], Train Loss: 0.3350, Train Acc: 91.44%\n","Epoch [25/30], Step [60/202], Train Loss: 0.3013, Train Acc: 92.29%\n","Epoch [25/30], Step [70/202], Train Loss: 0.2798, Train Acc: 92.54%\n","Epoch [25/30], Step [80/202], Train Loss: 0.2575, Train Acc: 93.09%\n","Epoch [25/30], Step [90/202], Train Loss: 0.2394, Train Acc: 93.47%\n","Epoch [25/30], Step [100/202], Train Loss: 0.2267, Train Acc: 93.84%\n","Epoch [25/30], Step [110/202], Train Loss: 0.2151, Train Acc: 94.09%\n","Epoch [25/30], Step [120/202], Train Loss: 0.2067, Train Acc: 94.30%\n","Epoch [25/30], Step [130/202], Train Loss: 0.1965, Train Acc: 94.52%\n","Epoch [25/30], Step [140/202], Train Loss: 0.1853, Train Acc: 94.84%\n","Epoch [25/30], Step [150/202], Train Loss: 0.1772, Train Acc: 95.00%\n","Epoch [25/30], Step [160/202], Train Loss: 0.1700, Train Acc: 95.20%\n","Epoch [25/30], Step [170/202], Train Loss: 0.1677, Train Acc: 95.22%\n","Epoch [25/30], Step [180/202], Train Loss: 0.1629, Train Acc: 95.31%\n","Epoch [25/30], Step [190/202], Train Loss: 0.1560, Train Acc: 95.51%\n","Epoch [25/30], Step [200/202], Train Loss: 0.1497, Train Acc: 95.69%\n","Epoch [25/30], Train Loss: 0.1488, Train Acc: 95.73%, Val Loss: 0.1176, Val Acc: 96.13%\n","Epoch [26/30], Step [10/202], Train Loss: 0.0469, Train Acc: 98.75%\n","Epoch [26/30], Step [20/202], Train Loss: 0.0474, Train Acc: 98.91%\n","Epoch [26/30], Step [30/202], Train Loss: 0.0420, Train Acc: 98.85%\n","Epoch [26/30], Step [40/202], Train Loss: 0.0352, Train Acc: 99.14%\n","Epoch [26/30], Step [50/202], Train Loss: 0.0310, Train Acc: 99.25%\n","Epoch [26/30], Step [60/202], Train Loss: 0.0292, Train Acc: 99.27%\n","Epoch [26/30], Step [70/202], Train Loss: 0.0263, Train Acc: 99.33%\n","Epoch [26/30], Step [80/202], Train Loss: 0.0251, Train Acc: 99.38%\n","Epoch [26/30], Step [90/202], Train Loss: 0.0230, Train Acc: 99.44%\n","Epoch [26/30], Step [100/202], Train Loss: 0.0230, Train Acc: 99.44%\n","Epoch [26/30], Step [110/202], Train Loss: 0.0220, Train Acc: 99.46%\n","Epoch [26/30], Step [120/202], Train Loss: 0.0219, Train Acc: 99.45%\n","Epoch [26/30], Step [130/202], Train Loss: 0.0215, Train Acc: 99.47%\n","Epoch [26/30], Step [140/202], Train Loss: 0.0228, Train Acc: 99.42%\n","Epoch [26/30], Step [150/202], Train Loss: 0.0220, Train Acc: 99.44%\n","Epoch [26/30], Step [160/202], Train Loss: 0.0228, Train Acc: 99.36%\n","Epoch [26/30], Step [170/202], Train Loss: 0.0223, Train Acc: 99.36%\n","Epoch [26/30], Step [180/202], Train Loss: 0.0228, Train Acc: 99.34%\n","Epoch [26/30], Step [190/202], Train Loss: 0.0219, Train Acc: 99.38%\n","Epoch [26/30], Step [200/202], Train Loss: 0.0213, Train Acc: 99.39%\n","Epoch [26/30], Train Loss: 0.0221, Train Acc: 99.40%, Val Loss: 0.0991, Val Acc: 97.11%\n","Epoch [27/30], Step [10/202], Train Loss: 0.0243, Train Acc: 99.06%\n","Epoch [27/30], Step [20/202], Train Loss: 0.0174, Train Acc: 99.38%\n","Epoch [27/30], Step [30/202], Train Loss: 0.0190, Train Acc: 99.27%\n","Epoch [27/30], Step [40/202], Train Loss: 0.0175, Train Acc: 99.30%\n","Epoch [27/30], Step [50/202], Train Loss: 0.0174, Train Acc: 99.31%\n","Epoch [27/30], Step [60/202], Train Loss: 0.0163, Train Acc: 99.38%\n","Epoch [27/30], Step [70/202], Train Loss: 0.0149, Train Acc: 99.42%\n","Epoch [27/30], Step [80/202], Train Loss: 0.0141, Train Acc: 99.45%\n","Epoch [27/30], Step [90/202], Train Loss: 0.0158, Train Acc: 99.44%\n","Epoch [27/30], Step [100/202], Train Loss: 0.0152, Train Acc: 99.47%\n","Epoch [27/30], Step [110/202], Train Loss: 0.0176, Train Acc: 99.43%\n","Epoch [27/30], Step [120/202], Train Loss: 0.0178, Train Acc: 99.40%\n","Epoch [27/30], Step [130/202], Train Loss: 0.0190, Train Acc: 99.35%\n","Epoch [27/30], Step [140/202], Train Loss: 0.0190, Train Acc: 99.35%\n","Epoch [27/30], Step [150/202], Train Loss: 0.0196, Train Acc: 99.35%\n","Epoch [27/30], Step [160/202], Train Loss: 0.0193, Train Acc: 99.38%\n","Epoch [27/30], Step [170/202], Train Loss: 0.0186, Train Acc: 99.41%\n","Epoch [27/30], Step [180/202], Train Loss: 0.0190, Train Acc: 99.39%\n","Epoch [27/30], Step [190/202], Train Loss: 0.0185, Train Acc: 99.41%\n","Epoch [27/30], Step [200/202], Train Loss: 0.0186, Train Acc: 99.39%\n","Epoch [27/30], Train Loss: 0.0185, Train Acc: 99.40%, Val Loss: 0.0776, Val Acc: 98.10%\n","Epoch [28/30], Step [10/202], Train Loss: 0.0045, Train Acc: 100.00%\n","Epoch [28/30], Step [20/202], Train Loss: 0.0038, Train Acc: 100.00%\n","Epoch [28/30], Step [30/202], Train Loss: 0.0041, Train Acc: 99.90%\n","Epoch [28/30], Step [40/202], Train Loss: 0.0039, Train Acc: 99.92%\n","Epoch [28/30], Step [50/202], Train Loss: 0.0040, Train Acc: 99.94%\n","Epoch [28/30], Step [60/202], Train Loss: 0.0036, Train Acc: 99.95%\n","Epoch [28/30], Step [70/202], Train Loss: 0.0033, Train Acc: 99.96%\n","Epoch [28/30], Step [80/202], Train Loss: 0.0034, Train Acc: 99.92%\n","Epoch [28/30], Step [90/202], Train Loss: 0.0038, Train Acc: 99.90%\n","Epoch [28/30], Step [100/202], Train Loss: 0.0037, Train Acc: 99.91%\n","Epoch [28/30], Step [110/202], Train Loss: 0.0037, Train Acc: 99.91%\n","Epoch [28/30], Step [120/202], Train Loss: 0.0036, Train Acc: 99.92%\n","Epoch [28/30], Step [130/202], Train Loss: 0.0034, Train Acc: 99.93%\n","Epoch [28/30], Step [140/202], Train Loss: 0.0032, Train Acc: 99.93%\n","Epoch [28/30], Step [150/202], Train Loss: 0.0030, Train Acc: 99.94%\n","Epoch [28/30], Step [160/202], Train Loss: 0.0029, Train Acc: 99.94%\n","Epoch [28/30], Step [170/202], Train Loss: 0.0034, Train Acc: 99.93%\n","Epoch [28/30], Step [180/202], Train Loss: 0.0062, Train Acc: 99.88%\n","Epoch [28/30], Step [190/202], Train Loss: 0.0082, Train Acc: 99.80%\n","Epoch [28/30], Step [200/202], Train Loss: 0.0086, Train Acc: 99.78%\n","Epoch [28/30], Train Loss: 0.0087, Train Acc: 99.77%, Val Loss: 0.1607, Val Acc: 96.25%\n","Epoch [29/30], Step [10/202], Train Loss: 0.0200, Train Acc: 99.06%\n","Epoch [29/30], Step [20/202], Train Loss: 0.0126, Train Acc: 99.53%\n","Epoch [29/30], Step [30/202], Train Loss: 0.0128, Train Acc: 99.48%\n","Epoch [29/30], Step [40/202], Train Loss: 0.0118, Train Acc: 99.53%\n","Epoch [29/30], Step [50/202], Train Loss: 0.0119, Train Acc: 99.56%\n","Epoch [29/30], Step [60/202], Train Loss: 0.0151, Train Acc: 99.48%\n","Epoch [29/30], Step [70/202], Train Loss: 0.0158, Train Acc: 99.46%\n","Epoch [29/30], Step [80/202], Train Loss: 0.0180, Train Acc: 99.34%\n","Epoch [29/30], Step [90/202], Train Loss: 0.0241, Train Acc: 99.24%\n","Epoch [29/30], Step [100/202], Train Loss: 0.0338, Train Acc: 99.00%\n","Epoch [29/30], Step [110/202], Train Loss: 0.0375, Train Acc: 98.92%\n","Epoch [29/30], Step [120/202], Train Loss: 0.0374, Train Acc: 98.93%\n","Epoch [29/30], Step [130/202], Train Loss: 0.0381, Train Acc: 98.89%\n","Epoch [29/30], Step [140/202], Train Loss: 0.0384, Train Acc: 98.82%\n","Epoch [29/30], Step [150/202], Train Loss: 0.0422, Train Acc: 98.73%\n","Epoch [29/30], Step [160/202], Train Loss: 0.0407, Train Acc: 98.77%\n","Epoch [29/30], Step [170/202], Train Loss: 0.0399, Train Acc: 98.77%\n","Epoch [29/30], Step [180/202], Train Loss: 0.0395, Train Acc: 98.77%\n","Epoch [29/30], Step [190/202], Train Loss: 0.0408, Train Acc: 98.73%\n","Epoch [29/30], Step [200/202], Train Loss: 0.0403, Train Acc: 98.75%\n","Epoch [29/30], Train Loss: 0.0399, Train Acc: 98.76%, Val Loss: 0.0773, Val Acc: 96.88%\n","Epoch [30/30], Step [10/202], Train Loss: 0.0246, Train Acc: 99.38%\n","Epoch [30/30], Step [20/202], Train Loss: 0.0218, Train Acc: 99.53%\n","Epoch [30/30], Step [30/202], Train Loss: 0.0160, Train Acc: 99.69%\n","Epoch [30/30], Step [40/202], Train Loss: 0.0170, Train Acc: 99.69%\n","Epoch [30/30], Step [50/202], Train Loss: 0.0147, Train Acc: 99.75%\n","Epoch [30/30], Step [60/202], Train Loss: 0.0161, Train Acc: 99.64%\n","Epoch [30/30], Step [70/202], Train Loss: 0.0144, Train Acc: 99.69%\n","Epoch [30/30], Step [80/202], Train Loss: 0.0127, Train Acc: 99.73%\n","Epoch [30/30], Step [90/202], Train Loss: 0.0115, Train Acc: 99.76%\n","Epoch [30/30], Step [100/202], Train Loss: 0.0110, Train Acc: 99.75%\n","Epoch [30/30], Step [110/202], Train Loss: 0.0111, Train Acc: 99.74%\n","Epoch [30/30], Step [120/202], Train Loss: 0.0119, Train Acc: 99.69%\n","Epoch [30/30], Step [130/202], Train Loss: 0.0117, Train Acc: 99.66%\n","Epoch [30/30], Step [140/202], Train Loss: 0.0114, Train Acc: 99.69%\n","Epoch [30/30], Step [150/202], Train Loss: 0.0110, Train Acc: 99.69%\n","Epoch [30/30], Step [160/202], Train Loss: 0.0107, Train Acc: 99.71%\n","Epoch [30/30], Step [170/202], Train Loss: 0.0108, Train Acc: 99.71%\n","Epoch [30/30], Step [180/202], Train Loss: 0.0104, Train Acc: 99.72%\n","Epoch [30/30], Step [190/202], Train Loss: 0.0114, Train Acc: 99.70%\n","Epoch [30/30], Step [200/202], Train Loss: 0.0110, Train Acc: 99.72%\n","Epoch [30/30], Train Loss: 0.0113, Train Acc: 99.71%, Val Loss: 0.1278, Val Acc: 97.29%\n"]}]},{"cell_type":"code","source":["trained_model"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"b3ZEnd4Tcdtw","executionInfo":{"status":"ok","timestamp":1678961317756,"user_tz":-540,"elapsed":34,"user":{"displayName":"HaJun Yoo","userId":"01231542744346053879"}},"outputId":"70552ffb-1aa1-46a8-c9f5-c93e5ebc18b1"},"execution_count":12,"outputs":[{"output_type":"execute_result","data":{"text/plain":["ResNetModel(\n","  (conv1): Conv2d(4, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n","  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","  (relu): ReLU(inplace=True)\n","  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n","  (layer1): Sequential(\n","    (0): BasicBlock(\n","      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (1): BasicBlock(\n","      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","  )\n","  (layer2): Sequential(\n","    (0): BasicBlock(\n","      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (downsample): Sequential(\n","        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (1): BasicBlock(\n","      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","  )\n","  (layer3): Sequential(\n","    (0): BasicBlock(\n","      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (downsample): Sequential(\n","        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (1): BasicBlock(\n","      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","  )\n","  (layer4): Sequential(\n","    (0): BasicBlock(\n","      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (downsample): Sequential(\n","        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (1): BasicBlock(\n","      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","  )\n","  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n","  (fc): Linear(in_features=512, out_features=6, bias=True)\n",")"]},"metadata":{},"execution_count":12}]},{"cell_type":"code","source":["print(f\"Training accuracy: {train_accs[-1]*100:.2f}%, Validation accuracy: {valid_accs[-1]*100:.2f}%\")\n","print(f\"Training loss: {train_losses[-1]:.4f}, Validation loss: {valid_losses[-1]:.4f}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Hu5j3_bWcs7s","executionInfo":{"status":"ok","timestamp":1678961317757,"user_tz":-540,"elapsed":18,"user":{"displayName":"HaJun Yoo","userId":"01231542744346053879"}},"outputId":"0ec9dd26-63dd-43f2-eed2-283551701d63"},"execution_count":13,"outputs":[{"output_type":"stream","name":"stdout","text":["Training accuracy: 99.71%, Validation accuracy: 97.29%\n","Training loss: 0.0113, Validation loss: 0.1278\n"]}]},{"cell_type":"code","source":["import matplotlib.pyplot as plt\n","\n","plt.plot(train_accs, label='Training accuracy')\n","plt.plot(valid_accs, label='Validation accuracy')\n","plt.xlabel('Epoch')\n","plt.ylabel('Accuracy')\n","plt.legend()\n","plt.show()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":276},"id":"OGz-bnXW7hXx","executionInfo":{"status":"ok","timestamp":1678962047841,"user_tz":-540,"elapsed":11,"user":{"displayName":"HaJun Yoo","userId":"01231542744346053879"}},"outputId":"569a4667-8b07-4b8e-de73-115f9d17c981"},"execution_count":26,"outputs":[{"output_type":"display_data","data":{"text/plain":["<Figure size 432x288 with 1 Axes>"],"image/png":"iVBORw0KGgoAAAANSUhEUgAAAYMAAAEDCAYAAADX1GjKAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/NK7nSAAAACXBIWXMAAAsTAAALEwEAmpwYAABNNElEQVR4nO3deVhUZfvA8e8Mq6yCbAKihAsKapKZSu6oiVtlJeZWmlpp9laW/rCyNLfSymxTX20xTVq0N63ENEtL1FQEwR0V2RmQVXaY3x9HxgWUdVjk/lwXF5wz5xyew+i559nuR6XVarUIIYRo0tT1XQAhhBD1T4KBEEIICQZCCCEkGAghhECCgRBCCMCwvgtQFXl5eURERGBvb4+BgUF9F0cIIRqF4uJiNBoN3t7emJqalntMowoGERERjB8/vr6LIYQQjdKmTZvo3r17ua81qmBgb28PKDfk5ORUz6URQojGITExkfHjx+ueoeVpVMGgtGnIyckJV1fXei6NEEI0LndqXpcOZCGEEBIMhBBCSDAQQgiBnoPB2bNn8fPz45tvvinz2oEDB3jssccYO3Ysn3zyiW7/kiVLGDt2LAEBAYSHh+uzeEIIIa7RWwdyTk4OixYtolevXuW+/s4777B+/XocHR2ZMGECQ4cO5cqVK0RHRxMUFERUVBSBgYEEBQXpq4hCCCGu0VvNwNjYmHXr1uHg4FDmtZiYGKytrWnZsiVqtZp+/foREhJCSEgIfn5+AHh4eJCRkUF2dra+iiiEaCAkk37901vNwNDQEEPD8i+v0WiwtbXVbdva2hITE0NaWhpeXl437ddoNFhYWOirmEKIGtBqtWTmFZGUmUdCRh5JGcr3xMw8EjNyycororC4hIJiLQVFxRQWa5XtohIKikt0P5dowdLEEKtmRljf8GXVzPCWbSP6t3fA2syovm/9rtOg5xnIpwUhGo68wmL+OJ3MH6eTiU/PvfbAzyOnoLjMsS3MjXG0MqW5mRHmJoYYGagxMVRjZKDCyECNsaH6hu8q1CoVWXlFZOYWknHtK0qTTWae8nNeYYnu2t3cmrP1ud6oVKq6vP0KZeUVEhmfSURcBifjM7nH3pynfN2xMKmdx2xEXAYOViY4WJafTqKm6iUYODg4kJKSottOSkrCwcEBIyOjm/YnJyffccacEEK/iku0hESl8tPxOIIjEsnKL8LW3Bh3O3M6OlnRv70DLa1NcbQ2paW1KU5WpjhYmWBiWLu5w/IKi8nMK+THo3Es33maI9Fp3N/GtuIT9SQzr5CIuIxrX0oAuJByVfe6nYUJW0Pj+PLAJV4Y2I5xPdwwNqxeq/zhi1f44PezhFxIZfagdrw8uH1t3cZN6iUYuLq6kp2dTWxsLE5OTuzdu5cVK1aQlpbG6tWrCQgIIDIyEgcHB2kiEqKOabVaIuIy+el4HNvD4knOysfSxJCHvJ14uJsLPe9pgYG6bj+VmxoZYGpkwFO927B2XxRr912otWDw3b8xHLp4pVLH5hQUcSohk0upObp9ztameLtY80g3F7xdrfF2tsbe0oTQy2ks33maBT9Hsv7vi7wypD0juzijruTf7silK3yw+yz/nE/FzsKEN0Z0YvwDbtW6x8rQWzCIiIhg+fLlxMXFYWhoSHBwMAMHDsTV1ZXBgwfz1ltv8corrwDg7++Pu7s77u7ueHl5ERAQgEqlYsGCBfoqnhB6k1NQxKELV9h/LoW/z2soKtHi7WxNZxdrvF2s8XKxwsq08m3eeYXFnE3KIjI+k5PxmZxKyKRrq+b83zBPDA1qbwxIdOpVfgqN539hcVzQXMXIQMWADg483M2FgZ4OmBrVf6bgZsYGTOzZmtV7z3NBk8099jX7sHg5NYfAbSewNDXEzLjix6GxoRpPJyse794KbxdrvJ2taGFhUu6x3dxs+HZaT/46q2H5zjO8uOU4a/ddYN4wT/q0u32Lx9HoND7cfZb951KwszDm9eEdGf9Aa5oZ6/fvr9I2oob52NhYBg0axJ49eyQ3kWgwSkq0nEzIZN85DfvPpnA0Oo2C4hJMDNX0cLfF1MiAiLgMEjLydOe425nj5WxFZxclSHi5WGPdzIiMnEIiE5Q255PxmUTGZ3Jek01xifLf1NLEkDZ25pyIy2CQpwMfP+lT44dEek4Br3wXxp7TyQA84G7Lw91c8Pdu2SA7ajVZ+fgu/4PH73Nl8SOda3StOd+HsT0snv2vDcDBSj9t8aD8G/k5LJ4Vu84Qm5aLb9sWzH3Iky6uzXXHhF5O44Pd59h3VkMLc2Oe7efBhJ61EwQq8+xs0B3I4u5Q+iCry6YFTVY+OyMT+e1EAkei0+jsYk3fdvb062BPZxfrGpclISOX/edS2H8uhX/Op3DlagEAHVta8ZRvG/q0s+P+NrY3fZpOyc7nRFwGkXEZnIjLIPRyOjvCE3SvtzA3JvXadQAcrUzo1NKKwZ0c8XK2wsvZGlebZqjVKjYejObN/0Uwcf0h/ju5O83NjKt1H+eSsnjm6yPEp+fy8uD2PHafK87Nm1Xzr1I37C1NGOPjwg9HY3l5cPvbfjKvyAVNNluPxTLF112vgQBArVbxcDcXhnV2YvOhy6z+4zyjPv6H4V1a8mg3FzYejObPMxpszY35v2GeTOzVulI1ldokNQOhV0ejr/Dq9+EUlWh5c0QnBnV00NsokOTMPHZGJvJLeAKHL11Bq4V77M3pdU8LIuIyCI/LQKsFGzMj+rSzp197e/q0t7vj6IySEi2Xr+QoTTQJGURe+7SuycoHlAdTn3Z29Glnh2/bO1+rPKnZ+UTGZ3IiLoPo1Ku421nQydkKL2cr7Cp4yP16IoH/bDlOGzszvprSg5bWVXuI7z6ZxH+CjmNqZMCaiT7c17r+OmSr6nxyNn7v/8V//NrxH7/qdai+uCWUXZFJ7J87oMK/dW3Lyitk3f6L/Hf/BXIKirExM2J6Xw8m9WqNeS2NPrqR1AxEvckrLOaD3WdZt+8CLa2bYWZswDNfH2FAB3sWjPSijZ15rfyexIw8dkYk8OuJRP6NVgJAOwcLXhjYjuGdW9Le0UIXfFKz8/n7fAp/ndGw75yGn8PiAfBytqJfe3v6trfHwsTwWvNMBicTMjmVkEV2fhEAhmoVbR0s6NvOHi9nK3q3bUEHR8saBbcWFib0vfa7q8q/c0uaNzNi+sajPPZZCF9N6UFbh4rb0LVaLZ/+GcWKXWfwdrZmzcT76q82kJsOieGQcwU8h4NB5Zql2jpYMMjTgY0h0Tzbz6PK/RnnkrL4OSyeGX096jwQAFiaGvHy4PZM7Nmafy9d0f3bq09SMxC17kRsBi9/d5xzydmM69GK+cM7YWKo5qsDl/hw9zkKikqY3vcenh/gUa2qsCYrnx3h8fwSrjQBAXRwtMS/c0v8OzvRztGywmuUtvP/dVbDX2c1HItOo6jk+n8Fc2MDOra00n1K93K2pq2DRYPoRL1VRFwGT33xL8UlJWx46n66udnc9tjcgmJe+zGc7WHxjOzqzLtjuui9Y1LnaiokHIeEsOtfaRevv97+IXjsCzA2q9TlQqJSGbfuIEse6cyTVRxlM3PTMf46q2H/awOwMa9eE1tjUplnpwQDUWsKikr4eO95Ptl7HnsLE5aN6Uz/DjenI0nOzGPZb6fZGhqHs7Upr4/oxDBvpwo/XWfnFxEckchPx+P453wKJVrwdLJkeOeWDOvcslKfiO8kM6+QkKhUCotL6NTSijYtzCs9BLAhiE69ysT1h9Fk5fPZBJ8yf3eA+PRcpm88QmR8Jq8O7cBz/Txqv8muMA+yEyErSfmuOXP9wZ8Rc/04mzbQsuu1r3sh5RzsnAduPWHct9Ds9gGtlFarZdTH/3A1v4jdL/er9Pt1Mj4T/4/2M3tgW14e0qHy95aXCbH/wj0DQN24Ej5LMBB15nRiJq98F0ZkfCaPdnNhwUivO45E+ffSFd78XySnEjLxbduCt0d50dbh5k/0BUUl7Dur4afjcew+lUReYQmuNs0Yfa8zD9/rUqkaQFOiycpn8obDnE3KYsXjXXm4m4vutaPRV5ix8Rh5hcWsCriXQR0dq/dLiovg7E5Ij4asROXrxod/XkbZc1q0VR74uod/l/If9pHb4MdpYNceJvwIVi0rLM7PYfHM/jaU/07qjl+nyt3TtK+PcPBCKn+/NrByo6UK8+Df/8L+lZB7Be57CoZ/0KgCgvQZCL0rKi5hzb4LfLj7LNbNjFg78T6GeFW8PvX9bWzZPsuXzYcvsyL4DA99uJ8pD7rzwsC2nE7M4qfQOH49kUBaTiE2ZkY8fl8rRt/rzH2tbRpcGoKGwt7ShKAZPZn+9VH+E3SclOx8nulzD9/9G8P8n07g0rwZ3057oGZB9LdX4cgG5WcDY7BwAktHsGsH7n2Vny2cwNIJLByVGoCpVeWu7fUImDaHoAmwYQhM/AlaeNzxFH9vJ5Y3b8ba/RcqFQxOxGbw+8kkXh7cvuJAUFwEYZvhz2WQGQceA8HGHY6sB20JjFjVqAJCRSQYiGqL0mTzyndhHI9JZ3jnlix62BvbKrS/GhqomdSrDcM7t+S94DOs23+BDX9fpKhEi6mRmiGdnHi4mzN92tljVIuTq+5mlqZGfPH0/bz83XHe+eUUOyMSORKdxoNt7fj4yW7VHoIKKJ+Oj2yAXrOgzyvKp/vaDsweA2Dydtj0GGwYCuN/AOd7b3u4oYGap33b8M4vpwiLSadrq+Z3vPz7v5+huZkRT/u2uf1BWi2c+hn2LILUc+ByHzz8GdzTT3nNrAXsexdKSmDUR6BueP1I1SHBQNxEq9WSlV9ESlY+KdkFaLLySclWvkp/1mQXkJKVT2JmHpamhqwe142RXZ2r/TtbWJiwbEwXAnq48f2RGLq3sWFIJye9DLG7K+xZpHwq7z+33JdNjQxYPc4HW/MIvjl4mSm+7gT613C28sV98Otr0G4oDF6o3wegiw9MCYaNj8CXI2DcZqXWcRsBPdxYtecc6/Zf4OMnfW573NHoNPae0TD3IU8sbzcDPGov7Hkb4kPBrgOM3aSMcioNeioVDJyv3P+fS0FbDKM/uSsCgvxvE2i1Wk4lKEPtdoTHE5uWW+YYtQpszU2wtzTBzsIYDztzWjY3ZXKvNrU2YefeVs25t4JPdk1e+mX4+32lmcLBEzqNLvcwA7WKRaO9eWFgOxxr+v5cuQjfTVLa/sf8t24efHbtYOouJSB8MwbGrIdOo8o91MLEkCd7uLFu/wViruTQyrb80Ugf/H6WFubGTOrVuuyLcUdh99tw8S+wbgWjP4WuAbe/1/7zQKWGvYuV9+Lhz/Tzd8lKUjqtYw8rAcpnMnR+rPZ/DxIMmrSLKVfZHhbPz2HxnE/OxkCtok87Oyb1an3toW+i+25jZlznyclqRVEBhAeBU2dw6tL423hL2+vtO8LPs8GlO1i7lHuoSqWqeSDIz4JvxynNI+O+rXz7f22wcoanf4PNY+H7yTDiA6XzthxP+bZh/d8X2fDPRRaM9Crz+qELqfx9PoXXh3e8ucaZfBr2vgOntivNPw8tg+5TwLAScw/6vaYEhD8WQUkxPLIGDGrwSC0uhMQTysM/5rASANIvK68ZGCud72Ytqn/9CkgwaGISMnLZEZbAz2HxnIjLQKVSOnPfedgb/84tq9Tm3ygcWa8MWQSlQ7OtH7QbrAwPbNa8XotWZYV5cOxr6OAPfm/Dmj6wbQZM+lk/Qa6kBLZOh5SzMHFrhZ25emFmC5N+gu8mw/YXIScVHny5TF9FS+tmjOzqTNC/Mfxn0M2dw1qtlpW/n8XB0oQJPa/VCtIuKR3D4UFgZA79/w96zQSTKnau952j1Ah2v6U0GT26rtIT5ygpUR74Z35THv7xoVB0rVZu6Qyt7oceM6BVD+WDjJF+U2ZIMGgCcguK2Roay/+Ox/PvtTQNXVyteX14R4Z3aVnlNAaNRnERHPwUXO+H7lPh/O9w+hc4vglUBsqY9rZ+0G4IOHrVfmdocRHsXqB8wu01s+bXi9ymPAx7TAe7tjBsOfz8Ahz4CB78T82vf6u978CZX2HYe3BP/9q/fmUZmyu1kp+ehz0LIfYIdBmrvG83TFB7po8720Lj2Hz4Ms/1vx64DkSlcvjiFd4e5YVpngZ2vQdHv1Ie4r1mgu9LYF6DT9wPvqT8e/r9DaWG8NiG2weE0gAQ+ROc/B9kxYPaSPnU3/1p5d9qqx5gXfdD5yUY3MUKikrY8q+SFEuTlU9bBwte8mvPyK7OuNdSOogG7fR2pZo9dAl0HAn3jlMe0HFH4Nwu5WvP28qXpTO081PaZF271/x3F+XDD1Pg9A7lP3vHUdC8Vc2u+e86pVOztDO120Q497vSTHFPP3DuVvNylzrxgzKu3mcy9JhWe9etLgMjpRmmhQccXqcEKSMzaD8UOj0M7Ybg5WzNg23t+PLARaY+6I6xoVqpFew6QwerQsZnrYdV66CkEHwmQd9XlUBdG3xnK8ElOBC+f0qZSW14rZZdXgAwMFFqqJ0WKvdQl81vtyHB4C5UVFzC1tA4Vu0+R1x6Lj3a2PLxuG70cLdtOmP0tVo48LEyLryD//X9BoZKjcCtJwx6EzIT4PxuJTBE/gTHN8Owd+H+qdX/3YW5ylj587uVJo0Dq5VO3xEfVP+acUeVr2Hv3TyyZeQqZf+Pz8CMfcqn6JqKOwb/mwluvcF/Re3XmKpLrVY6bvvMgeh/4ORPcPJnpcZ0LTDMazOQx85bsD0snjH3ubI/8iK+cRt4odlODEOuQpcnlGvY3lP75es1U+lD2DlPCQi9ZynluzEAtPUDr4YTAG4kweAuUlKi5deIBN7//SwXNFfp7GLNkkc707edXdWCgFbbcB4A1RVzSKkB+K+48ygPq5bgM1H5ysuAH6bCLy9D8kmlM7Gy7b+lSjtcL/2tPKjve0q57rGvlcBQ3drB4f+CsYUywuVGZrbwyOfw1SjlITRqdfWuXyorEbaMB3MHGLvx+qfbhsTAUKkJ3dNPCY43BAbvyG2EmppyaOf9aDN603X/Z/Q1yqTEY4QyJNSxk37L1vM5UBvCr3PgzC83BIC3ldxLDSwA3EiCwV1Aq9Xyx+lkVuw6y6mETNo7WvD5hPsY6uVY9ZrA1hnKhBu79mDvCfYdrn+3adN4xlMfWK3MZr33ycqfY2oNTwYp7fwHVit5dZ74WnngVkZuujJZKu4YPLpW+RQK0OdlJRjsXwkjP6zijaAkeIv4UQlY5T1M3PuC74vwz4fKg+c2w00rVJinBIK8dGVYp7ld9a5Tl8oJDPF/bsQ7OhjVvv2EFXemoG8gfoP9K75WbekxTWl+Krja4APAjSQYNHIHolJYEXyGY5fTcbM144OxXRnV1aV6w0ALc5VPWPaeygPw0n4I33L9dQMTZfx3aYBw6qJ04jW04ZqpUUpHcZ+Xq95sojaAIe+AQydl9Mq6gTBuizKm/06upsDGh5Whik98pfRRlLJ2Vdqoj32tlKl5FdexDf0aivPh/ju03Q+YDxf+rHC46W1ptbDjP0pt6omNylDcxuZaYHB1e5B+y3ajyk7CpEUrdg/sV/dl8Rxe97+zhiQYNFIZOYXM+SGM308m4WRlypJHOvN4d9eapW249DcU5cGgN5RPmKA0caScA83pa19nlHHQET8qr/eYoYxqqY1mJa1WaaaoRIKyOzr4mdK802N69a9x75PKJKst4+G/fvDYeqWdtzyZCUogSLukBI52fmWP6fMyhG6E/e9XrXZQUgz/boA2fe4ckAyNlYlZ1Rlumpuu9GmEfQv9A287uauxMDE0YKKvB+8FF/GBX7taXSf6bqbXYLBkyRLCwsJQqVQEBgbSpUsX3Wu7d+/ms88+w9jYmOHDhzNhwgQOHTrEiy++SLt27QBo3749b7zxhj6L2CiFx6bz/KZjJGXmMfchT572bVM7efbP7QLDZtD6wev7TK2V0TW3jrApuKqkRTj0mVIlrunQRq1WGTb49/sw6mOlSaQ6cq4oQ0c7P64kS6uJVj1g+l6lD2DzWBj8NvSefXPgS7+stNdf1SiZNts8WP61SmsHR7+qWu3gbDBkXIahiys+tqrDTRMjlBFK4d9BYQ50CVBG2NwFnunjjoe9OUM61fDfQBOit2Bw+PBhoqOjCQoKIioqisDAQIKCggAoKSlh0aJFbNu2jebNmzNt2jT8/JRPUz169OCjjz7SV7EaNa1Wy+bDl3n755PYWRjz3Yxed1zIpIoXV4KBe9/KTW4xNleGbGYnKW3slk5lOzerYu8SJRCYNlc6Qts8CLbuVb/OkQ3Kg602xvWD8hCfslMZ4/77m5B0UukYNjJVmqO+GgUFWUqGzVb33/laD750re+gCrWDw2vByuXmEVF3UtFw06ICZcjt4f/C5QNgaKqkN7h/2h0TwjU2JoYGPORdwxpmE6O3+lNISIjuAe/h4UFGRgbZ2dkApKWlYWVlha2tLWq1mp49e3LgwAF9FeWukFNQxCvfhTF/WwQ9PVqwY3af2gsEoDzY0i4pY58rS61WRrK06aMMRTy/p3q/+89lShZIn0nK8EiVGrY9qzSRVEVRvvLw9BioTCKrLcbm8PiXSrt8+Bb4criS0OyLYcqM0ck7Kg4EcL12EPrN9TQDd5JyDi7sVSYjVTbNQelwUwtHZbhpwVVlf2aCEnA/9FbmP2TFw+BF8PIpJdHaXRQIRPXoLRikpKRgY3P9YWVra4tGo9H9fPXqVS5dukRhYSGHDh0iJSUFgPPnz/Pss88ybtw4/vnnH30Vr1GJ0mTzyCcH2HY8jv/4teOLp+6v/bQR53Yp36sSDEDJ4RKwSZkM9d0kiD9etfP/ek/J/njveCU/vE1r8H8PYg7CP6uqdq0TPyg1lV6zqnZeZahUSi6aJ75Whp1ufBhQKblzWnap6OzrSlMp7F9Z8bH//leZsOYzuWplLR1umhql9B98N1kJAn+9q3T6P/k9vBCqTJSq7Egpcdersw7kGxdUU6lULFu2jMDAQCwtLXUr77Rp04ZZs2YxbNgwYmJimDRpErt27cLYuAGOda4jv4Qn8NoPYRgbqvnq6R7VWji9Us7/rgwntWlT9XNNrWHCD7B+CGx6XBmWWJkmnv3vKykPugQo4+NLOzy7jFVmmO5donRkV+Zhq9VCyCfg4KXUDPSl02hlItvBz6Dfq1WfvGTtojzcj36hrAlwu76D/GxlApzXI2BRdgnLCt043NS0OTzwrDKRTh+TrcRdQW81AwcHB92nfYDk5GTs7a8/yHr06MHmzZtZs2YNlpaWuLi44OjoiL+/PyqVCjc3N+zs7EhKStJXERu0gqIS3t4eyczNx2jvZMkvs/voLxAUXFVGErUbUv1rWDkrHajFBUrK4aspdz7+n1VKGojOj8PDn948f0GlghEfKhkat05Xxr9XJOoPSI5UZn3qe8Jcyy7wyGfVf7A++JLSFHan2kF4EORn1iwVxMA3YNL/lKagoYslEIg70lsw8PX1JTg4GIDIyEgcHBywsLi+aPkzzzxDamoqOTk57N27l169evHzzz+zfv16ADQaDampqTg6VnOt1kYsISOXgLUhfPHPJZ7q3Yag6b1wbq7HZHIX9ykP8ao2Ed3KvoMyaSszDjY/cb29+lYhnyidsV6PwsOflz+RzcxWacvWnFI6QysS8rGy3KK3fnK916rS2kHoN5AWXfZ1rVZpImrZVUlcVl0GhkqCuRuSuQlxO3prJvLx8cHLy4uAgABUKhULFixg69atWFpaMnjwYJ544gmmTJmCSqVi+vTp2NraMnDgQObMmcOePXsoLCzkrbfeanJNRBdTrvLYZwfIKyzm4ye7MaJLLSXSupNzvytpfN161fxabj2V8e7fTYTvn4aAzTd3fh78XEnm1Wn0tXS/d/gn2M4P7n9GedC3G6KMjilPUqRSMxj0ZsNMn1CeB1+CY18ptYNRt4yei/5H6ZcY9XHjTwsiGg2V9sbG/AYuNjaWQYMGsWfPHl0/w92kpETL2LUhnEnMYuvzvWnrUIOFyytLq4UPuygzTsdtrr3r/rteyfHTbaLSH6BSKdkmf50DniOU0TmVyftTcBU+76OMFHrun/LXIPjpeSVZ2UuRjatD9Ndri8u/cEzpOC/13WRlNvHLp+RTvagVlXl2ytS8BuSrkEv8eymNN0d61U0gAGVGccblmjcR3er+qUp2ydCNymihIxuUQNBhuJLet7IJ4IzNlTw/WQnwWzlr/mYlKpOmuk1oXIEAyu87yIxXVt3ymSiBQNQpCQYNRHTqVZbvPM2ADvaM8aliXpmaOP+78r22gwHAwNfh3gnw13LY8ZKStOvxL6velOPaXZkZG75FqQHc6NAaKClSskU2NlbOSlbT45uUOR4AR79U1tTtXoMU2kJUgwSDBqCkRMtrP4RjpFaz5NHOdbvmwLldSlI2fayspFIpM229H1M6i5/4uvpt+n3ngLOPElQyE5R9BVeVGkfHEY13pEzpKln7Vyqzg498ofSPVGf2tRA1IMGgAdh0KJpDF6/w+oiOdbsEZX4WRIfop1ZQysBISfL2+BeVW2T8Ttd5dK0yzPR/M5W+jtBNSrrlXi/UWnHrnK52sBlCVsPV5IaxsphociQY1LOYKzks/e00fdrZ8UT3Gi6LWFUX/lKWAGyrx2BQm+zawZBFELVHSTtx8BNl6KXbA/Vdspp58D9K7WDPQmVCm8eg+i6RaIIkGNQjrVbL3B/DUatULBvTpe6XpDy3C4wtleGgjcX9zygPy9/mKu3s+kg9UddKaweg3F9DWx9CNAmynkE92nz4MgeiUlnySGdc9DmprDxarTK/wGNA1Zd2rE8qlTIZ7dOeShqMGxeRacz6zVX6U+6rYh4iIWqJBIN6Epeey9JfT+PbtgXjetRx8xAok5qy4vXbX6AvVi1h2h/KsMzGsgxnRcxbKCusCVFPJBjUA61Wy7wfwynRaln2aD00D8H1LKWNpb/gVi086rsEQtxVpHGyHnx3JIb951L4v2GetLKtp4lF535XZh3XdIlJIcRdQYJBHUvIyOWdHafoeY8t4x9oXfYArVZZOKW4SH+FyMuAywdrlqVUCHFXkWBQh7RaLYFbT1BUomX5mC6o1eU0D136W1k4Zd97+itI1F7QFjfeJiIhRK2TYFCHfjwWx94zGl57qAOtW5iXf1BCmPJ9/wpICNdPQc79fm2h+xqkRxZC3FUkGNSRpMw8Fm6P5P42Nkzu1eYOB0ZAM1tlYZefnofiwtotiFar5CPyGFT5dXWFEHc9CQZ1ZOGOk+QXlfDuY13Lbx4qlRgBzt1gxAeQdEJZGrI2JYYr6wQ3xiGlQgi9kWBQB6I02fx6IoFn+rjjbneb5iFQEpVpToOTN3gOV5aE3PcuJJ6ovcLohpT61d41hRCNngSDOrBu3wWMDdQ87VtBJsqUs0quIMfOyvawd5Umo9psLjq3W6l5VGeRdSHEXUuCgZ4lZeax9Vgcj3d3xc6igqydSZHKd0cv5buZrdJclBgOf39Y88LkXIHYwzKKSAhRhgQDPdvw90WKSkqY3qcSM2aTToCBsZKds1THEcp6AH8tvx4sqivqD2XhFJlfIIS4hV6DwZIlSxg7diwBAQGEh988THL37t2MGTOGcePG8c0331TqnMYmI7eQTYcuM7yLM24tKjHTODEC7D3LJo4b9q6y9u9Pz9Wsuej8bqXZycWn+tcQQtyV9BYMDh8+THR0NEFBQSxevJjFixfrXispKWHRokWsW7eOTZs2sXfvXhITE+94TmO06VA02flFzOhbyVW4kiKUFBG3Mm8Bw99X5iD8s6p6hSkpUeYXtB109yR3E0LUGr0Fg5CQEPz8lBErHh4eZGRkkJ2dDUBaWhpWVlbY2tqiVqvp2bMnBw4cuOM5jU1eYTEb/r5En3Z2eLtYV3xCVhJc1YCjd/mvdxqlLB355zJIOln1AiWEQk6KNBEJIcqlt2CQkpKCjY2NbtvW1haNRqP7+erVq1y6dInCwkIOHTpESkrKHc9pbLYeiyMlO5/n+lUyu2ZShPLd6TbBAMD/PWXm8P+er3ruonO7AZWsoiWEKFedTUHVarW6n1UqFcuWLSMwMBBLS0tcXctfjP3GcxqT4hIta/dF0cXVml4eLSp3UmkwuF3NAMDcDoavhO8nw4FV0OeVyhfq3C5wuU9pchJCiFvorWbg4OBASkqKbjs5ORl7e3vddo8ePdi8eTNr1qzB0tISFxeXCs9pLHZGJHIpNYdn+3lUfq2CxAiwdFaGk96J18PQ6WGluSj51J2PLcqH+ONw9EuIOypNREKI29JbMPD19SU4OBiAyMhIHBwcsLCw0L3+zDPPkJqaSk5ODnv37qVXr14VntMYaLVaPv8rCnc7c4Z6OVX+xKSIOzcR3ch/BZhYXpuMdq25KC9DyXga8ilsew4+84UlzrC2H2x/UWle8nq4yvcjhGga9NZM5OPjg5eXFwEBAahUKhYsWMDWrVuxtLRk8ODBPPHEE0yZMgWVSsX06dOxtbXF1ta2zDmNzYGoVE7EZbD00c4Y3CkH0Y2K8pXZx+0fqtzxFvZKQPjhafjiIchOhvToG153VEYltRsCLbuAUxewcZeF1oUQt6XXPoM5c+bctO3p6an7eciQIQwZUrbZ4tZzGpvP/4rC3tKER7q5VP4kzRkoKap8zQDA6xG4sBcu/aOkl7hvMjh1VYKApWPVCy6EaNIkh3EtiojLYP+5FOY+5ImpURXG8lem8/hWKhWMWl21AgohxG1Iu0Et+vyvKCxNDBnf061qJyZGgKEp2Moi70KI+iHBoJZEp17l1xMJPNnTDStTo4pPuFHSCXDoKIvNCCHqjQSDWrJ23wUM1WqmVpSm+lZarVIzqEoTkRBC1DIJBrVAk5XP90djedTHBQcr06qdnJUIuVfKz0kkhBB1RIJBLfjywEUKi0uYXtmEdDfSdR571W6hhBCiCiQY1FB2fhEbQ6J5yMuJe+yrMUGudElLCQZCiHokPZY1FLz7dzLzinm2sgnpbpUUAdatoJlNxccKIYSeSM2gBgovHWLMvwHMbnmarq2aV+8iSZHSeSyEqHcSDGrg4vE/ARhvcaR6FyjMg5RzVZt5LIQQeiDBoAZyLx8DwCFxHxTmVv0CmlOgLZb+AiFEvZNgUANW6SfJVFujKryqLDZfVYmlI4lkWKkQon5JMKim2KQU3IpjuOA2Bkybw8mfq36RpAgwMgPbKk5UE0KIWiajiarp5PEDuKq0OHj6QvN8OLUDigrA0LjyF0mKBIdOskC9EKLeSc2gmq6c/xeAlp4PQMdRkJ8BF/dV/gJarTLHQDqPhRANgASDaigu0WKsOUG2gTUqa1fwGADGlnDqf5W/SGYc5KXLsFIhRIMgwaAawmPT6VBygZwW3sq6AoYm0OEhpamodBnKiiRWYw0DIYTQEwkG1XDgTDztVbFYut93fWfHUUrCueh/KneRJElDIYRoOCQYVMPl00cwUhXTzM3n+s62fsrIoFOVHFWUFAnNW4OplX4KKYQQVVBhMHjhhRfYtWsXBQUFVb74kiVLGDt2LAEBAYSHh9/02qZNmxg7dizjxo1j8eLFAGzdupV+/foxceJEJk6cyGeffVbl36lvWXmFGCRdu5eWXa+/YGymBIRTO6CkpOILJUZI2mohRINR4dDSp59+mj179rBu3TratWvHyJEj6dWrV4UXPnz4MNHR0QQFBREVFUVgYCBBQUEAZGdns379enbt2oWhoSFTpkzh+PHjAPj7+zN37tya3ZUehUSl0omLFBlZYmhzy/yATqOVmkHsYXDrefuLFOTAlSjwHqPfwgohRCVVGAx8fHzw8VGaQ06cOMHChQtJSkriiSeeYMqUKZiZmZV7XkhICH5+fgB4eHiQkZFBdnY2FhYWGBkZYWRkRE5ODmZmZuTm5mJtbV2Lt6U/+8+l8LhBNGrne5XO4xu1GwIGxsoEtDsFg+RToC2R/gIhRINRYTNRbm4uv/zyCzNnzuSdd97B39+f77//HmdnZ2bOnHnb81JSUrCxuZ6W2dbWFo1GA4CJiQkzZ87Ez8+PAQMG0LVrV9zdlU/Zhw8fZurUqUyePJmTJ0/W9P5q3T9nE+ioikbt3LXsi6ZW4DEQTm1X5hHcTmnnscwxEEI0EBXWDEaNGsXgwYOZPXs2HTp00O1/9NFHCQ0NrfQv0t7wcMzOzmbNmjXs3LkTCwsLJk+ezOnTp+natSu2trb079+f0NBQ5s6dy/bt26t4S/oTnXoV47TzGJkUQst7yz+o4yg4uxPiQ8HFp/xjkiLB2AKat9FXUYUQokoqrBls27aN++67TxcIfvrpJ3JycgBYtGjRbc9zcHAgJSVFt52cnIy9vT0AUVFRtGrVCltbW4yNjenevTsRERF4eHjQv39/ALp168aVK1coLi6u9s3Vtv3nUvBWX1Q2WpZTMwDoMAzUhnceVZQYoTQRqWUwlxCiYajwaTRnzhxiY2N12/n5+bzyyisVXtjX15fg4GAAIiMjcXBwwMJCWRbSxcWFqKgo8vLyAIiIiKBNmzasW7eOHTt2AHD27FlsbW0xMGg4eXv2n9PwgGksWiNzaHGblc3MbKFNH6XfoLymIq1WFrQRQjQ4FTYTZWVlMXnyZN322LFjdQ/sO/Hx8cHLy4uAgABUKhULFixg69atWFpaMnjwYKZOncqkSZMwMDCgW7dudO/eHVdXV1599VW2bNlCUVGRbshpQ1BUXMKB86n8n/llVC063zm5XKdRsOMlSD5ZtpM4/bKSx0g6j4UQDUiFwcDCwoJvvvkGHx8fSkpKOHjwIJaWlpW6+Jw5c27a9vT01P0cEBBAQEDATa87OTmxcePGSl27roXFpnM1vwBXwyhoOfHOB3uOgB0vK7WDWx/6SdfSUMgcAyFEA1JhM9GKFStISUnhww8/5OOPP6agoIB33323LsrWoOw7m8I96gQMi3Nu319QysIBWvcuv98gKRJQKamrhRCigaiwZmBpacm0adPIyMgAoKCggNmzZ7Nhwwa9F64h2X9Og3+LZMii4mAAyqiinXMh5TzYtb2+P/GEspiNiYXeyiqEEFVVYc3g448/ZtSoUYwcOZIZM2YwZsyYm5p7moKM3EKOx6TT1zIeDE3BvhL333Gk8v3WtNZJEdJ5LIRocCoMBvv372fPnj106tSJ7du38/XXXzeoET51ISQqhRIttC+5oPQBGFRigThrF3DpfvNymPnZcOWi9BcIIRqcCoOBSqVCq9VSXFxMXl4eXl5eHD16tC7K1mD8dTYFCxMDLNMiK9dEVKrTKEg4DmmXlO3kk4BWRhIJIRqcCoPB0KFD+eqrrxg5ciSjR4/mySefpFmzZnVRtgZBq9Wy76yGkW4FqPIzqxYMOo5Svp+6Nos6SRa0EUI0TBW2dzzwwAN06qSMfOnXrx9paWl07NhR7wVrKC6l5hCXnstDHRIhhqoFA1t3cOqiNBX1fkGZeWxiDc3d9FZeIYSojgprBsuWLaOoSFnK0dnZGS8vL9RNKI3C/nNKcr2uBtFKmomqDgntNEpJaZ0Zf63z2KtstlMhhKhnFdYMmjVrxpAhQ/D09MTIyEi3f9WqVXotWEOx72wKrWybYZ1xEhw6KusdV0XH0fDHO0pTUVIk3PukfgoqhBA1UGEwmDp1al2Uo0EqLC4hJCqFh+91RnU+TElCV1X27ZWhqAc/hYJs6TwWQjRIFQaDw4cPl7u/R48etV6Yhib0cjpXC4oZ7FoM4am3T1tdkY6jYN+1WduOMqxUCNHwVNj4b2Njo/uysLDg7NmzutnId7v95zQYqFXcb3pZ2VHdYNDp2qgilVppahJCiAamwprB+PHjb9p+6qmnePbZZ/VWoIZk37kU7m3VHPPUP5UHeXWbeBy9wcZd6YA2Ln+ZUCGEqE8VBoPz58/ftK3RaLh48aLeCtRQpOcUEB6bzouD2kFCGNh1qP6DXKWChz+F4oLaLaQQQtSSCoPB22+/rftZpVJhaWlJYGCgXgvVEPxzPhWtFvq0s4ewMHDvV7MLtu5dOwUTQgg9qDAYbNy4kfj4eJydnQFlyUoPj9us8nUX2XdWg6WpIV2b50FWQtUmmwkhRCNTYQfye++9x0cffaTb3rBhw12/noFWq2X/OQ2+HnYYJl9LISHBQAhxF6swGISGhrJs2TLd9uLFiwkLC9NroepblOYq8Rl59GlvB/HHlZ2SaVQIcRerMBiUlJRw7tw53XZ4eDja8hZ6v4uUpqDo285eyTpq6wGmVvVbKCGE0KMK+wzefPNN3nrrLS5duoRKpaJt27a89dZblbr4kiVLCAsLQ6VSERgYSJcuXXSvbdq0iZ9//hm1Wo23tzfz58+nsLCQefPmER8fj4GBAUuXLqVVq1bVvrnqColKpXULM1rZmkFCOLh2r/MyCCFEXaowGHTq1In33nuvyh3Ihw8fJjo6mqCgIKKioggMDCQoKAiA7Oxs1q9fz65duzA0NGTKlCkcP36cixcvYmVlxcqVK/n7779ZuXIlH374Yc3usBouX8mhnYMl5FyBjMtwf9NNySGEaBr01oEcEhKCn58fAB4eHmRkZJCdnQ2AkZERRkZG5OTkUFRURG5uLtbW1oSEhDB48GAAevfuzbFjx6p1UzUVl5aLS3NTZX4BgPO99VIOIYSoK3rrQE5JScHGxka3bWtri0ajtMWbmJgwc+ZM/Pz8GDBgAF27dsXd3Z2UlBRsbW2VgqnVqFQqCgrqdqJWZl4hWflFuNg0ux4MnLrc+SQhhGjk6qwD+cZzsrOzWbNmDTt37mTPnj2EhYVx+vTpO55TV+LTcwFwbn4tGDR3AzPbOi+HEELUpSp3IHt4eODr61vhhR0cHEhJSdFtJycnY29vDyj9Dq1atdLVArp3705ERAQODg5oNBo8PT0pLCxEq9VibGxc3XurljLBQOYXCCGagAprBp06deL9999n2rRptGzZkoSEhEqtdObr60twcDAAkZGRODg4YGFhAYCLiwtRUVHk5eUBEBERQZs2bfD19WXnzp0A7N27lwceeKDaN1ZdcWlKMHBtVgRXoiQYCCGahNvWDNLT0wkODmbHjh1ER0czZMgQsrKy2LVrV6Uu7OPjg5eXFwEBAahUKhYsWMDWrVuxtLRk8ODBTJ06lUmTJmFgYEC3bt3o3r07xcXFHDhwgHHjxmFsbHxTX0VdiUvPw8hAhV32GWVHddNWCyFEI3LbYPDggw/i5ubG3Llz6dOnD2q1mocffrhKF58zZ85N256enrqfAwICCAgIuOn10rkF9Sk+PZeW1s1QJ4YrO6RmIIRoAm7b3rNs2TLc3NyYP38+CxYsICQkpC7LVW/i03Nxbm6qzDy2bAkWDvVdJCGE0LvbBoMRI0bw+eef88svv+Dt7c2nn37KhQsXWL58eZk1Du4mcem50nkshGhyKuwJtra2ZuzYsWzcuJHff/8dOzs7XnvttbooW50rLC4hKTOPNpZAylnpLxBCNBkVDwu6gaOjI1OnTmXr1q36Kk+9SsrMo0QLHdWXQVsiNQMhRJNRpWBwtysdVtqm8FozmAQDIUQTIcHgBvEZSjBwvHoGzOzAyrmeSySEEHVDgsEN4tOVSXAWV04qi9moVPVcIiGEqBsSDG4Ql56Lg5kadcppaCnJ6YQQTYcEgxvEpeVyv2UKFBeAoyxzKYRoOiQY3CA+PZf7TGKVDVnzWAjRhEgwuEar1RKfnounKhoMTKBF2/oukhBC1BkJBtdk5hZxtaCY1gVR4NgJDCrM7i2EEHcNCQbXxKbnAFrsrp4DR+/6Lo4QQtQpCQbXxKfn4UgaJgVpssylEKLJkWBwTXx6Lh3V0cqGk9QMhBBNiwSDa+LTc+licFnZcPSq38IIIUQdk2BwTWx6Lvcax0Lz1mBqXd/FEUKIOiXB4BrdsFKZXyCEaIIkGFxzJS0Np6I4CQZCiCZJr4PplyxZQlhYGCqVisDAQLp0UUbpJCUl3bQ+ckxMDK+88gqFhYWsWrUKNzc3AHr37s1zzz2nzyICUFBUgu3V86iNtRIMhBBNkt6CweHDh4mOjiYoKIioqCgCAwMJCgoClEVyNm7cCEBRURETJ05k4MCBBAcH4+/vz9y5c/VVrHIlZuTRUVXaeSwjiYQQTY/emolCQkLw8/MDwMPDg4yMDLKzs8sct23bNoYOHYq5ubm+ilKhuPRcOqkuUWRkCc3d6q0cQghRX/QWDFJSUrCxsdFt29raotFoyhz3/fff89hjj+m2Dx8+zNSpU5k8eTInT57UV/FuoswxuEyhvZesYSCEaJLqLAGPVqstsy80NJR77rkHCwsLALp27YqtrS39+/cnNDSUuXPnsn37dr2XLT4tm4dUlzFyGaD33yWEEA2R3oKBg4MDKSkpuu3k5GTs7e1vOubPP/+kV69eum0PDw88PDwA6NatG1euXKG4uBgDAwN9FROA/OTzmKvyZUEbIUSTpbdmIl9fX4KDgwGIjIzEwcFBVwModeLECTw9PXXb69atY8eOHQCcPXsWW1tbvQcCAJPUU8oPMpJICNFE6a1m4OPjg5eXFwEBAahUKhYsWMDWrVuxtLRk8ODBAGg0Glq0aKE7Z+TIkbz66qts2bKFoqIiFi9erK/i3cQ26zTFGGBg71nxwUIIcRfSa5/BjXMJgJtqAUCZ/gAnJyfdkNO6otVqccmPItWsNQ5GpnX6u4UQoqFo8jOQ03IK6UA0mdYd67soQghRb5p8MEhKjKOl6gpF9pKpVAjRdDX5YJAdfRwAY9eu9VsQIYSoR00+GJQknACguXu3ei6JEELUnyYfDJpdiSRJa4ONvXN9F0UIIepNkw8GtllnuWR4DypJQyGEaMKadjAoysepIJoks3b1XRIhhKhXTTsYaM5gSDFZzWWymRCiaWvSwaAwLgyAYgdZw0AI0bTVWdbShignJgxjrTFmLdvXd1GEEKJeNemaAYnhnNa64WxTfwvrCCFEQ9B0g4FWS7MrpzhV4oZL82b1XRohhKhXTTcYZMRiXJjJSW1rnKwlQZ0QomlrusEgUZl5nGDaFhND/a+ZIIQQDVnTDQZJEZSg4mrzDvVdEiGEqHdNNxgkhhOvcrppcR0hhGiqmmww0CZGcKJYOo+FEAKaajDIy0SVdpHIYjecpfNYCCGaaDBIPgnASW1rnKVmIIQQ+p2BvGTJEsLCwlCpVAQGBtKlSxcAkpKSblofOSYmhldeeYWHHnqIefPmER8fj4GBAUuXLqVVq1a1X7BrI4lOlrTGxUaCgRBC6C0YHD58mOjoaIKCgoiKiiIwMJCgoCAAHB0ddQvfFxUVMXHiRAYOHMiOHTuwsrJi5cqV/P3336xcuZIPP/yw9guXeII8Q2sSsZU+AyGEQI/NRCEhIfj5+QHg4eFBRkYG2dnZZY7btm0bQ4cOxdzcnJCQEAYPHgxA7969OXbsmH4Kl3iC+GZtMTM2xLqZkX5+hxBCNCJ6CwYpKSnY2Njotm1tbdFoNGWO+/7773nsscd059ja2ioFU6tRqVQUFBTUbsGKiyD5JBfUbXBu3kwWtRFCCOqwA1mr1ZbZFxoayj333IOFhUWlz6mxK1FQlEd4cWtpIhJCiGv0FgwcHBxISUnRbScnJ2Nvb3/TMX/++Se9evW66ZzS2kNhYSFarRZjY+PaLdi1zuPDOc4ykkgIIa7RWzDw9fUlODgYgMjISBwcHMrUAE6cOIGnp+dN5+zcuROAvXv38sADD9R+wRJPoFUbcTTHAZfmMsdACCFAj6OJfHx88PLyIiAgAJVKxYIFC9i6dSuWlpa6TmKNRnNTOgh/f38OHDjAuHHjMDY2ZtmyZbVfsMQTFNi0ozDHUGoGQghxjV7nGdw4lwC4qRYAsH379pu2S+cW6FVSBOkOvhCH9BkIIcQ1TWsGcnYyZCcRb+IBIDUDIYS4pmkFg2udx+fV7qhUyKI2QtSDZcuWMXHiRB566CH69evHxIkTmTVrVqXOfemll8jLyyv3NY1Gw5tvvlmbRW1S9NpM1OBcCwZhRW44WhZgZNC0YqEQDcG8efMA2Lp1K+fOnWPu3LmVPveDDz647Wv29vYsXLiwxuVrqppWMEiKACtXorKMcLGR1c2EaEjmzZuHkZER6enpLF26lFdeeYWcnBzy8vJ444036NKlCwMHDmT79u0sWrQIBwcHIiMjiY+PZ8WKFVhbWzN79my2bt3K4MGDGTt2LHv37qWgoIAvvvgCrVbL7NmzycvLo1+/fnz33Xf88ccfN5Vh6dKlhIeHk5+fz7hx43j88ceJi4tj3rx5FBcX4+zszPLly0lMTCyzb/78+QwdOpQBAwawd+9egoODmTVrFq+++ipmZmZMmDCBrKwsvvnmG9RqNe3atWPRokUUFhYyb9484uLiMDEx4d1332XWrFmsXLkSNzc3EhMTef7559m6date//5NKxgkngAnb+Jic+naqnl9l0aIevfj0Vi+OxJTq9d8onsrxtznWq1zra2tWbRoERcvXuTxxx/Hz8+PkJAQ1q1bx+rVq286tqCggPXr1/Ptt9/y008/MXnyZN1rxcXF3HPPPTzzzDO89NJLHDx4kISEBDw8PHj99dfZtGlTmd+dn5+Pi4sL//d//0deXh5+fn48/vjjfPDBBzz11FMMGjSId999l4iICDZu3Fhm3+2cOnWKvXv3YmNjQ1BQEP/973+xsrJi/PjxnDlzhvDwcOzs7Fi5ciW//PILe/bsYfTo0fz66688++yz7Nmzh+HDh1fr71kVTaedpDAXUs6hdfQmISMXZ5ljIESDU5rZ2M7OjuDgYMaNG8eKFStIT08vc2z37t0BcHJyKjfv2Y2vZ2VlERUVhY+PDwCDBg0qc7yJiQkZGRkEBAQwbdo00tLSADh58qTuvNdee42uXbuWu+92WrVqpUvNY21tzfPPP8+ECROIiooiPT2dyMhI3bWGDx/Ok08+yfDhw9m1axegTM4dMWJEBX+5mms6NYPsJNAWk2HjTWGxFlcZSSQEY+5zrfaneH0wMlISR3711Vc4Ojry3nvvceLECd59990yxxoYXG/qLS91za2va7Va1Grl8295OckOHz7MwYMH2bhxI0ZGRnTr1k13nVuvX96+G69ZVFRU5p4KCgpYuHAh//vf/7C3t2fGjBm6a5WUlNx0LRsbG5ycnAgPD6ekpARHR8cy5a1tTadm0Lw1PL2Tiy36ATKsVIiGLC0tDTc3NwB2795NYWFhja/p5uama87Zt29fub/TyckJIyMj9uzZQ3FxMQUFBXh7e3Pw4EEAVq1axYEDB8rdZ25urkunc/To0TLXv3r1KgYGBtjb25OQkEBERASFhYV07txZd629e/fy+eefAzB69GgWLlzIQw89VON7r4ymEwxUKmjdi7gMZViaBAMhGq7Ro0fzxRdfMGXKFLp06YJGo+HHH3+s0TUfeeQRjhw5wsSJE0lJSdHVEkr17t2b6OhoJkyYQExMDP379+ett95i9uzZfPfdd0yYMIHY2FgeeOCBcveNHj2a9evXM3XqVAwNyza62NjY4Ovry5gxY/j444955plnWLp0Kf7+/uTm5jJhwgS++uorHnnkEQAGDBjA5cuXGTp0aI3uu7JUWr2kBtWP2NhYBg0axJ49e3B1rV7Vdu2+KJb8epqwBUNkLQMhmpC4uDguXLhAnz59CA0NZfXq1WzYsKG+i3VbBw8eZNu2bSxfvrzG16rMs7Pp9BlcE5+eh6WJLGojRFNjaWnJl19+ySeffALA/Pnz67lEt/fRRx/x999/lxlBpU9NLhjEpedKE5EQTZCVlRXr16+v72JUyuzZs5k9e3ad/s6m02dwTVyaDCsVQohbNblgEJ8hNQMhhLhVkwoGV/OLSM8pxMVGgoEQQtyoSQWDhIxcQNYxEEKIWzWpYBCbpgQDaSYSov6MHTu2TC6flStX3naYZ+nyt4sXLyYm5uY8SmfPnmXixIm3/V3Z2dn8/fffAKxdu5bQ0NCaFP2u1qSCQXy6TDgTor6NGDGC33777aZ9u3btqjAZ2/z582nVqlWVfldkZCT//PMPANOnT9elmBBlNamhpfHpuRioVThamtR3UYRosvz9/Rk3bhyvvvoqABERETg4OKDVanWf8ouKili+fLkuJQXAxIkTeeONN7CysuLFF1/E2NiYDh066F7fsGEDwcHBlJSU0K9fP2bNmsXChQvJzs6mTZs2hIaGMnToUB588EHefPNNYmJiKCgoYPbs2Tz44IPlpr22sLDQXf/06dO8/fbbGBoaolarWbVqFc2bN2fdunUEBwejVqt5+eWX6dmzZ5l9rq6uuvTaAI8++igfffQRH3/8cYVpu//55x/ef/99DAwM8Pf3x93dnR07dvDee+8B8PrrrzNgwIByk+9VhV6DwZIlSwgLC0OlUhEYGKjLSAiQkJDAyy+/TGFhIZ06dWLhwoUcOnSIF198kXbt2gHQvn173njjjVorT1x6Lk5WphjKojZCKI5/C6Hf1O41u02Ae8fd9uUWLVrQqlUrwsPD6dKlC7/99hsjR44kOTmZmTNn0rNnT3744Qc2b96sWwjnRl9//TX+/v5MnjyZtWvXcubMGd1rmzdvRq1WM2jQIJ566immTp3KuXPnGDt2rK6J6JdffsHY2JhvvvmGpKQkJk2aRHBwcLlpr/38/HTXTk1N5Y033qBTp06sWrWK7du306dPH4KDg/nuu++IiYlh7dq1ODk5ldn33HPP3fbvcae03R999BFvv/02W7Zs0WU8feKJJ1iyZAn5+fkYGRlx7NixWlnhTW/B4PDhw0RHRxMUFERUVBSBgYEEBQXpXl+2bBlTpkxh8ODBvP3228THxwPQo0cPPvroI72USZlwJnMMhKhvI0aM4Ndff6VLly788ccfbNmyhZycHN555x1Wr15NZmYmXl5e5Z4bFRWlS972wAMPsH//fgBMTU2ZMGEChoaGpKWllZv2GpSaSGk/hKOjI8bGxrpjb017faMWLVqwYsUK8vLySE5OZuTIkZw8eZKuXbuiVqtp3bo1ixcv5tdffy2zLzY29rZ/ixvTdn/66aesX7+egoICzMzMuHLlCiYmJtja2gKwZs0aAPr3789ff/2Fvb093bt3x9jYuKI/eYX0FgxCQkJ0UdXDw4OMjAyys7OxsLCgpKSEo0eP8v777wOwYMECgDKdQ7UtPj2X+1rb6PV3CNGo3Dvujp/i9WXw4MF8/vnnDB8+nDZt2mBtbc2yZct48MEHGTduHDt37uTPP/8s99wbU1GXpn6Oi4vjyy+/ZNu2bZibm1eY///GlGwFBQW6690pLfbixYuZNm0affv2Zf369eTk5JSbfrq8fbemzC4vxXV5abvVanWZawE8/PDDrFu3DhcXl1pb60Bv7SUpKSm6BR0AbG1tdeldr1y5grm5OUuXLmXcuHGsXLlSd9z58+d59tlnGTdunK7jpzYUl2hJzMiTYaVCNAAWFhZ06NCBNWvWMHLkSOB62mqtVsuePXtum7ba3d1dNxrp0KFDunNtbW0xNzcnMjKSuLg4CgsLUavVNz14ATp37qw7LyEhAbVajZWVVYVlTk9Px83NjYKCAv766y8KCwvx8vLi2LFjFBUVkZKSwsyZM8vdZ2FhQWpqKlqtFo1GU+4H3/LSdtvY2FBcXExSUhJarZYZM2aQmZlJx44dSUpKIjw8nPvvv7+Sf/U7q7MO5BujrFar1bXVubi4MH36dP788086duzIrFmzGDZsGDExMUyaNIldu3bVShUoOSuPohKtjCQSooEYOXIkr732GitWrACUIaeLFi3CxcVF11lcOiz0RpMmTeI///kPv//+O+3btwegY8eOmJubExAQwH333UdAQABvv/02gYGBrFixAicnJ935w4cP5/Dhw0ycOJHCwkIWLlxYqfJOmDCBmTNn0qpVKyZOnMjChQvx9/dn9OjRTJgwAa1Wy0svvYSrq2uZfdbW1vTu3ZsxY8bg6elJx44dy1x/9OjRzJ07l507dzJ+/Hh27NjBjz/+yIIFC3R5ioYNG6YLXL6+vly9erXchXqqRasnH330kfbbb7/VbQ8cOFCblZWl1Wq12sLCQu2wYcN0r61bt067du3aMtcYM2aM9vLly7rtmJgYbfv27bUxMTFVLk98eo7Wfd4O7dHoK1U+VwghGpKSkhLt5MmTtZcuXarU8ZV5duqtmcjX15fg4GBAGevr4OCgG6ZlaGhIq1atuHTpku51d3d3fv75Z11WQY1GQ2pqaq0t99bSuhnhbw3Fx036DIQQjVdsbCxjxoyhd+/etG7dutauq7dmIh8fH7y8vAgICEClUrFgwQK2bt2KpaUlgwcPJjAwkHnz5qHVamnfvj0DBw4kJyeHOXPm6NoL33rrrVppIiplYdKkplUIIe5Crq6uuvkKtanJrXQmhBBNTWWenTL7SgghhAQDIYQQEgyEEEIgwUAIIQQSDIQQQtDIUlgXFxcDkJiYWM8lEUKIxqP0mVn6DC1PowoGpbmNxo8fX88lEUKIxkej0dx2olqjmmeQl5dHREQE9vb2N2UXFEIIcXvFxcVoNBq8vb0xNS0/jX+jCgZCCCH0QzqQhRBCNK4+g5q40xKcjZG+lwitS2fPnuX555/nqaeeYsKECSQkJPDaa69RXFyMvb097733Xq3mqNK3W+9n3rx5REZG0rx5cwCmTp1K//7967WMVfHuu+9y9OhRioqKmDFjBp07d27U7w+Uvac//vij0b5Hubm5zJs3j9TUVPLz83n++efx9PSs8nvUJIJBRUtwNlb6XCK0ruTk5LBo0SJ69eql2/fRRx/x5JNPMmzYMN5//31++OEHnnzyyXosZeWVdz8AL7/8MgMGDKinUlXfwYMHOXfuHEFBQaSlpfHII4/Qq1evRvv+QPn31LNnz0b7Hu3duxdvb2+mTZtGXFwcU6ZMwcfHp8rvUZNoJrrdEpyi/hkbG7Nu3TocHBx0+w4dOsSgQYMAGDBgACEhIfVVvCor734as/vvv59Vq1YBYGVlRW5ubqN+f6D8e7rTkMuGzt/fn2nTpgHKym2Ojo7Veo+aRDC40xKcjZm+lgitS4aGhmVGN+Tm5uqqtC1atGhU71V59wPwzTffMGnSJF566SWuXLlSDyWrHgMDA8zMzAD44Ycf6Nu3b6N+f6D8ezIwMGi071GpgIAA5syZQ2BgYLXeoybRTHSru2EAVZs2bfS2RGhDcje8V6NHj6Z58+Z07NiRtWvX8vHHH/Pmm2/Wd7GqZPfu3fzwww9s2LCBIUOG6PY35vfnxnuKiIho9O/Rli1bOHXqFK+++mqZZYYro0nUDBwcHEhJSdFtJycnY29vX48lqjlHR0f8/f1RqVS4ublhZ2dHUlJSfRerVpiZmZGXlwdAUlJSo29y6dWrl27N24EDB3L27Nl6LlHV7N+/n88//5x169ZhaWl5V7w/t95TY36PIiIiSEhIAJS1oIuLizE3N6/ye9QkgsGdluBsrPS5RGh96927t+792rVrF3369KnnEtXMCy+8QExMDKD0h5SOAGsMsrKyePfdd1mzZo1upE1jf3/Ku6fG/B4dOXKEDRs2AEqTeE5OTrXeoyYz6WzFihUcOXJEtwSnp6dnfRepRrKzs5kzZw6ZmZkUFhYya9Ys+vXrV9/FqrKIiAiWL19OXFwchoaGODo6smLFCubNm0d+fj7Ozs4sXboUIyOj+i5qpZR3PxMmTGDt2rU0a9YMMzMzli5dSosWLeq7qJUSFBTE6tWrcXd31+1btmwZr7/+eqN8f6D8e3r00Uf55ptvGuV7lJeXx/z580lISCAvL49Zs2bh7e3N3Llzq/QeNZlgIIQQ4vaaRDOREEKIO5NgIIQQQoKBEEIICQZCCCGQYCCEEIImOgNZiIrExsYycuRIvL29b9q/evVq3dj06li9ejU2NjZMmDChhiUUonZJMBDiNtzd3dm4cWN9F0OIOiHBQIgqmDdvHmZmZly4cIG0tDSWLl1Kp06d+Oqrr/j1118BGDRoENOnTycuLo558+ZRXFyMs7Mzy5cvB5T1DmbMmMGlS5eYP38+ffv2rc9bEgKQPgMhqqyoqIgvv/ySF198kU8++YSYmBi2bdvGpk2b2LRpE7/99huXL1/mgw8+4KmnnmLz5s04ODgQEREBQHp6OmvWrOH1119ny5Yt9Xw3QiikZiDEbVy8eJGJEyfqtkvTF/Tu3RuAe++9lxUrVnDq1Cm6du2KoaHy38nHx4fTp09z8uRJ5s+fD8Brr70GwL59+/Dx8QGUZINZWVl1dj9C3IkEAyFuo7w+g3nz5lFSUqLbVqlUqFSqm9IEFxYWolarMTAwKDd9cGnQEKIhkWYiIaro6NGjAISGhuLh4UHHjh05fvw4RUVFFBUVERYWRseOHfH29ubgwYMArFq1igMHDtRnsYW4I/mIIsRt3NpMBGBqaoqhoSEzZswgISGB9957D1dXV8aOHcuECRPQarU8/vjjuLi4MHv2bP7v//6PzZs307JlS2bNmqULJEI0NJK1VIgqmDdvHkOHDm2UC6cLcSfSTCSEEEJqBkIIIaRmIIQQAgkGQgghkGAghBACCQZCCCGQYCCEEAIJBkIIIYD/B5XcJhSNjNUDAAAAAElFTkSuQmCC\n"},"metadata":{}}]},{"cell_type":"code","source":["import matplotlib.pyplot as plt\n","\n","plt.plot(train_losses, label='Training Loss')\n","plt.plot(valid_losses, label='Validation Loss')\n","plt.xlabel('Epoch')\n","plt.ylabel('Loss')\n","plt.legend()\n","plt.show()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":276},"id":"pD7c38SR7_7X","executionInfo":{"status":"ok","timestamp":1678962083681,"user_tz":-540,"elapsed":500,"user":{"displayName":"HaJun Yoo","userId":"01231542744346053879"}},"outputId":"44f29fe1-39a0-4848-fa45-bab9d4a860f5"},"execution_count":27,"outputs":[{"output_type":"display_data","data":{"text/plain":["<Figure size 432x288 with 1 Axes>"],"image/png":"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\n"},"metadata":{}}]},{"cell_type":"code","source":["# Define the file path for the saved model\n","# save_path = '/content/drive/MyDrive/졸플/Audio/output_128/pytorch_cnn.pt'\n","save_path = '/content/drive/MyDrive/졸플/Audio/output_128/pytorch_resnet.pt'\n","\n","# Save the trained model\n","# torch.save(trained_model.state_dict(), save_path)\n","torch.save({\n","            'model_state_dict': trained_model.state_dict(),\n","            'optimizer_state_dict': optimizer.state_dict()\n","            }, save_path)"],"metadata":{"id":"mYRkbWX0cwXo","executionInfo":{"status":"ok","timestamp":1678961692707,"user_tz":-540,"elapsed":417,"user":{"displayName":"HaJun Yoo","userId":"01231542744346053879"}}},"execution_count":15,"outputs":[]},{"cell_type":"code","source":["# Define the path to the saved model\n","model_path = '/content/drive/MyDrive/졸플/Audio/output_128/pytorch_resnet.pt'\n","\n","# Load the saved model\n","checkpoint = torch.load(model_path)\n","res_model = ResNetModel(num_classes=6)\n","model.load_state_dict(checkpoint['model_state_dict'])\n","\n","# Define the device\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","# Move the model to the device\n","res_model.to(device)\n","\n","\n","# Create a validation data loader\n","val_loader = DataLoader(val_dataset, batch_size=batch_size)\n","\n","# Set the model to evaluation mode\n","res_model.eval()\n","\n","# Initialize the correct and total predictions counters\n","correct_predictions = 0\n","total_predictions = 0\n","\n","# Loop over the validation data loader\n","for inputs, labels in val_loader:\n","    # Move the inputs and labels to the device\n","    inputs = inputs.to(device)\n","    labels = labels.to(device)\n","\n","    # Compute the predicted outputs\n","    with torch.no_grad():\n","        outputs = res_model(inputs)\n","\n","    # Get the predicted labels\n","    _, predicted_labels = torch.max(outputs.data, 1)\n","\n","    # Update the counters\n","    total_predictions += labels.size(0)\n","    correct_predictions += (predicted_labels == labels).sum().item()\n","\n","# Compute the validation accuracy\n","val_accuracy = 100.0 * correct_predictions / total_predictions\n","\n","print(correct_predictions)\n","print(total_predictions)\n","print('Validation accuracy: %.2f %%' % val_accuracy)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"TaK97H488ZpN","executionInfo":{"status":"ok","timestamp":1678962362908,"user_tz":-540,"elapsed":1252,"user":{"displayName":"HaJun Yoo","userId":"01231542744346053879"}},"outputId":"7a0783b0-fb84-4df9-8f5c-179f3f1d4cd4"},"execution_count":31,"outputs":[{"output_type":"stream","name":"stdout","text":["245\n","1610\n","Validation accuracy: 15.22 %\n"]}]},{"cell_type":"markdown","source":["### Deep CNN "],"metadata":{"id":"OeST6-sJmWZX"}},{"cell_type":"code","source":["import torch.optim as optim\n","\n","# Instantiate the model\n","model = DeepCNNModel()\n","\n","# Define the loss function and optimizer\n","loss_func = nn.CrossEntropyLoss()\n","optimizer = optim.Adam(model.parameters(), lr=0.001)\n","\n","# Train the model\n","n_epochs = 30\n","early_stop = 15\n","progress_interval = 1\n","\n","\n","optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n","loss_func = nn.CrossEntropyLoss()\n","\n","trained_model, lowest_loss, train_losses, valid_losses, train_accs, valid_accs = train_model(model, train_loader, val_loader, optimizer, loss_func, early_stop, n_epochs, progress_interval, device)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6CalQr3zdmF8","executionInfo":{"status":"ok","timestamp":1678957118402,"user_tz":-540,"elapsed":403016,"user":{"displayName":"HaJun Yoo","userId":"01231542744346053879"}},"outputId":"59d4b445-662d-4a72-cf0b-17b581e6d845"},"execution_count":55,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch [1/30], Step [10/202], Train Loss: 13.5713, Train Acc: 15.31%\n","Epoch [1/30], Step [20/202], Train Loss: 8.1316, Train Acc: 22.03%\n","Epoch [1/30], Step [30/202], Train Loss: 6.0403, Train Acc: 25.21%\n","Epoch [1/30], Step [40/202], Train Loss: 4.9532, Train Acc: 26.17%\n","Epoch [1/30], Step [50/202], Train Loss: 4.3659, Train Acc: 26.88%\n","Epoch [1/30], Step [60/202], Train Loss: 3.9204, Train Acc: 27.86%\n","Epoch [1/30], Step [70/202], Train Loss: 3.5998, Train Acc: 28.39%\n","Epoch [1/30], Step [80/202], Train Loss: 3.3603, Train Acc: 28.91%\n","Epoch [1/30], Step [90/202], Train Loss: 3.1528, Train Acc: 29.55%\n","Epoch [1/30], Step [100/202], Train Loss: 2.9864, Train Acc: 29.97%\n","Epoch [1/30], Step [110/202], Train Loss: 2.8554, Train Acc: 30.20%\n","Epoch [1/30], Step [120/202], Train Loss: 2.7419, Train Acc: 30.42%\n","Epoch [1/30], Step [130/202], Train Loss: 2.6422, Train Acc: 31.01%\n","Epoch [1/30], Step [140/202], Train Loss: 2.5573, Train Acc: 31.56%\n","Epoch [1/30], Step [150/202], Train Loss: 2.4884, Train Acc: 32.04%\n","Epoch [1/30], Step [160/202], Train Loss: 2.4270, Train Acc: 32.44%\n","Epoch [1/30], Step [170/202], Train Loss: 2.3730, Train Acc: 32.57%\n","Epoch [1/30], Step [180/202], Train Loss: 2.3251, Train Acc: 33.06%\n","Epoch [1/30], Step [190/202], Train Loss: 2.2783, Train Acc: 33.42%\n","Epoch [1/30], Step [200/202], Train Loss: 2.2356, Train Acc: 33.88%\n","Epoch [1/30], Train Loss: 2.2293, Train Acc: 33.86%, Val Loss: 1.3580, Val Acc: 43.93%\n","Epoch [2/30], Step [10/202], Train Loss: 1.4333, Train Acc: 40.94%\n","Epoch [2/30], Step [20/202], Train Loss: 1.4325, Train Acc: 40.47%\n","Epoch [2/30], Step [30/202], Train Loss: 1.4171, Train Acc: 40.00%\n","Epoch [2/30], Step [40/202], Train Loss: 1.4009, Train Acc: 40.94%\n","Epoch [2/30], Step [50/202], Train Loss: 1.3830, Train Acc: 41.94%\n","Epoch [2/30], Step [60/202], Train Loss: 1.3777, Train Acc: 41.82%\n","Epoch [2/30], Step [70/202], Train Loss: 1.3819, Train Acc: 42.28%\n","Epoch [2/30], Step [80/202], Train Loss: 1.3598, Train Acc: 43.09%\n","Epoch [2/30], Step [90/202], Train Loss: 1.3546, Train Acc: 43.51%\n","Epoch [2/30], Step [100/202], Train Loss: 1.3314, Train Acc: 44.53%\n","Epoch [2/30], Step [110/202], Train Loss: 1.3259, Train Acc: 44.80%\n","Epoch [2/30], Step [120/202], Train Loss: 1.3121, Train Acc: 45.39%\n","Epoch [2/30], Step [130/202], Train Loss: 1.3166, Train Acc: 45.26%\n","Epoch [2/30], Step [140/202], Train Loss: 1.3070, Train Acc: 45.58%\n","Epoch [2/30], Step [150/202], Train Loss: 1.2939, Train Acc: 46.21%\n","Epoch [2/30], Step [160/202], Train Loss: 1.2932, Train Acc: 46.68%\n","Epoch [2/30], Step [170/202], Train Loss: 1.2907, Train Acc: 46.91%\n","Epoch [2/30], Step [180/202], Train Loss: 1.2895, Train Acc: 47.01%\n","Epoch [2/30], Step [190/202], Train Loss: 1.2925, Train Acc: 47.17%\n","Epoch [2/30], Step [200/202], Train Loss: 1.2885, Train Acc: 47.38%\n","Epoch [2/30], Train Loss: 1.2872, Train Acc: 47.48%, Val Loss: 1.1215, Val Acc: 57.27%\n","Epoch [3/30], Step [10/202], Train Loss: 1.2465, Train Acc: 52.81%\n","Epoch [3/30], Step [20/202], Train Loss: 1.2391, Train Acc: 52.34%\n","Epoch [3/30], Step [30/202], Train Loss: 1.2232, Train Acc: 51.46%\n","Epoch [3/30], Step [40/202], Train Loss: 1.1673, Train Acc: 54.37%\n","Epoch [3/30], Step [50/202], Train Loss: 1.1864, Train Acc: 53.12%\n","Epoch [3/30], Step [60/202], Train Loss: 1.1905, Train Acc: 52.55%\n","Epoch [3/30], Step [70/202], Train Loss: 1.1825, Train Acc: 52.81%\n","Epoch [3/30], Step [80/202], Train Loss: 1.1839, Train Acc: 53.01%\n","Epoch [3/30], Step [90/202], Train Loss: 1.1862, Train Acc: 53.19%\n","Epoch [3/30], Step [100/202], Train Loss: 1.1769, Train Acc: 53.37%\n","Epoch [3/30], Step [110/202], Train Loss: 1.1705, Train Acc: 53.30%\n","Epoch [3/30], Step [120/202], Train Loss: 1.1731, Train Acc: 53.18%\n","Epoch [3/30], Step [130/202], Train Loss: 1.1632, Train Acc: 53.80%\n","Epoch [3/30], Step [140/202], Train Loss: 1.1639, Train Acc: 53.82%\n","Epoch [3/30], Step [150/202], Train Loss: 1.1583, Train Acc: 54.27%\n","Epoch [3/30], Step [160/202], Train Loss: 1.1513, Train Acc: 54.59%\n","Epoch [3/30], Step [170/202], Train Loss: 1.1453, Train Acc: 54.72%\n","Epoch [3/30], Step [180/202], Train Loss: 1.1377, Train Acc: 54.91%\n","Epoch [3/30], Step [190/202], Train Loss: 1.1358, Train Acc: 54.93%\n","Epoch [3/30], Step [200/202], Train Loss: 1.1290, Train Acc: 55.22%\n","Epoch [3/30], Train Loss: 1.1254, Train Acc: 55.28%, Val Loss: 0.9425, Val Acc: 64.62%\n","Epoch [4/30], Step [10/202], Train Loss: 1.0837, Train Acc: 55.62%\n","Epoch [4/30], Step [20/202], Train Loss: 1.0219, Train Acc: 58.59%\n","Epoch [4/30], Step [30/202], Train Loss: 0.9968, Train Acc: 60.10%\n","Epoch [4/30], Step [40/202], Train Loss: 0.9819, Train Acc: 61.09%\n","Epoch [4/30], Step [50/202], Train Loss: 1.0183, Train Acc: 59.94%\n","Epoch [4/30], Step [60/202], Train Loss: 1.0286, Train Acc: 59.58%\n","Epoch [4/30], Step [70/202], Train Loss: 1.0137, Train Acc: 59.96%\n","Epoch [4/30], Step [80/202], Train Loss: 1.0065, Train Acc: 60.31%\n","Epoch [4/30], Step [90/202], Train Loss: 1.0050, Train Acc: 60.14%\n","Epoch [4/30], Step [100/202], Train Loss: 0.9947, Train Acc: 60.56%\n","Epoch [4/30], Step [110/202], Train Loss: 0.9922, Train Acc: 60.62%\n","Epoch [4/30], Step [120/202], Train Loss: 0.9895, Train Acc: 60.73%\n","Epoch [4/30], Step [130/202], Train Loss: 0.9891, Train Acc: 60.94%\n","Epoch [4/30], Step [140/202], Train Loss: 0.9935, Train Acc: 60.89%\n","Epoch [4/30], Step [150/202], Train Loss: 0.9877, Train Acc: 61.02%\n","Epoch [4/30], Step [160/202], Train Loss: 0.9840, Train Acc: 61.31%\n","Epoch [4/30], Step [170/202], Train Loss: 0.9812, Train Acc: 61.60%\n","Epoch [4/30], Step [180/202], Train Loss: 0.9803, Train Acc: 61.86%\n","Epoch [4/30], Step [190/202], Train Loss: 0.9847, Train Acc: 61.64%\n","Epoch [4/30], Step [200/202], Train Loss: 0.9829, Train Acc: 61.69%\n","Epoch [4/30], Train Loss: 0.9834, Train Acc: 61.68%, Val Loss: 0.8494, Val Acc: 67.23%\n","Epoch [5/30], Step [10/202], Train Loss: 0.8819, Train Acc: 66.56%\n","Epoch [5/30], Step [20/202], Train Loss: 0.9312, Train Acc: 64.69%\n","Epoch [5/30], Step [30/202], Train Loss: 0.9452, Train Acc: 63.33%\n","Epoch [5/30], Step [40/202], Train Loss: 0.9475, Train Acc: 62.81%\n","Epoch [5/30], Step [50/202], Train Loss: 0.9208, Train Acc: 63.69%\n","Epoch [5/30], Step [60/202], Train Loss: 0.9241, Train Acc: 63.75%\n","Epoch [5/30], Step [70/202], Train Loss: 0.9278, Train Acc: 63.84%\n","Epoch [5/30], Step [80/202], Train Loss: 0.9353, Train Acc: 63.63%\n","Epoch [5/30], Step [90/202], Train Loss: 0.9311, Train Acc: 63.44%\n","Epoch [5/30], Step [100/202], Train Loss: 0.9309, Train Acc: 63.59%\n","Epoch [5/30], Step [110/202], Train Loss: 0.9304, Train Acc: 63.66%\n","Epoch [5/30], Step [120/202], Train Loss: 0.9203, Train Acc: 63.85%\n","Epoch [5/30], Step [130/202], Train Loss: 0.9146, Train Acc: 63.89%\n","Epoch [5/30], Step [140/202], Train Loss: 0.9076, Train Acc: 63.95%\n","Epoch [5/30], Step [150/202], Train Loss: 0.9089, Train Acc: 64.10%\n","Epoch [5/30], Step [160/202], Train Loss: 0.9092, Train Acc: 64.02%\n","Epoch [5/30], Step [170/202], Train Loss: 0.9107, Train Acc: 64.12%\n","Epoch [5/30], Step [180/202], Train Loss: 0.9041, Train Acc: 64.46%\n","Epoch [5/30], Step [190/202], Train Loss: 0.9017, Train Acc: 64.54%\n","Epoch [5/30], Step [200/202], Train Loss: 0.8923, Train Acc: 64.69%\n","Epoch [5/30], Train Loss: 0.8920, Train Acc: 64.65%, Val Loss: 0.7083, Val Acc: 73.06%\n","Epoch [6/30], Step [10/202], Train Loss: 0.8510, Train Acc: 70.62%\n","Epoch [6/30], Step [20/202], Train Loss: 0.8051, Train Acc: 69.84%\n","Epoch [6/30], Step [30/202], Train Loss: 0.8091, Train Acc: 70.21%\n","Epoch [6/30], Step [40/202], Train Loss: 0.7986, Train Acc: 69.53%\n","Epoch [6/30], Step [50/202], Train Loss: 0.8192, Train Acc: 68.75%\n","Epoch [6/30], Step [60/202], Train Loss: 0.8148, Train Acc: 68.65%\n","Epoch [6/30], Step [70/202], Train Loss: 0.8162, Train Acc: 68.53%\n","Epoch [6/30], Step [80/202], Train Loss: 0.8203, Train Acc: 68.36%\n","Epoch [6/30], Step [90/202], Train Loss: 0.8289, Train Acc: 68.06%\n","Epoch [6/30], Step [100/202], Train Loss: 0.8225, Train Acc: 68.16%\n","Epoch [6/30], Step [110/202], Train Loss: 0.8374, Train Acc: 68.12%\n","Epoch [6/30], Step [120/202], Train Loss: 0.8346, Train Acc: 68.10%\n","Epoch [6/30], Step [130/202], Train Loss: 0.8331, Train Acc: 68.22%\n","Epoch [6/30], Step [140/202], Train Loss: 0.8296, Train Acc: 68.33%\n","Epoch [6/30], Step [150/202], Train Loss: 0.8320, Train Acc: 68.38%\n","Epoch [6/30], Step [160/202], Train Loss: 0.8316, Train Acc: 68.34%\n","Epoch [6/30], Step [170/202], Train Loss: 0.8266, Train Acc: 68.53%\n","Epoch [6/30], Step [180/202], Train Loss: 0.8304, Train Acc: 68.18%\n","Epoch [6/30], Step [190/202], Train Loss: 0.8313, Train Acc: 68.17%\n","Epoch [6/30], Step [200/202], Train Loss: 0.8334, Train Acc: 68.19%\n","Epoch [6/30], Train Loss: 0.8349, Train Acc: 68.07%, Val Loss: 0.6861, Val Acc: 74.13%\n","Epoch [7/30], Step [10/202], Train Loss: 0.6151, Train Acc: 77.81%\n","Epoch [7/30], Step [20/202], Train Loss: 0.7385, Train Acc: 72.97%\n","Epoch [7/30], Step [30/202], Train Loss: 0.7602, Train Acc: 71.35%\n","Epoch [7/30], Step [40/202], Train Loss: 0.7855, Train Acc: 70.55%\n","Epoch [7/30], Step [50/202], Train Loss: 0.7878, Train Acc: 71.00%\n","Epoch [7/30], Step [60/202], Train Loss: 0.7810, Train Acc: 71.04%\n","Epoch [7/30], Step [70/202], Train Loss: 0.7786, Train Acc: 70.76%\n","Epoch [7/30], Step [80/202], Train Loss: 0.7893, Train Acc: 70.62%\n","Epoch [7/30], Step [90/202], Train Loss: 0.7900, Train Acc: 70.62%\n","Epoch [7/30], Step [100/202], Train Loss: 0.7941, Train Acc: 70.12%\n","Epoch [7/30], Step [110/202], Train Loss: 0.7932, Train Acc: 70.34%\n","Epoch [7/30], Step [120/202], Train Loss: 0.7963, Train Acc: 70.00%\n","Epoch [7/30], Step [130/202], Train Loss: 0.8019, Train Acc: 69.88%\n","Epoch [7/30], Step [140/202], Train Loss: 0.7938, Train Acc: 70.22%\n","Epoch [7/30], Step [150/202], Train Loss: 0.7868, Train Acc: 70.46%\n","Epoch [7/30], Step [160/202], Train Loss: 0.7785, Train Acc: 70.72%\n","Epoch [7/30], Step [170/202], Train Loss: 0.7740, Train Acc: 70.92%\n","Epoch [7/30], Step [180/202], Train Loss: 0.7764, Train Acc: 70.73%\n","Epoch [7/30], Step [190/202], Train Loss: 0.7748, Train Acc: 70.79%\n","Epoch [7/30], Step [200/202], Train Loss: 0.7729, Train Acc: 70.78%\n","Epoch [7/30], Train Loss: 0.7710, Train Acc: 70.85%, Val Loss: 0.6179, Val Acc: 76.40%\n","Epoch [8/30], Step [10/202], Train Loss: 0.6731, Train Acc: 72.81%\n","Epoch [8/30], Step [20/202], Train Loss: 0.6934, Train Acc: 71.88%\n","Epoch [8/30], Step [30/202], Train Loss: 0.7362, Train Acc: 70.73%\n","Epoch [8/30], Step [40/202], Train Loss: 0.7493, Train Acc: 70.08%\n","Epoch [8/30], Step [50/202], Train Loss: 0.7436, Train Acc: 70.62%\n","Epoch [8/30], Step [60/202], Train Loss: 0.7473, Train Acc: 70.62%\n","Epoch [8/30], Step [70/202], Train Loss: 0.7384, Train Acc: 71.16%\n","Epoch [8/30], Step [80/202], Train Loss: 0.7353, Train Acc: 71.48%\n","Epoch [8/30], Step [90/202], Train Loss: 0.7328, Train Acc: 71.98%\n","Epoch [8/30], Step [100/202], Train Loss: 0.7352, Train Acc: 71.88%\n","Epoch [8/30], Step [110/202], Train Loss: 0.7340, Train Acc: 71.93%\n","Epoch [8/30], Step [120/202], Train Loss: 0.7318, Train Acc: 71.93%\n","Epoch [8/30], Step [130/202], Train Loss: 0.7284, Train Acc: 72.14%\n","Epoch [8/30], Step [140/202], Train Loss: 0.7242, Train Acc: 72.28%\n","Epoch [8/30], Step [150/202], Train Loss: 0.7188, Train Acc: 72.48%\n","Epoch [8/30], Step [160/202], Train Loss: 0.7277, Train Acc: 72.46%\n","Epoch [8/30], Step [170/202], Train Loss: 0.7263, Train Acc: 72.56%\n","Epoch [8/30], Step [180/202], Train Loss: 0.7228, Train Acc: 72.66%\n","Epoch [8/30], Step [190/202], Train Loss: 0.7191, Train Acc: 72.81%\n","Epoch [8/30], Step [200/202], Train Loss: 0.7243, Train Acc: 72.69%\n","Epoch [8/30], Train Loss: 0.7293, Train Acc: 72.51%, Val Loss: 0.6507, Val Acc: 72.23%\n","Epoch [9/30], Step [10/202], Train Loss: 0.8909, Train Acc: 67.19%\n","Epoch [9/30], Step [20/202], Train Loss: 0.8656, Train Acc: 67.50%\n","Epoch [9/30], Step [30/202], Train Loss: 0.8263, Train Acc: 68.85%\n","Epoch [9/30], Step [40/202], Train Loss: 0.8147, Train Acc: 67.81%\n","Epoch [9/30], Step [50/202], Train Loss: 0.7969, Train Acc: 69.00%\n","Epoch [9/30], Step [60/202], Train Loss: 0.7737, Train Acc: 69.84%\n","Epoch [9/30], Step [70/202], Train Loss: 0.7615, Train Acc: 70.45%\n","Epoch [9/30], Step [80/202], Train Loss: 0.7427, Train Acc: 71.56%\n","Epoch [9/30], Step [90/202], Train Loss: 0.7304, Train Acc: 72.12%\n","Epoch [9/30], Step [100/202], Train Loss: 0.7315, Train Acc: 72.34%\n","Epoch [9/30], Step [110/202], Train Loss: 0.7173, Train Acc: 72.95%\n","Epoch [9/30], Step [120/202], Train Loss: 0.7121, Train Acc: 73.28%\n","Epoch [9/30], Step [130/202], Train Loss: 0.7071, Train Acc: 73.39%\n","Epoch [9/30], Step [140/202], Train Loss: 0.7067, Train Acc: 73.26%\n","Epoch [9/30], Step [150/202], Train Loss: 0.7055, Train Acc: 73.21%\n","Epoch [9/30], Step [160/202], Train Loss: 0.7024, Train Acc: 73.30%\n","Epoch [9/30], Step [170/202], Train Loss: 0.6992, Train Acc: 73.42%\n","Epoch [9/30], Step [180/202], Train Loss: 0.6953, Train Acc: 73.68%\n","Epoch [9/30], Step [190/202], Train Loss: 0.6986, Train Acc: 73.52%\n","Epoch [9/30], Step [200/202], Train Loss: 0.6992, Train Acc: 73.36%\n","Epoch [9/30], Train Loss: 0.6986, Train Acc: 73.48%, Val Loss: 0.5231, Val Acc: 80.62%\n","Epoch [10/30], Step [10/202], Train Loss: 0.6829, Train Acc: 73.44%\n","Epoch [10/30], Step [20/202], Train Loss: 0.6598, Train Acc: 76.09%\n","Epoch [10/30], Step [30/202], Train Loss: 0.6661, Train Acc: 76.25%\n","Epoch [10/30], Step [40/202], Train Loss: 0.6436, Train Acc: 76.48%\n","Epoch [10/30], Step [50/202], Train Loss: 0.6383, Train Acc: 76.31%\n","Epoch [10/30], Step [60/202], Train Loss: 0.6412, Train Acc: 75.94%\n","Epoch [10/30], Step [70/202], Train Loss: 0.6158, Train Acc: 77.14%\n","Epoch [10/30], Step [80/202], Train Loss: 0.6283, Train Acc: 76.88%\n","Epoch [10/30], Step [90/202], Train Loss: 0.6315, Train Acc: 76.74%\n","Epoch [10/30], Step [100/202], Train Loss: 0.6401, Train Acc: 76.41%\n","Epoch [10/30], Step [110/202], Train Loss: 0.6348, Train Acc: 76.56%\n","Epoch [10/30], Step [120/202], Train Loss: 0.6312, Train Acc: 76.69%\n","Epoch [10/30], Step [130/202], Train Loss: 0.6312, Train Acc: 76.78%\n","Epoch [10/30], Step [140/202], Train Loss: 0.6246, Train Acc: 76.96%\n","Epoch [10/30], Step [150/202], Train Loss: 0.6284, Train Acc: 76.79%\n","Epoch [10/30], Step [160/202], Train Loss: 0.6276, Train Acc: 76.89%\n","Epoch [10/30], Step [170/202], Train Loss: 0.6294, Train Acc: 76.91%\n","Epoch [10/30], Step [180/202], Train Loss: 0.6259, Train Acc: 77.07%\n","Epoch [10/30], Step [190/202], Train Loss: 0.6311, Train Acc: 76.79%\n","Epoch [10/30], Step [200/202], Train Loss: 0.6291, Train Acc: 76.70%\n","Epoch [10/30], Train Loss: 0.6272, Train Acc: 76.69%, Val Loss: 0.4888, Val Acc: 81.12%\n","Epoch [11/30], Step [10/202], Train Loss: 0.5414, Train Acc: 80.31%\n","Epoch [11/30], Step [20/202], Train Loss: 0.5451, Train Acc: 79.06%\n","Epoch [11/30], Step [30/202], Train Loss: 0.5666, Train Acc: 78.33%\n","Epoch [11/30], Step [40/202], Train Loss: 0.5690, Train Acc: 77.73%\n","Epoch [11/30], Step [50/202], Train Loss: 0.5597, Train Acc: 78.50%\n","Epoch [11/30], Step [60/202], Train Loss: 0.5558, Train Acc: 78.39%\n","Epoch [11/30], Step [70/202], Train Loss: 0.5630, Train Acc: 77.99%\n","Epoch [11/30], Step [80/202], Train Loss: 0.5623, Train Acc: 78.05%\n","Epoch [11/30], Step [90/202], Train Loss: 0.5688, Train Acc: 77.33%\n","Epoch [11/30], Step [100/202], Train Loss: 0.5681, Train Acc: 77.31%\n","Epoch [11/30], Step [110/202], Train Loss: 0.5651, Train Acc: 77.47%\n","Epoch [11/30], Step [120/202], Train Loss: 0.5688, Train Acc: 77.76%\n","Epoch [11/30], Step [130/202], Train Loss: 0.5667, Train Acc: 77.91%\n","Epoch [11/30], Step [140/202], Train Loss: 0.5676, Train Acc: 77.90%\n","Epoch [11/30], Step [150/202], Train Loss: 0.5710, Train Acc: 77.83%\n","Epoch [11/30], Step [160/202], Train Loss: 0.5722, Train Acc: 77.83%\n","Epoch [11/30], Step [170/202], Train Loss: 0.5737, Train Acc: 77.85%\n","Epoch [11/30], Step [180/202], Train Loss: 0.5747, Train Acc: 77.78%\n","Epoch [11/30], Step [190/202], Train Loss: 0.5729, Train Acc: 77.89%\n","Epoch [11/30], Step [200/202], Train Loss: 0.5737, Train Acc: 77.77%\n","Epoch [11/30], Train Loss: 0.5711, Train Acc: 77.80%, Val Loss: 0.4968, Val Acc: 81.91%\n","Epoch [12/30], Step [10/202], Train Loss: 0.5315, Train Acc: 77.81%\n","Epoch [12/30], Step [20/202], Train Loss: 0.5493, Train Acc: 78.91%\n","Epoch [12/30], Step [30/202], Train Loss: 0.5140, Train Acc: 80.21%\n","Epoch [12/30], Step [40/202], Train Loss: 0.5407, Train Acc: 79.06%\n","Epoch [12/30], Step [50/202], Train Loss: 0.5444, Train Acc: 78.94%\n","Epoch [12/30], Step [60/202], Train Loss: 0.5386, Train Acc: 78.85%\n","Epoch [12/30], Step [70/202], Train Loss: 0.5349, Train Acc: 78.97%\n","Epoch [12/30], Step [80/202], Train Loss: 0.5350, Train Acc: 78.91%\n","Epoch [12/30], Step [90/202], Train Loss: 0.5370, Train Acc: 78.78%\n","Epoch [12/30], Step [100/202], Train Loss: 0.5375, Train Acc: 78.59%\n","Epoch [12/30], Step [110/202], Train Loss: 0.5381, Train Acc: 78.64%\n","Epoch [12/30], Step [120/202], Train Loss: 0.5408, Train Acc: 78.65%\n","Epoch [12/30], Step [130/202], Train Loss: 0.5465, Train Acc: 78.53%\n","Epoch [12/30], Step [140/202], Train Loss: 0.5544, Train Acc: 78.50%\n","Epoch [12/30], Step [150/202], Train Loss: 0.5575, Train Acc: 78.44%\n","Epoch [12/30], Step [160/202], Train Loss: 0.5595, Train Acc: 78.26%\n","Epoch [12/30], Step [170/202], Train Loss: 0.5603, Train Acc: 78.27%\n","Epoch [12/30], Step [180/202], Train Loss: 0.5571, Train Acc: 78.35%\n","Epoch [12/30], Step [190/202], Train Loss: 0.5624, Train Acc: 78.21%\n","Epoch [12/30], Step [200/202], Train Loss: 0.5618, Train Acc: 78.27%\n","Epoch [12/30], Train Loss: 0.5636, Train Acc: 78.30%, Val Loss: 0.4575, Val Acc: 82.46%\n","Epoch [13/30], Step [10/202], Train Loss: 0.5087, Train Acc: 81.25%\n","Epoch [13/30], Step [20/202], Train Loss: 0.5187, Train Acc: 80.16%\n","Epoch [13/30], Step [30/202], Train Loss: 0.5384, Train Acc: 79.27%\n","Epoch [13/30], Step [40/202], Train Loss: 0.5171, Train Acc: 80.23%\n","Epoch [13/30], Step [50/202], Train Loss: 0.5246, Train Acc: 79.94%\n","Epoch [13/30], Step [60/202], Train Loss: 0.5182, Train Acc: 80.05%\n","Epoch [13/30], Step [70/202], Train Loss: 0.5249, Train Acc: 79.87%\n","Epoch [13/30], Step [80/202], Train Loss: 0.5174, Train Acc: 80.04%\n","Epoch [13/30], Step [90/202], Train Loss: 0.5230, Train Acc: 79.97%\n","Epoch [13/30], Step [100/202], Train Loss: 0.5182, Train Acc: 80.38%\n","Epoch [13/30], Step [110/202], Train Loss: 0.5104, Train Acc: 80.57%\n","Epoch [13/30], Step [120/202], Train Loss: 0.5160, Train Acc: 80.36%\n","Epoch [13/30], Step [130/202], Train Loss: 0.5245, Train Acc: 80.02%\n","Epoch [13/30], Step [140/202], Train Loss: 0.5206, Train Acc: 80.25%\n","Epoch [13/30], Step [150/202], Train Loss: 0.5175, Train Acc: 80.15%\n","Epoch [13/30], Step [160/202], Train Loss: 0.5128, Train Acc: 80.33%\n","Epoch [13/30], Step [170/202], Train Loss: 0.5112, Train Acc: 80.55%\n","Epoch [13/30], Step [180/202], Train Loss: 0.5102, Train Acc: 80.57%\n","Epoch [13/30], Step [190/202], Train Loss: 0.5136, Train Acc: 80.59%\n","Epoch [13/30], Step [200/202], Train Loss: 0.5152, Train Acc: 80.64%\n","Epoch [13/30], Train Loss: 0.5116, Train Acc: 80.79%, Val Loss: 0.4379, Val Acc: 83.44%\n","Epoch [14/30], Step [10/202], Train Loss: 0.4436, Train Acc: 83.44%\n","Epoch [14/30], Step [20/202], Train Loss: 0.4482, Train Acc: 83.12%\n","Epoch [14/30], Step [30/202], Train Loss: 0.4670, Train Acc: 82.92%\n","Epoch [14/30], Step [40/202], Train Loss: 0.4468, Train Acc: 83.91%\n","Epoch [14/30], Step [50/202], Train Loss: 0.4355, Train Acc: 83.75%\n","Epoch [14/30], Step [60/202], Train Loss: 0.4353, Train Acc: 83.39%\n","Epoch [14/30], Step [70/202], Train Loss: 0.4387, Train Acc: 83.62%\n","Epoch [14/30], Step [80/202], Train Loss: 0.4383, Train Acc: 83.32%\n","Epoch [14/30], Step [90/202], Train Loss: 0.4377, Train Acc: 83.16%\n","Epoch [14/30], Step [100/202], Train Loss: 0.4423, Train Acc: 83.31%\n","Epoch [14/30], Step [110/202], Train Loss: 0.4375, Train Acc: 83.35%\n","Epoch [14/30], Step [120/202], Train Loss: 0.4448, Train Acc: 82.89%\n","Epoch [14/30], Step [130/202], Train Loss: 0.4486, Train Acc: 82.72%\n","Epoch [14/30], Step [140/202], Train Loss: 0.4527, Train Acc: 82.39%\n","Epoch [14/30], Step [150/202], Train Loss: 0.4582, Train Acc: 82.23%\n","Epoch [14/30], Step [160/202], Train Loss: 0.4600, Train Acc: 82.30%\n","Epoch [14/30], Step [170/202], Train Loss: 0.4627, Train Acc: 82.15%\n","Epoch [14/30], Step [180/202], Train Loss: 0.4609, Train Acc: 82.43%\n","Epoch [14/30], Step [190/202], Train Loss: 0.4645, Train Acc: 82.20%\n","Epoch [14/30], Step [200/202], Train Loss: 0.4615, Train Acc: 82.36%\n","Epoch [14/30], Train Loss: 0.4612, Train Acc: 82.33%, Val Loss: 0.4431, Val Acc: 83.39%\n","Epoch [15/30], Step [10/202], Train Loss: 0.4379, Train Acc: 80.00%\n","Epoch [15/30], Step [20/202], Train Loss: 0.4276, Train Acc: 82.34%\n","Epoch [15/30], Step [30/202], Train Loss: 0.4218, Train Acc: 83.33%\n","Epoch [15/30], Step [40/202], Train Loss: 0.3944, Train Acc: 85.08%\n","Epoch [15/30], Step [50/202], Train Loss: 0.4093, Train Acc: 84.50%\n","Epoch [15/30], Step [60/202], Train Loss: 0.4114, Train Acc: 84.53%\n","Epoch [15/30], Step [70/202], Train Loss: 0.4144, Train Acc: 84.55%\n","Epoch [15/30], Step [80/202], Train Loss: 0.4140, Train Acc: 84.26%\n","Epoch [15/30], Step [90/202], Train Loss: 0.4199, Train Acc: 84.31%\n","Epoch [15/30], Step [100/202], Train Loss: 0.4363, Train Acc: 83.81%\n","Epoch [15/30], Step [110/202], Train Loss: 0.4354, Train Acc: 83.72%\n","Epoch [15/30], Step [120/202], Train Loss: 0.4420, Train Acc: 83.36%\n","Epoch [15/30], Step [130/202], Train Loss: 0.4445, Train Acc: 83.15%\n","Epoch [15/30], Step [140/202], Train Loss: 0.4451, Train Acc: 83.30%\n","Epoch [15/30], Step [150/202], Train Loss: 0.4463, Train Acc: 83.17%\n","Epoch [15/30], Step [160/202], Train Loss: 0.4465, Train Acc: 83.20%\n","Epoch [15/30], Step [170/202], Train Loss: 0.4509, Train Acc: 83.05%\n","Epoch [15/30], Step [180/202], Train Loss: 0.4551, Train Acc: 82.86%\n","Epoch [15/30], Step [190/202], Train Loss: 0.4572, Train Acc: 82.75%\n","Epoch [15/30], Step [200/202], Train Loss: 0.4608, Train Acc: 82.62%\n","Epoch [15/30], Train Loss: 0.4615, Train Acc: 82.44%, Val Loss: 0.3859, Val Acc: 86.14%\n","Epoch [16/30], Step [10/202], Train Loss: 0.3915, Train Acc: 85.94%\n","Epoch [16/30], Step [20/202], Train Loss: 0.4290, Train Acc: 83.91%\n","Epoch [16/30], Step [30/202], Train Loss: 0.4263, Train Acc: 84.27%\n","Epoch [16/30], Step [40/202], Train Loss: 0.4407, Train Acc: 83.59%\n","Epoch [16/30], Step [50/202], Train Loss: 0.4247, Train Acc: 84.44%\n","Epoch [16/30], Step [60/202], Train Loss: 0.4230, Train Acc: 84.22%\n","Epoch [16/30], Step [70/202], Train Loss: 0.4084, Train Acc: 84.78%\n","Epoch [16/30], Step [80/202], Train Loss: 0.4119, Train Acc: 84.41%\n","Epoch [16/30], Step [90/202], Train Loss: 0.4148, Train Acc: 84.44%\n","Epoch [16/30], Step [100/202], Train Loss: 0.4242, Train Acc: 84.22%\n","Epoch [16/30], Step [110/202], Train Loss: 0.4252, Train Acc: 84.09%\n","Epoch [16/30], Step [120/202], Train Loss: 0.4249, Train Acc: 84.06%\n","Epoch [16/30], Step [130/202], Train Loss: 0.4242, Train Acc: 84.13%\n","Epoch [16/30], Step [140/202], Train Loss: 0.4213, Train Acc: 84.11%\n","Epoch [16/30], Step [150/202], Train Loss: 0.4195, Train Acc: 84.21%\n","Epoch [16/30], Step [160/202], Train Loss: 0.4169, Train Acc: 84.14%\n","Epoch [16/30], Step [170/202], Train Loss: 0.4137, Train Acc: 84.23%\n","Epoch [16/30], Step [180/202], Train Loss: 0.4151, Train Acc: 84.03%\n","Epoch [16/30], Step [190/202], Train Loss: 0.4139, Train Acc: 84.03%\n","Epoch [16/30], Step [200/202], Train Loss: 0.4146, Train Acc: 83.95%\n","Epoch [16/30], Train Loss: 0.4133, Train Acc: 84.03%, Val Loss: 0.3942, Val Acc: 86.26%\n","Epoch [17/30], Step [10/202], Train Loss: 0.4525, Train Acc: 83.12%\n","Epoch [17/30], Step [20/202], Train Loss: 0.4494, Train Acc: 83.28%\n","Epoch [17/30], Step [30/202], Train Loss: 0.4349, Train Acc: 83.75%\n","Epoch [17/30], Step [40/202], Train Loss: 0.4237, Train Acc: 84.22%\n","Epoch [17/30], Step [50/202], Train Loss: 0.4378, Train Acc: 83.69%\n","Epoch [17/30], Step [60/202], Train Loss: 0.4253, Train Acc: 84.06%\n","Epoch [17/30], Step [70/202], Train Loss: 0.4069, Train Acc: 84.73%\n","Epoch [17/30], Step [80/202], Train Loss: 0.4122, Train Acc: 84.41%\n","Epoch [17/30], Step [90/202], Train Loss: 0.4128, Train Acc: 84.34%\n","Epoch [17/30], Step [100/202], Train Loss: 0.4099, Train Acc: 84.66%\n","Epoch [17/30], Step [110/202], Train Loss: 0.4079, Train Acc: 84.86%\n","Epoch [17/30], Step [120/202], Train Loss: 0.4000, Train Acc: 85.00%\n","Epoch [17/30], Step [130/202], Train Loss: 0.4035, Train Acc: 84.86%\n","Epoch [17/30], Step [140/202], Train Loss: 0.4093, Train Acc: 84.75%\n","Epoch [17/30], Step [150/202], Train Loss: 0.4105, Train Acc: 84.62%\n","Epoch [17/30], Step [160/202], Train Loss: 0.4129, Train Acc: 84.57%\n","Epoch [17/30], Step [170/202], Train Loss: 0.4081, Train Acc: 84.72%\n","Epoch [17/30], Step [180/202], Train Loss: 0.4076, Train Acc: 84.81%\n","Epoch [17/30], Step [190/202], Train Loss: 0.4021, Train Acc: 84.98%\n","Epoch [17/30], Step [200/202], Train Loss: 0.4007, Train Acc: 85.00%\n","Epoch [17/30], Train Loss: 0.4003, Train Acc: 85.02%, Val Loss: 0.3586, Val Acc: 87.55%\n","Epoch [18/30], Step [10/202], Train Loss: 0.3723, Train Acc: 85.62%\n","Epoch [18/30], Step [20/202], Train Loss: 0.3854, Train Acc: 84.84%\n","Epoch [18/30], Step [30/202], Train Loss: 0.3574, Train Acc: 86.35%\n","Epoch [18/30], Step [40/202], Train Loss: 0.3440, Train Acc: 86.48%\n","Epoch [18/30], Step [50/202], Train Loss: 0.3321, Train Acc: 86.94%\n","Epoch [18/30], Step [60/202], Train Loss: 0.3428, Train Acc: 86.35%\n","Epoch [18/30], Step [70/202], Train Loss: 0.3416, Train Acc: 86.70%\n","Epoch [18/30], Step [80/202], Train Loss: 0.3441, Train Acc: 86.56%\n","Epoch [18/30], Step [90/202], Train Loss: 0.3483, Train Acc: 86.35%\n","Epoch [18/30], Step [100/202], Train Loss: 0.3558, Train Acc: 86.09%\n","Epoch [18/30], Step [110/202], Train Loss: 0.3613, Train Acc: 86.02%\n","Epoch [18/30], Step [120/202], Train Loss: 0.3649, Train Acc: 85.89%\n","Epoch [18/30], Step [130/202], Train Loss: 0.3647, Train Acc: 85.91%\n","Epoch [18/30], Step [140/202], Train Loss: 0.3611, Train Acc: 86.05%\n","Epoch [18/30], Step [150/202], Train Loss: 0.3693, Train Acc: 86.02%\n","Epoch [18/30], Step [160/202], Train Loss: 0.3671, Train Acc: 86.11%\n","Epoch [18/30], Step [170/202], Train Loss: 0.3696, Train Acc: 85.86%\n","Epoch [18/30], Step [180/202], Train Loss: 0.3722, Train Acc: 85.73%\n","Epoch [18/30], Step [190/202], Train Loss: 0.3734, Train Acc: 85.66%\n","Epoch [18/30], Step [200/202], Train Loss: 0.3707, Train Acc: 85.70%\n","Epoch [18/30], Train Loss: 0.3706, Train Acc: 85.75%, Val Loss: 0.3617, Val Acc: 87.13%\n","Epoch [19/30], Step [10/202], Train Loss: 0.2962, Train Acc: 89.06%\n","Epoch [19/30], Step [20/202], Train Loss: 0.3581, Train Acc: 87.50%\n","Epoch [19/30], Step [30/202], Train Loss: 0.3520, Train Acc: 87.81%\n","Epoch [19/30], Step [40/202], Train Loss: 0.3407, Train Acc: 87.73%\n","Epoch [19/30], Step [50/202], Train Loss: 0.3295, Train Acc: 88.00%\n","Epoch [19/30], Step [60/202], Train Loss: 0.3310, Train Acc: 87.81%\n","Epoch [19/30], Step [70/202], Train Loss: 0.3266, Train Acc: 87.90%\n","Epoch [19/30], Step [80/202], Train Loss: 0.3292, Train Acc: 87.73%\n","Epoch [19/30], Step [90/202], Train Loss: 0.3298, Train Acc: 87.43%\n","Epoch [19/30], Step [100/202], Train Loss: 0.3311, Train Acc: 87.38%\n","Epoch [19/30], Step [110/202], Train Loss: 0.3316, Train Acc: 87.13%\n","Epoch [19/30], Step [120/202], Train Loss: 0.3282, Train Acc: 87.11%\n","Epoch [19/30], Step [130/202], Train Loss: 0.3241, Train Acc: 87.26%\n","Epoch [19/30], Step [140/202], Train Loss: 0.3240, Train Acc: 87.30%\n","Epoch [19/30], Step [150/202], Train Loss: 0.3213, Train Acc: 87.46%\n","Epoch [19/30], Step [160/202], Train Loss: 0.3270, Train Acc: 87.46%\n","Epoch [19/30], Step [170/202], Train Loss: 0.3315, Train Acc: 87.35%\n","Epoch [19/30], Step [180/202], Train Loss: 0.3337, Train Acc: 87.26%\n","Epoch [19/30], Step [190/202], Train Loss: 0.3321, Train Acc: 87.29%\n","Epoch [19/30], Step [200/202], Train Loss: 0.3370, Train Acc: 87.16%\n","Epoch [19/30], Train Loss: 0.3378, Train Acc: 87.19%, Val Loss: 0.3393, Val Acc: 89.03%\n","Epoch [20/30], Step [10/202], Train Loss: 0.2868, Train Acc: 87.81%\n","Epoch [20/30], Step [20/202], Train Loss: 0.2822, Train Acc: 88.12%\n","Epoch [20/30], Step [30/202], Train Loss: 0.2917, Train Acc: 87.81%\n","Epoch [20/30], Step [40/202], Train Loss: 0.2943, Train Acc: 87.58%\n","Epoch [20/30], Step [50/202], Train Loss: 0.3015, Train Acc: 87.50%\n","Epoch [20/30], Step [60/202], Train Loss: 0.3099, Train Acc: 87.55%\n","Epoch [20/30], Step [70/202], Train Loss: 0.3195, Train Acc: 87.28%\n","Epoch [20/30], Step [80/202], Train Loss: 0.3168, Train Acc: 87.42%\n","Epoch [20/30], Step [90/202], Train Loss: 0.3193, Train Acc: 87.26%\n","Epoch [20/30], Step [100/202], Train Loss: 0.3221, Train Acc: 87.09%\n","Epoch [20/30], Step [110/202], Train Loss: 0.3253, Train Acc: 87.24%\n","Epoch [20/30], Step [120/202], Train Loss: 0.3253, Train Acc: 87.24%\n","Epoch [20/30], Step [130/202], Train Loss: 0.3276, Train Acc: 87.19%\n","Epoch [20/30], Step [140/202], Train Loss: 0.3229, Train Acc: 87.46%\n","Epoch [20/30], Step [150/202], Train Loss: 0.3263, Train Acc: 87.44%\n","Epoch [20/30], Step [160/202], Train Loss: 0.3251, Train Acc: 87.46%\n","Epoch [20/30], Step [170/202], Train Loss: 0.3238, Train Acc: 87.57%\n","Epoch [20/30], Step [180/202], Train Loss: 0.3209, Train Acc: 87.71%\n","Epoch [20/30], Step [190/202], Train Loss: 0.3205, Train Acc: 87.68%\n","Epoch [20/30], Step [200/202], Train Loss: 0.3180, Train Acc: 87.69%\n","Epoch [20/30], Train Loss: 0.3171, Train Acc: 87.62%, Val Loss: 0.3179, Val Acc: 89.22%\n","Epoch [21/30], Step [10/202], Train Loss: 0.2961, Train Acc: 90.31%\n","Epoch [21/30], Step [20/202], Train Loss: 0.2902, Train Acc: 89.38%\n","Epoch [21/30], Step [30/202], Train Loss: 0.3023, Train Acc: 89.69%\n","Epoch [21/30], Step [40/202], Train Loss: 0.2931, Train Acc: 89.22%\n","Epoch [21/30], Step [50/202], Train Loss: 0.2979, Train Acc: 89.31%\n","Epoch [21/30], Step [60/202], Train Loss: 0.2965, Train Acc: 89.01%\n","Epoch [21/30], Step [70/202], Train Loss: 0.2927, Train Acc: 89.02%\n","Epoch [21/30], Step [80/202], Train Loss: 0.2889, Train Acc: 89.02%\n","Epoch [21/30], Step [90/202], Train Loss: 0.2917, Train Acc: 88.75%\n","Epoch [21/30], Step [100/202], Train Loss: 0.2954, Train Acc: 88.62%\n","Epoch [21/30], Step [110/202], Train Loss: 0.2966, Train Acc: 88.49%\n","Epoch [21/30], Step [120/202], Train Loss: 0.2951, Train Acc: 88.57%\n","Epoch [21/30], Step [130/202], Train Loss: 0.2964, Train Acc: 88.51%\n","Epoch [21/30], Step [140/202], Train Loss: 0.3018, Train Acc: 88.42%\n","Epoch [21/30], Step [150/202], Train Loss: 0.3093, Train Acc: 87.98%\n","Epoch [21/30], Step [160/202], Train Loss: 0.3063, Train Acc: 88.01%\n","Epoch [21/30], Step [170/202], Train Loss: 0.3048, Train Acc: 88.14%\n","Epoch [21/30], Step [180/202], Train Loss: 0.3042, Train Acc: 88.18%\n","Epoch [21/30], Step [190/202], Train Loss: 0.3019, Train Acc: 88.34%\n","Epoch [21/30], Step [200/202], Train Loss: 0.3030, Train Acc: 88.28%\n","Epoch [21/30], Train Loss: 0.3030, Train Acc: 88.27%, Val Loss: 0.3084, Val Acc: 89.45%\n","Epoch [22/30], Step [10/202], Train Loss: 0.2697, Train Acc: 90.31%\n","Epoch [22/30], Step [20/202], Train Loss: 0.2770, Train Acc: 90.00%\n","Epoch [22/30], Step [30/202], Train Loss: 0.2650, Train Acc: 90.52%\n","Epoch [22/30], Step [40/202], Train Loss: 0.2677, Train Acc: 90.47%\n","Epoch [22/30], Step [50/202], Train Loss: 0.2799, Train Acc: 89.75%\n","Epoch [22/30], Step [60/202], Train Loss: 0.2797, Train Acc: 89.32%\n","Epoch [22/30], Step [70/202], Train Loss: 0.2801, Train Acc: 89.38%\n","Epoch [22/30], Step [80/202], Train Loss: 0.2849, Train Acc: 89.38%\n","Epoch [22/30], Step [90/202], Train Loss: 0.2848, Train Acc: 89.34%\n","Epoch [22/30], Step [100/202], Train Loss: 0.2870, Train Acc: 89.38%\n","Epoch [22/30], Step [110/202], Train Loss: 0.2837, Train Acc: 89.49%\n","Epoch [22/30], Step [120/202], Train Loss: 0.2824, Train Acc: 89.51%\n","Epoch [22/30], Step [130/202], Train Loss: 0.2826, Train Acc: 89.52%\n","Epoch [22/30], Step [140/202], Train Loss: 0.2816, Train Acc: 89.44%\n","Epoch [22/30], Step [150/202], Train Loss: 0.2833, Train Acc: 89.31%\n","Epoch [22/30], Step [160/202], Train Loss: 0.2812, Train Acc: 89.43%\n","Epoch [22/30], Step [170/202], Train Loss: 0.2782, Train Acc: 89.56%\n","Epoch [22/30], Step [180/202], Train Loss: 0.2784, Train Acc: 89.58%\n","Epoch [22/30], Step [190/202], Train Loss: 0.2781, Train Acc: 89.54%\n","Epoch [22/30], Step [200/202], Train Loss: 0.2809, Train Acc: 89.52%\n","Epoch [22/30], Train Loss: 0.2815, Train Acc: 89.42%, Val Loss: 0.2980, Val Acc: 89.88%\n","Epoch [23/30], Step [10/202], Train Loss: 0.3054, Train Acc: 86.56%\n","Epoch [23/30], Step [20/202], Train Loss: 0.2767, Train Acc: 88.91%\n","Epoch [23/30], Step [30/202], Train Loss: 0.2695, Train Acc: 89.58%\n","Epoch [23/30], Step [40/202], Train Loss: 0.2636, Train Acc: 89.69%\n","Epoch [23/30], Step [50/202], Train Loss: 0.2585, Train Acc: 89.88%\n","Epoch [23/30], Step [60/202], Train Loss: 0.2642, Train Acc: 89.84%\n","Epoch [23/30], Step [70/202], Train Loss: 0.2707, Train Acc: 89.69%\n","Epoch [23/30], Step [80/202], Train Loss: 0.2748, Train Acc: 89.41%\n","Epoch [23/30], Step [90/202], Train Loss: 0.2689, Train Acc: 89.62%\n","Epoch [23/30], Step [100/202], Train Loss: 0.2732, Train Acc: 89.34%\n","Epoch [23/30], Step [110/202], Train Loss: 0.2717, Train Acc: 89.40%\n","Epoch [23/30], Step [120/202], Train Loss: 0.2729, Train Acc: 89.35%\n","Epoch [23/30], Step [130/202], Train Loss: 0.2766, Train Acc: 89.18%\n","Epoch [23/30], Step [140/202], Train Loss: 0.2781, Train Acc: 89.17%\n","Epoch [23/30], Step [150/202], Train Loss: 0.2797, Train Acc: 89.06%\n","Epoch [23/30], Step [160/202], Train Loss: 0.2749, Train Acc: 89.30%\n","Epoch [23/30], Step [170/202], Train Loss: 0.2748, Train Acc: 89.25%\n","Epoch [23/30], Step [180/202], Train Loss: 0.2750, Train Acc: 89.17%\n","Epoch [23/30], Step [190/202], Train Loss: 0.2704, Train Acc: 89.34%\n","Epoch [23/30], Step [200/202], Train Loss: 0.2694, Train Acc: 89.42%\n","Epoch [23/30], Train Loss: 0.2674, Train Acc: 89.51%, Val Loss: 0.2891, Val Acc: 90.01%\n","Epoch [24/30], Step [10/202], Train Loss: 0.2096, Train Acc: 91.56%\n","Epoch [24/30], Step [20/202], Train Loss: 0.2635, Train Acc: 89.38%\n","Epoch [24/30], Step [30/202], Train Loss: 0.2572, Train Acc: 89.69%\n","Epoch [24/30], Step [40/202], Train Loss: 0.2562, Train Acc: 90.23%\n","Epoch [24/30], Step [50/202], Train Loss: 0.2614, Train Acc: 90.31%\n","Epoch [24/30], Step [60/202], Train Loss: 0.2502, Train Acc: 91.04%\n","Epoch [24/30], Step [70/202], Train Loss: 0.2471, Train Acc: 90.94%\n","Epoch [24/30], Step [80/202], Train Loss: 0.2442, Train Acc: 91.02%\n","Epoch [24/30], Step [90/202], Train Loss: 0.2469, Train Acc: 90.87%\n","Epoch [24/30], Step [100/202], Train Loss: 0.2482, Train Acc: 90.84%\n","Epoch [24/30], Step [110/202], Train Loss: 0.2549, Train Acc: 90.82%\n","Epoch [24/30], Step [120/202], Train Loss: 0.2566, Train Acc: 90.55%\n","Epoch [24/30], Step [130/202], Train Loss: 0.2557, Train Acc: 90.62%\n","Epoch [24/30], Step [140/202], Train Loss: 0.2515, Train Acc: 90.78%\n","Epoch [24/30], Step [150/202], Train Loss: 0.2544, Train Acc: 90.73%\n","Epoch [24/30], Step [160/202], Train Loss: 0.2577, Train Acc: 90.62%\n","Epoch [24/30], Step [170/202], Train Loss: 0.2586, Train Acc: 90.51%\n","Epoch [24/30], Step [180/202], Train Loss: 0.2586, Train Acc: 90.36%\n","Epoch [24/30], Step [190/202], Train Loss: 0.2578, Train Acc: 90.33%\n","Epoch [24/30], Step [200/202], Train Loss: 0.2553, Train Acc: 90.47%\n","Epoch [24/30], Train Loss: 0.2569, Train Acc: 90.42%, Val Loss: 0.2743, Val Acc: 91.48%\n","Epoch [25/30], Step [10/202], Train Loss: 0.2098, Train Acc: 91.56%\n","Epoch [25/30], Step [20/202], Train Loss: 0.2059, Train Acc: 92.19%\n","Epoch [25/30], Step [30/202], Train Loss: 0.2270, Train Acc: 91.15%\n","Epoch [25/30], Step [40/202], Train Loss: 0.2294, Train Acc: 90.55%\n","Epoch [25/30], Step [50/202], Train Loss: 0.2238, Train Acc: 90.50%\n","Epoch [25/30], Step [60/202], Train Loss: 0.2228, Train Acc: 90.73%\n","Epoch [25/30], Step [70/202], Train Loss: 0.2149, Train Acc: 91.29%\n","Epoch [25/30], Step [80/202], Train Loss: 0.2135, Train Acc: 91.41%\n","Epoch [25/30], Step [90/202], Train Loss: 0.2170, Train Acc: 91.22%\n","Epoch [25/30], Step [100/202], Train Loss: 0.2204, Train Acc: 91.25%\n","Epoch [25/30], Step [110/202], Train Loss: 0.2201, Train Acc: 91.42%\n","Epoch [25/30], Step [120/202], Train Loss: 0.2212, Train Acc: 91.25%\n","Epoch [25/30], Step [130/202], Train Loss: 0.2220, Train Acc: 91.32%\n","Epoch [25/30], Step [140/202], Train Loss: 0.2228, Train Acc: 91.32%\n","Epoch [25/30], Step [150/202], Train Loss: 0.2241, Train Acc: 91.25%\n","Epoch [25/30], Step [160/202], Train Loss: 0.2271, Train Acc: 91.19%\n","Epoch [25/30], Step [170/202], Train Loss: 0.2283, Train Acc: 91.18%\n","Epoch [25/30], Step [180/202], Train Loss: 0.2285, Train Acc: 91.08%\n","Epoch [25/30], Step [190/202], Train Loss: 0.2286, Train Acc: 91.12%\n","Epoch [25/30], Step [200/202], Train Loss: 0.2282, Train Acc: 91.12%\n","Epoch [25/30], Train Loss: 0.2273, Train Acc: 91.15%, Val Loss: 0.3212, Val Acc: 90.07%\n","Epoch [26/30], Step [10/202], Train Loss: 0.2503, Train Acc: 90.00%\n","Epoch [26/30], Step [20/202], Train Loss: 0.2381, Train Acc: 90.16%\n","Epoch [26/30], Step [30/202], Train Loss: 0.2295, Train Acc: 90.10%\n","Epoch [26/30], Step [40/202], Train Loss: 0.2324, Train Acc: 90.78%\n","Epoch [26/30], Step [50/202], Train Loss: 0.2246, Train Acc: 91.19%\n","Epoch [26/30], Step [60/202], Train Loss: 0.2271, Train Acc: 91.15%\n","Epoch [26/30], Step [70/202], Train Loss: 0.2302, Train Acc: 90.85%\n","Epoch [26/30], Step [80/202], Train Loss: 0.2325, Train Acc: 90.94%\n","Epoch [26/30], Step [90/202], Train Loss: 0.2405, Train Acc: 90.97%\n","Epoch [26/30], Step [100/202], Train Loss: 0.2371, Train Acc: 91.16%\n","Epoch [26/30], Step [110/202], Train Loss: 0.2415, Train Acc: 90.82%\n","Epoch [26/30], Step [120/202], Train Loss: 0.2495, Train Acc: 90.62%\n","Epoch [26/30], Step [130/202], Train Loss: 0.2487, Train Acc: 90.55%\n","Epoch [26/30], Step [140/202], Train Loss: 0.2471, Train Acc: 90.65%\n","Epoch [26/30], Step [150/202], Train Loss: 0.2479, Train Acc: 90.48%\n","Epoch [26/30], Step [160/202], Train Loss: 0.2488, Train Acc: 90.51%\n","Epoch [26/30], Step [170/202], Train Loss: 0.2542, Train Acc: 90.35%\n","Epoch [26/30], Step [180/202], Train Loss: 0.2495, Train Acc: 90.54%\n","Epoch [26/30], Step [190/202], Train Loss: 0.2483, Train Acc: 90.58%\n","Epoch [26/30], Step [200/202], Train Loss: 0.2472, Train Acc: 90.62%\n","Epoch [26/30], Train Loss: 0.2456, Train Acc: 90.70%, Val Loss: 0.2927, Val Acc: 91.85%\n","Epoch [27/30], Step [10/202], Train Loss: 0.1882, Train Acc: 92.81%\n","Epoch [27/30], Step [20/202], Train Loss: 0.2172, Train Acc: 91.88%\n","Epoch [27/30], Step [30/202], Train Loss: 0.1989, Train Acc: 92.81%\n","Epoch [27/30], Step [40/202], Train Loss: 0.1877, Train Acc: 93.12%\n","Epoch [27/30], Step [50/202], Train Loss: 0.1994, Train Acc: 92.62%\n","Epoch [27/30], Step [60/202], Train Loss: 0.2006, Train Acc: 92.24%\n","Epoch [27/30], Step [70/202], Train Loss: 0.2046, Train Acc: 91.92%\n","Epoch [27/30], Step [80/202], Train Loss: 0.2071, Train Acc: 91.95%\n","Epoch [27/30], Step [90/202], Train Loss: 0.2042, Train Acc: 91.94%\n","Epoch [27/30], Step [100/202], Train Loss: 0.2051, Train Acc: 92.00%\n","Epoch [27/30], Step [110/202], Train Loss: 0.2052, Train Acc: 91.96%\n","Epoch [27/30], Step [120/202], Train Loss: 0.2036, Train Acc: 91.98%\n","Epoch [27/30], Step [130/202], Train Loss: 0.2055, Train Acc: 91.83%\n","Epoch [27/30], Step [140/202], Train Loss: 0.2065, Train Acc: 91.76%\n","Epoch [27/30], Step [150/202], Train Loss: 0.2130, Train Acc: 91.60%\n","Epoch [27/30], Step [160/202], Train Loss: 0.2153, Train Acc: 91.64%\n","Epoch [27/30], Step [170/202], Train Loss: 0.2136, Train Acc: 91.75%\n","Epoch [27/30], Step [180/202], Train Loss: 0.2161, Train Acc: 91.67%\n","Epoch [27/30], Step [190/202], Train Loss: 0.2159, Train Acc: 91.73%\n","Epoch [27/30], Step [200/202], Train Loss: 0.2162, Train Acc: 91.77%\n","Epoch [27/30], Train Loss: 0.2162, Train Acc: 91.80%, Val Loss: 0.2950, Val Acc: 90.74%\n","Epoch [28/30], Step [10/202], Train Loss: 0.2121, Train Acc: 93.12%\n","Epoch [28/30], Step [20/202], Train Loss: 0.1965, Train Acc: 92.81%\n","Epoch [28/30], Step [30/202], Train Loss: 0.1931, Train Acc: 92.71%\n","Epoch [28/30], Step [40/202], Train Loss: 0.2027, Train Acc: 92.34%\n","Epoch [28/30], Step [50/202], Train Loss: 0.2054, Train Acc: 92.31%\n","Epoch [28/30], Step [60/202], Train Loss: 0.1991, Train Acc: 92.40%\n","Epoch [28/30], Step [70/202], Train Loss: 0.2079, Train Acc: 92.10%\n","Epoch [28/30], Step [80/202], Train Loss: 0.2050, Train Acc: 92.19%\n","Epoch [28/30], Step [90/202], Train Loss: 0.2052, Train Acc: 92.08%\n","Epoch [28/30], Step [100/202], Train Loss: 0.2073, Train Acc: 92.03%\n","Epoch [28/30], Step [110/202], Train Loss: 0.2106, Train Acc: 91.99%\n","Epoch [28/30], Step [120/202], Train Loss: 0.2084, Train Acc: 91.95%\n","Epoch [28/30], Step [130/202], Train Loss: 0.2055, Train Acc: 92.16%\n","Epoch [28/30], Step [140/202], Train Loss: 0.2065, Train Acc: 92.03%\n","Epoch [28/30], Step [150/202], Train Loss: 0.2074, Train Acc: 91.94%\n","Epoch [28/30], Step [160/202], Train Loss: 0.2056, Train Acc: 91.97%\n","Epoch [28/30], Step [170/202], Train Loss: 0.2104, Train Acc: 91.80%\n","Epoch [28/30], Step [180/202], Train Loss: 0.2100, Train Acc: 91.75%\n","Epoch [28/30], Step [190/202], Train Loss: 0.2106, Train Acc: 91.74%\n","Epoch [28/30], Step [200/202], Train Loss: 0.2154, Train Acc: 91.55%\n","Epoch [28/30], Train Loss: 0.2140, Train Acc: 91.58%, Val Loss: 0.2960, Val Acc: 91.54%\n","Epoch [29/30], Step [10/202], Train Loss: 0.2306, Train Acc: 90.00%\n","Epoch [29/30], Step [20/202], Train Loss: 0.2227, Train Acc: 90.78%\n","Epoch [29/30], Step [30/202], Train Loss: 0.2073, Train Acc: 91.67%\n","Epoch [29/30], Step [40/202], Train Loss: 0.2094, Train Acc: 91.17%\n","Epoch [29/30], Step [50/202], Train Loss: 0.2080, Train Acc: 91.44%\n","Epoch [29/30], Step [60/202], Train Loss: 0.1988, Train Acc: 91.82%\n","Epoch [29/30], Step [70/202], Train Loss: 0.1978, Train Acc: 91.96%\n","Epoch [29/30], Step [80/202], Train Loss: 0.1955, Train Acc: 91.95%\n","Epoch [29/30], Step [90/202], Train Loss: 0.1971, Train Acc: 91.94%\n","Epoch [29/30], Step [100/202], Train Loss: 0.1970, Train Acc: 92.12%\n","Epoch [29/30], Step [110/202], Train Loss: 0.1974, Train Acc: 92.16%\n","Epoch [29/30], Step [120/202], Train Loss: 0.1914, Train Acc: 92.37%\n","Epoch [29/30], Step [130/202], Train Loss: 0.1935, Train Acc: 92.21%\n","Epoch [29/30], Step [140/202], Train Loss: 0.1948, Train Acc: 92.23%\n","Epoch [29/30], Step [150/202], Train Loss: 0.1977, Train Acc: 92.19%\n","Epoch [29/30], Step [160/202], Train Loss: 0.1994, Train Acc: 92.09%\n","Epoch [29/30], Step [170/202], Train Loss: 0.2011, Train Acc: 92.08%\n","Epoch [29/30], Step [180/202], Train Loss: 0.2008, Train Acc: 92.12%\n","Epoch [29/30], Step [190/202], Train Loss: 0.1980, Train Acc: 92.29%\n","Epoch [29/30], Step [200/202], Train Loss: 0.1975, Train Acc: 92.34%\n","Epoch [29/30], Train Loss: 0.1958, Train Acc: 92.42%, Val Loss: 0.2487, Val Acc: 93.00%\n","Epoch [30/30], Step [10/202], Train Loss: 0.1449, Train Acc: 95.00%\n","Epoch [30/30], Step [20/202], Train Loss: 0.1447, Train Acc: 94.84%\n","Epoch [30/30], Step [30/202], Train Loss: 0.1489, Train Acc: 94.79%\n","Epoch [30/30], Step [40/202], Train Loss: 0.1508, Train Acc: 94.45%\n","Epoch [30/30], Step [50/202], Train Loss: 0.1548, Train Acc: 94.19%\n","Epoch [30/30], Step [60/202], Train Loss: 0.1553, Train Acc: 94.06%\n","Epoch [30/30], Step [70/202], Train Loss: 0.1546, Train Acc: 93.88%\n","Epoch [30/30], Step [80/202], Train Loss: 0.1503, Train Acc: 94.14%\n","Epoch [30/30], Step [90/202], Train Loss: 0.1489, Train Acc: 94.34%\n","Epoch [30/30], Step [100/202], Train Loss: 0.1554, Train Acc: 94.34%\n","Epoch [30/30], Step [110/202], Train Loss: 0.1572, Train Acc: 94.18%\n","Epoch [30/30], Step [120/202], Train Loss: 0.1569, Train Acc: 94.11%\n","Epoch [30/30], Step [130/202], Train Loss: 0.1611, Train Acc: 93.94%\n","Epoch [30/30], Step [140/202], Train Loss: 0.1625, Train Acc: 93.91%\n","Epoch [30/30], Step [150/202], Train Loss: 0.1679, Train Acc: 93.69%\n","Epoch [30/30], Step [160/202], Train Loss: 0.1657, Train Acc: 93.69%\n","Epoch [30/30], Step [170/202], Train Loss: 0.1704, Train Acc: 93.77%\n","Epoch [30/30], Step [180/202], Train Loss: 0.1737, Train Acc: 93.65%\n","Epoch [30/30], Step [190/202], Train Loss: 0.1745, Train Acc: 93.60%\n","Epoch [30/30], Step [200/202], Train Loss: 0.1731, Train Acc: 93.64%\n","Epoch [30/30], Train Loss: 0.1732, Train Acc: 93.69%, Val Loss: 0.2338, Val Acc: 93.19%\n"]}]},{"cell_type":"code","source":["trained_model"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Ddkw9TfAmcdK","executionInfo":{"status":"ok","timestamp":1678957118402,"user_tz":-540,"elapsed":24,"user":{"displayName":"HaJun Yoo","userId":"01231542744346053879"}},"outputId":"9325b0eb-58ff-4c1b-e4ce-f1aafd8c06b7"},"execution_count":56,"outputs":[{"output_type":"execute_result","data":{"text/plain":["DeepCNNModel(\n","  (conv1): Conv2d(4, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","  (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","  (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","  (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","  (pool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","  (dropout1): Dropout2d(p=0.25, inplace=False)\n","  (conv3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","  (bn3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","  (conv4): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","  (bn4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","  (pool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","  (dropout2): Dropout2d(p=0.25, inplace=False)\n","  (conv5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","  (bn5): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","  (conv6): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","  (bn6): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","  (pool3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","  (dropout3): Dropout2d(p=0.25, inplace=False)\n","  (fc1): Linear(in_features=32768, out_features=512, bias=True)\n","  (dropout4): Dropout(p=0.5, inplace=False)\n","  (fc2): Linear(in_features=512, out_features=6, bias=True)\n",")"]},"metadata":{},"execution_count":56}]},{"cell_type":"code","source":["print(f\"Training accuracy: {train_accs[-1]*100:.2f}%, Validation accuracy: {valid_accs[-1]*100:.2f}%\")\n","print(f\"Training loss: {train_losses[-1]:.4f}, Validation loss: {valid_losses[-1]:.4f}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"79WctvQdlPPl","executionInfo":{"status":"ok","timestamp":1678957118402,"user_tz":-540,"elapsed":4,"user":{"displayName":"HaJun Yoo","userId":"01231542744346053879"}},"outputId":"6d0fcab5-e1e2-473b-e3c0-3dcb014f07cf"},"execution_count":57,"outputs":[{"output_type":"stream","name":"stdout","text":["Training accuracy: 93.69%, Validation accuracy: 93.19%\n","Training loss: 0.1732, Validation loss: 0.2338\n"]}]},{"cell_type":"code","source":["# Define the file path for the saved model\n","# save_path = '/content/drive/MyDrive/졸플/Audio/output_128/pytorch_cnn.pt'\n","save_path = '/content/drive/MyDrive/졸플/Audio/output_128/pytorch_deep_cnn.pt'\n","\n","# Save the trained model\n","torch.save({\n","            'model_state_dict': trained_model.state_dict(),\n","            'optimizer_state_dict': optimizer.state_dict()\n","            }, save_path)"],"metadata":{"id":"98BJdXgFmdi3","executionInfo":{"status":"ok","timestamp":1678957118403,"user_tz":-540,"elapsed":4,"user":{"displayName":"HaJun Yoo","userId":"01231542744346053879"}}},"execution_count":58,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"9gJy26T7mgDC"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Test with wav"],"metadata":{"id":"4Y10wldboiiM"}},{"cell_type":"code","source":["import librosa\n","import numpy as np\n","\n","import torch\n","from torchvision.models.resnet import ResNet, BasicBlock\n","import torch.nn as nn\n","import torch.nn.functional as F\n","from PIL import Image\n","\n","\n","# Define the path to the saved model\n","model_path = '/content/drive/MyDrive/졸플/Audio/output_128/pytorch_resnet.pt'\n","\n","# Load the saved model\n","checkpoint = torch.load(model_path)\n","model = ResNetModel(num_classes=6)\n","model.load_state_dict(checkpoint['model_state_dict'])\n","\n","# Define the device\n","# device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","device = torch.device('cpu')\n","# Move the model to the device\n","model.to(device)\n","\n","audio_file1 = '/content/drive/MyDrive/졸플/Audio/test/유아-성추행.wav'\n","audio_file2 = '/content/drive/MyDrive/졸플/Audio/test/유투브-도와주세요.wav'"],"metadata":{"id":"uNCUpuXjwYWy","executionInfo":{"status":"ok","timestamp":1678961700843,"user_tz":-540,"elapsed":3012,"user":{"displayName":"HaJun Yoo","userId":"01231542744346053879"}}},"execution_count":16,"outputs":[]},{"cell_type":"code","source":["def predict(audio_file, model):\n","\n","  # Load the audio data and resample it to the desired sampling rate\n","  audio_data, sr = librosa.load(audio_file, sr=44100, duration=5)\n","\n","  # Calculate the spectrogram of the audio data\n","  spec = librosa.feature.melspectrogram(audio_data, sr=sr)\n","\n","  # Convert the spectrogram to decibels\n","  spec_db = librosa.power_to_db(spec, ref=np.max)\n","\n","  # Add an additional channel to the spectrogram\n","  spec_db = np.repeat(spec_db[:, :, np.newaxis], 4, axis=2)\n","  # print(\"spec_db:\",spec_db)\n","  # Resize the spectrogram to match the input shape of the model\n","  spec_resized = np.resize(spec_db, (1, 4, 128, 128))\n","  # print(\"spec_resized:\", spec_resized)\n","\n","  # Normalize the spectrogram by z-score(정규화)\n","  mean = np.mean(spec_resized)\n","  std = np.std(spec_resized)\n","  spec_resized = (spec_resized - mean) / std\n","\n","  # print('spec shape :',spectrogram.shape)\n","  # print(\"spec :\",spectrogram)\n","\n","  # Convert the spectrogram to a tensor and move it to the device\n","  spectrogram_tensor = torch.tensor(spec_resized, dtype=torch.float).to(device)\n","\n","  # Set the model to evaluation mode\n","  model.eval()\n","\n","  # Predict the probabilities for each class\n","  with torch.no_grad():\n","      probabilities = model(spectrogram_tensor)\n","  print('predicted prob:', probabilities)\n","  # Get the index of the class with the highest probability\n","  predicted_class_index = torch.argmax(probabilities, dim=1)\n","\n","  label_names = ['regular', 'help', 'robbery', 'sexual', 'theft', 'violence']\n","  label_index = predicted_class_index.item()\n","\n","  print(f\"Predicted class index: {label_names[int(label_index)]}\")\n","  \n","\n","  return label_names[int(label_index)]"],"metadata":{"id":"3_8YuQeJqbHU","executionInfo":{"status":"ok","timestamp":1678961750755,"user_tz":-540,"elapsed":3,"user":{"displayName":"HaJun Yoo","userId":"01231542744346053879"}}},"execution_count":23,"outputs":[]},{"cell_type":"code","source":["import time\n","\n","startTime = time.time()\n","# 유아-성추행\n","predict(audio_file1, model)\n","\n","endTime = time.time() - startTime\n","print('걸린 시간 :',  endTime)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZBD8iwlTvsEp","executionInfo":{"status":"ok","timestamp":1678961752526,"user_tz":-540,"elapsed":5,"user":{"displayName":"HaJun Yoo","userId":"01231542744346053879"}},"outputId":"4396ec1a-8ff5-4d4b-ad52-6c41266b259f"},"execution_count":24,"outputs":[{"output_type":"stream","name":"stdout","text":["predicted prob: tensor([[ -8.7048,   5.4524,  -9.8120, -19.1895,   4.1433,   5.3668]])\n","Predicted class index: help\n","걸린 시간 : 0.15838623046875\n"]}]},{"cell_type":"code","source":["# 유투브-도와주세요\n","predict(audio_file2, model)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":71},"id":"WOSwW-J6vw8c","executionInfo":{"status":"ok","timestamp":1678961754242,"user_tz":-540,"elapsed":6,"user":{"displayName":"HaJun Yoo","userId":"01231542744346053879"}},"outputId":"b671590e-f1ba-4909-df97-936bef16b175"},"execution_count":25,"outputs":[{"output_type":"stream","name":"stdout","text":["predicted prob: tensor([[-11.9501,  -3.4895,  -8.5090, -21.4889,  -0.9494,  16.1659]])\n","Predicted class index: violence\n"]},{"output_type":"execute_result","data":{"text/plain":["'violence'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":25}]},{"cell_type":"code","source":[],"metadata":{"id":"U4w18li8ylPI"},"execution_count":null,"outputs":[]}]}