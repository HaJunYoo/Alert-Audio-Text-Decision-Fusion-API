{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-22T10:19:22.269112Z",
     "start_time": "2023-03-22T10:19:18.999770Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import librosa\n",
    "import numpy as np\n",
    "\n",
    "import os\n",
    "import time\n",
    "\n",
    "import boto3\n",
    "from botocore.exceptions import ClientError\n",
    "\n",
    "import gluonnlp as nlp\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from transformers import AutoTokenizer\n",
    "from kobert.pytorch_kobert import get_pytorch_kobert_model\n",
    "from kobert.utils import get_tokenizer\n",
    "\n",
    "from torchvision.models.resnet import ResNet, BasicBlock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-22T10:19:25.296841Z",
     "start_time": "2023-03-22T10:19:25.275654Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# BERT 모델, Vocabulary 불러오기\n",
    "class BERTClassifier(nn.Module):\n",
    "    def __init__(self,\n",
    "                 bert,\n",
    "                 hidden_size=768,\n",
    "                 num_classes=6,  ##클래스 수 조정##\n",
    "                 dr_rate=None,\n",
    "                 params=None):\n",
    "        super(BERTClassifier, self).__init__()\n",
    "        self.bert = bert\n",
    "        self.dr_rate = dr_rate\n",
    "\n",
    "        self.classifier = nn.Linear(hidden_size, num_classes)\n",
    "        if dr_rate:\n",
    "            self.dropout = nn.Dropout(p=dr_rate)\n",
    "\n",
    "    def gen_attention_mask(self, token_ids, valid_length):\n",
    "        attention_mask = torch.zeros_like(token_ids)\n",
    "        for i, v in enumerate(valid_length):\n",
    "            attention_mask[i][:v] = 1\n",
    "        return attention_mask.float()\n",
    "\n",
    "    def forward(self, token_ids, valid_length, segment_ids):\n",
    "        attention_mask = self.gen_attention_mask(token_ids, valid_length)\n",
    "\n",
    "        _, pooler = self.bert(input_ids=token_ids, token_type_ids=segment_ids.long(),\n",
    "                              attention_mask=attention_mask.float().to(token_ids.device), return_dict=False)\n",
    "        if self.dr_rate:\n",
    "            out = self.dropout(pooler)\n",
    "        return self.classifier(out)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class BERTDataset(Dataset):\n",
    "    def __init__(self, dataset, sent_idx, label_idx, bert_tokenizer, vocab, max_len,\n",
    "                 pad, pair):\n",
    "        transform = nlp.data.BERTSentenceTransform(\n",
    "            bert_tokenizer, max_seq_length=max_len, vocab=vocab, pad=pad, pair=pair)\n",
    "\n",
    "        self.sentences = [transform([i[sent_idx]]) for i in dataset]\n",
    "        self.labels = [np.int32(i[label_idx]) for i in dataset]\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        return (self.sentences[i] + (self.labels[i],))\n",
    "\n",
    "    def __len__(self):\n",
    "        return (len(self.labels))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class ResNetModel(ResNet):\n",
    "    def __init__(self, num_classes=6):\n",
    "        super(ResNetModel, self).__init__(BasicBlock, [2, 2, 2, 2], num_classes=num_classes)\n",
    "        self.conv1 = nn.Conv2d(4, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool(x)\n",
    "\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "\n",
    "        x = self.avgpool(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "device = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading BERT model...\n",
      "using cached model. /Users/yoohajun/Library/Mobile Documents/com~apple~CloudDocs/Hajun/Graduate_project/fastapi/Diffusion/.cache/kobert_v1.zip\n",
      "using cached model. /Users/yoohajun/Library/Mobile Documents/com~apple~CloudDocs/Hajun/Graduate_project/fastapi/Diffusion/.cache/kobert_news_wiki_ko_cased-1087f8699e.spiece\n",
      "Loading BERT tokenizer...\n",
      "using cached model. /Users/yoohajun/Library/Mobile Documents/com~apple~CloudDocs/Hajun/Graduate_project/fastapi/Diffusion/.cache/kobert_news_wiki_ko_cased-1087f8699e.spiece\n"
     ]
    },
    {
     "data": {
      "text/plain": "<All keys matched successfully>"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Setting prediction parameters\n",
    "max_len = 60\n",
    "batch_size = 64\n",
    "learning_rate = 5e-5\n",
    "\n",
    "print(\"Loading BERT model...\")\n",
    "# Load pre-trained model (weights)\n",
    "bertmodel, vocab = get_pytorch_kobert_model()\n",
    "\n",
    "# Load tokenizer from a local directory\n",
    "# kobert_tokenizer = AutoTokenizer.from_pretrained(\"kobert_tokenizer\", use_fast=False)\n",
    "# tok = kobert_tokenizer.tokenize\n",
    "print(\"Loading BERT tokenizer...\")\n",
    "tokenizer = get_tokenizer()\n",
    "tok = nlp.data.BERTSPTokenizer(tokenizer, vocab, lower=False)\n",
    "\n",
    "PATH = '/Users/yoohajun/Library/Mobile Documents/com~apple~CloudDocs/Hajun/Graduate_project/fastapi/KoBERT/'\n",
    "kobert_model = BERTClassifier(bertmodel, dr_rate=0.5)\n",
    "kobert_model.load_state_dict(torch.load(PATH + 'model_state_dict.pt', map_location=device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "<All keys matched successfully>"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the path to the saved model\n",
    "model_path = '/Users/yoohajun/Library/Mobile Documents/com~apple~CloudDocs/Hajun/Graduate_project/fastapi/resnet-model/pytorch_resnet.pt'\n",
    "# Load the saved model\n",
    "checkpoint = torch.load(model_path, map_location=torch.device('cpu'))\n",
    "resnet_model = ResNetModel(num_classes=6)\n",
    "resnet_model.load_state_dict(checkpoint['model_state_dict'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def scale_to_range(arr, target_range=(0, 1)):\n",
    "    # Calculate exponential values for each element\n",
    "    exp_arr = np.exp(arr)\n",
    "\n",
    "    # Calculate the sum of all exponential values\n",
    "    exp_sum = np.sum(exp_arr)\n",
    "\n",
    "    # Calculate probability for each element by dividing its exponential value by the sum\n",
    "    probs = exp_arr / exp_sum\n",
    "\n",
    "    # Scale probabilities to target range\n",
    "    scaled = (probs * (target_range[1] - target_range[0])) + target_range[0]\n",
    "\n",
    "    return scaled\n",
    "\n",
    "# decision diffusion을 수행할 때 range scaling을 하는 이유는 균일하게 특성을 통일해야한다고 생각했지만\n",
    "# 오히려 scaling을 하게 되면 그 특성을 손상시키게 된다\n",
    "# 정확도가 89 -> 82 로 낙하 (기본 Decision Tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def softmax(vals, idx):\n",
    "    valscpu = vals.cpu().detach().squeeze(0)\n",
    "    a = 0\n",
    "    for i in valscpu:\n",
    "        a += np.exp(i)\n",
    "    return ((np.exp(valscpu[idx])) / a).item() * 100\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def text_predict(predict_sentence, model=kobert_model):\n",
    "    # print(\"predictsentence start:\", predict_sentence)\n",
    "    start = time.time()\n",
    "    text_label = ['regular', 'help', 'robbery', 'sexual', 'theft', 'violence']\n",
    "    data = [predict_sentence]\n",
    "    # dataset_another = [data]\n",
    "\n",
    "    transform = nlp.data.BERTSentenceTransform(tok, max_len, pad=True, pair=False)\n",
    "    tokenized = transform(data)\n",
    "    model.eval()\n",
    "\n",
    "    # print([tokenized[0]])\n",
    "    # token_ids = torch.tensor([tokenized[0]]).to(device)\n",
    "    # segment_ids = torch.tensor([tokenized[2]]).to(device)\n",
    "    token_ids = torch.tensor(np.array([tokenized[0]])).to(device)\n",
    "    valid_length = [tokenized[1]]\n",
    "    segment_ids = torch.tensor(np.array([tokenized[2]])).to(device)\n",
    "\n",
    "    result = model(token_ids, valid_length, segment_ids)\n",
    "    # print(result)\n",
    "    idx = result.argmax().cpu().item()\n",
    "    out_prob = result.detach().cpu().numpy()[0]\n",
    "\n",
    "    # scaled_prob = scale_to_range(out_prob)\n",
    "    # print(out_prob)\n",
    "    # print(\"대사의 카테고리는:\", text_label[idx])\n",
    "    # print(\"대사 신뢰도는:\", \"{:.2f}%\".format(softmax(result, idx)))\n",
    "    end = time.time() - start\n",
    "    # print(\"text predict 걸린 시간:\", end)\n",
    "    return out_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def audio_predict(file_location, model=resnet_model):\n",
    "    try:\n",
    "        audio_data, sr = librosa.load(file_location, sr=44100, duration=5)\n",
    "\n",
    "        # Define label names\n",
    "        label_names = ['regular', 'help', 'robbery', 'sexual', 'theft', 'violence']\n",
    "\n",
    "        # Calculate the spectrogram of the audio data\n",
    "        spec = librosa.feature.melspectrogram(y=audio_data, sr=sr)\n",
    "\n",
    "        # Convert the spectrogram to decibels\n",
    "        spec_db = librosa.power_to_db(spec, ref=np.max)\n",
    "\n",
    "        # Add an additional channel to the spectrogram\n",
    "        spec_db = np.repeat(spec_db[:, :, np.newaxis], 4, axis=2)\n",
    "\n",
    "        # Resize the spectrogram to match the input shape of the model\n",
    "        spec_resized = np.resize(spec_db, (1, 4, 128, 128))\n",
    "\n",
    "        # Normalize the spectrogram by z-score\n",
    "        mean = np.mean(spec_resized)\n",
    "        std = np.std(spec_resized)\n",
    "        spec_resized = (spec_resized - mean) / std\n",
    "\n",
    "        # Convert the spectrogram to a tensor and move it to the device\n",
    "        spectrogram_tensor = torch.tensor(spec_resized, dtype=torch.float).to(device)\n",
    "\n",
    "        # Set the model to evaluation mode\n",
    "        model.eval()\n",
    "\n",
    "        # Predict the probabilities for each class\n",
    "        with torch.no_grad():\n",
    "            out = model(spectrogram_tensor)\n",
    "\n",
    "        # Get the index of the class with the highest probability\n",
    "        predicted_class_index = torch.argmax(out, dim=1)\n",
    "\n",
    "        label_index = predicted_class_index.item()\n",
    "\n",
    "        # print(\"음성의 카테고리는:\", label_names[label_index])\n",
    "        # print(\"음성 신뢰도는:\", \"{:.2f}%\".format(softmax(out, label_index)))\n",
    "        prob = out.detach().cpu().numpy()[0]\n",
    "        # scaled_prob = scale_to_range(prob)\n",
    "\n",
    "        return prob\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f'Error: {e}')\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('./audio_text_diffusion_train.csv', encoding='utf8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": "     Unnamed: 0              audio_id  \\\n0             0    15.실내_906628_label   \n1             1    15.실내_903897_label   \n2             2    15.실내_918134_label   \n3             3    15.실내_654528_label   \n4             4    15.실내_661859_label   \n..          ...                   ...   \n402         402  3.절도범죄_1240207_label   \n403         403  3.절도범죄_1240211_label   \n404         404  3.절도범죄_1240983_label   \n405         405  3.절도범죄_1240989_label   \n406         406   4.폭력범죄_866862_label   \n\n                                             audio_dir       note category_02  \n0    /Users/yoohajun/Desktop/grad_audio/diffusion/t...        NaN          실내  \n1    /Users/yoohajun/Desktop/grad_audio/diffusion/t...        NaN          실내  \n2    /Users/yoohajun/Desktop/grad_audio/diffusion/t...        NaN          실내  \n3    /Users/yoohajun/Desktop/grad_audio/diffusion/t...        NaN          실내  \n4    /Users/yoohajun/Desktop/grad_audio/diffusion/t...        NaN          실내  \n..                                                 ...        ...         ...  \n402  /Users/yoohajun/Desktop/grad_audio/diffusion/t...  소매치기 잡아라         절도범죄  \n403  /Users/yoohajun/Desktop/grad_audio/diffusion/t...   소매치기 잡아라        절도범죄  \n404  /Users/yoohajun/Desktop/grad_audio/diffusion/t...    저 놈 잡아라        절도범죄  \n405  /Users/yoohajun/Desktop/grad_audio/diffusion/t...   저 놈 잡아라         절도범죄  \n406  /Users/yoohajun/Desktop/grad_audio/diffusion/t...    아 그만하세요        폭력범죄  \n\n[407 rows x 5 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Unnamed: 0</th>\n      <th>audio_id</th>\n      <th>audio_dir</th>\n      <th>note</th>\n      <th>category_02</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>15.실내_906628_label</td>\n      <td>/Users/yoohajun/Desktop/grad_audio/diffusion/t...</td>\n      <td>NaN</td>\n      <td>실내</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>15.실내_903897_label</td>\n      <td>/Users/yoohajun/Desktop/grad_audio/diffusion/t...</td>\n      <td>NaN</td>\n      <td>실내</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>15.실내_918134_label</td>\n      <td>/Users/yoohajun/Desktop/grad_audio/diffusion/t...</td>\n      <td>NaN</td>\n      <td>실내</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>15.실내_654528_label</td>\n      <td>/Users/yoohajun/Desktop/grad_audio/diffusion/t...</td>\n      <td>NaN</td>\n      <td>실내</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>15.실내_661859_label</td>\n      <td>/Users/yoohajun/Desktop/grad_audio/diffusion/t...</td>\n      <td>NaN</td>\n      <td>실내</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>402</th>\n      <td>402</td>\n      <td>3.절도범죄_1240207_label</td>\n      <td>/Users/yoohajun/Desktop/grad_audio/diffusion/t...</td>\n      <td>소매치기 잡아라</td>\n      <td>절도범죄</td>\n    </tr>\n    <tr>\n      <th>403</th>\n      <td>403</td>\n      <td>3.절도범죄_1240211_label</td>\n      <td>/Users/yoohajun/Desktop/grad_audio/diffusion/t...</td>\n      <td>소매치기 잡아라</td>\n      <td>절도범죄</td>\n    </tr>\n    <tr>\n      <th>404</th>\n      <td>404</td>\n      <td>3.절도범죄_1240983_label</td>\n      <td>/Users/yoohajun/Desktop/grad_audio/diffusion/t...</td>\n      <td>저 놈 잡아라</td>\n      <td>절도범죄</td>\n    </tr>\n    <tr>\n      <th>405</th>\n      <td>405</td>\n      <td>3.절도범죄_1240989_label</td>\n      <td>/Users/yoohajun/Desktop/grad_audio/diffusion/t...</td>\n      <td>저 놈 잡아라</td>\n      <td>절도범죄</td>\n    </tr>\n    <tr>\n      <th>406</th>\n      <td>406</td>\n      <td>4.폭력범죄_866862_label</td>\n      <td>/Users/yoohajun/Desktop/grad_audio/diffusion/t...</td>\n      <td>아 그만하세요</td>\n      <td>폭력범죄</td>\n    </tr>\n  </tbody>\n</table>\n<p>407 rows × 5 columns</p>\n</div>"
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# 음성 파일 id, 음성 파일 경로, note, 음성 파일 븐류 -> 1차 csv\n",
    "\n",
    "# 오디오 확률 리스트, 텍스트 확률 리스트, 라벨\n",
    "\n",
    "# 리스트 nested 해제 , 라벨\n",
    "\n",
    "# diffusion layer ml 학습 - decision tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "# define a function to apply to each row of the DataFrame\n",
    "def add_prediction(row):\n",
    "    # call the audio_predict function with the audio_dir value\n",
    "    audio_prediction = audio_predict(row['audio_dir'])\n",
    "    # add the prediction values as a new column to the DataFrame\n",
    "    if audio_prediction is not None:\n",
    "        # add the prediction values as a new column to the DataFrame\n",
    "        # temp = scale_to_range(audio_prediction)\n",
    "        # temp_arr = temp.tolist()\n",
    "        # row['audio_prediction'] = temp_arr\n",
    "        row['audio_prediction'] = audio_prediction.tolist()\n",
    "    else:\n",
    "        row['audio_prediction'] = None\n",
    "\n",
    "    text_prediction = text_predict(row['note'])\n",
    "\n",
    "    if text_prediction is not None:\n",
    "        # add the prediction values as a new column to the DataFrame\n",
    "        row['text_prediction'] = text_prediction.tolist()\n",
    "    else:\n",
    "        row['text_prediction'] = None\n",
    "\n",
    "    return row\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "data": {
      "text/plain": "     Unnamed: 0              audio_id  \\\n0             0    15.실내_906628_label   \n1             1    15.실내_903897_label   \n2             2    15.실내_918134_label   \n3             3    15.실내_654528_label   \n4             4    15.실내_661859_label   \n..          ...                   ...   \n402         402  3.절도범죄_1240207_label   \n403         403  3.절도범죄_1240211_label   \n404         404  3.절도범죄_1240983_label   \n405         405  3.절도범죄_1240989_label   \n406         406   4.폭력범죄_866862_label   \n\n                                             audio_dir       note category_02  \n0    /Users/yoohajun/Desktop/grad_audio/diffusion/t...        NaN          실내  \n1    /Users/yoohajun/Desktop/grad_audio/diffusion/t...        NaN          실내  \n2    /Users/yoohajun/Desktop/grad_audio/diffusion/t...        NaN          실내  \n3    /Users/yoohajun/Desktop/grad_audio/diffusion/t...        NaN          실내  \n4    /Users/yoohajun/Desktop/grad_audio/diffusion/t...        NaN          실내  \n..                                                 ...        ...         ...  \n402  /Users/yoohajun/Desktop/grad_audio/diffusion/t...  소매치기 잡아라         절도범죄  \n403  /Users/yoohajun/Desktop/grad_audio/diffusion/t...   소매치기 잡아라        절도범죄  \n404  /Users/yoohajun/Desktop/grad_audio/diffusion/t...    저 놈 잡아라        절도범죄  \n405  /Users/yoohajun/Desktop/grad_audio/diffusion/t...   저 놈 잡아라         절도범죄  \n406  /Users/yoohajun/Desktop/grad_audio/diffusion/t...    아 그만하세요        폭력범죄  \n\n[407 rows x 5 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Unnamed: 0</th>\n      <th>audio_id</th>\n      <th>audio_dir</th>\n      <th>note</th>\n      <th>category_02</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>15.실내_906628_label</td>\n      <td>/Users/yoohajun/Desktop/grad_audio/diffusion/t...</td>\n      <td>NaN</td>\n      <td>실내</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>15.실내_903897_label</td>\n      <td>/Users/yoohajun/Desktop/grad_audio/diffusion/t...</td>\n      <td>NaN</td>\n      <td>실내</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>15.실내_918134_label</td>\n      <td>/Users/yoohajun/Desktop/grad_audio/diffusion/t...</td>\n      <td>NaN</td>\n      <td>실내</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>15.실내_654528_label</td>\n      <td>/Users/yoohajun/Desktop/grad_audio/diffusion/t...</td>\n      <td>NaN</td>\n      <td>실내</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>15.실내_661859_label</td>\n      <td>/Users/yoohajun/Desktop/grad_audio/diffusion/t...</td>\n      <td>NaN</td>\n      <td>실내</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>402</th>\n      <td>402</td>\n      <td>3.절도범죄_1240207_label</td>\n      <td>/Users/yoohajun/Desktop/grad_audio/diffusion/t...</td>\n      <td>소매치기 잡아라</td>\n      <td>절도범죄</td>\n    </tr>\n    <tr>\n      <th>403</th>\n      <td>403</td>\n      <td>3.절도범죄_1240211_label</td>\n      <td>/Users/yoohajun/Desktop/grad_audio/diffusion/t...</td>\n      <td>소매치기 잡아라</td>\n      <td>절도범죄</td>\n    </tr>\n    <tr>\n      <th>404</th>\n      <td>404</td>\n      <td>3.절도범죄_1240983_label</td>\n      <td>/Users/yoohajun/Desktop/grad_audio/diffusion/t...</td>\n      <td>저 놈 잡아라</td>\n      <td>절도범죄</td>\n    </tr>\n    <tr>\n      <th>405</th>\n      <td>405</td>\n      <td>3.절도범죄_1240989_label</td>\n      <td>/Users/yoohajun/Desktop/grad_audio/diffusion/t...</td>\n      <td>저 놈 잡아라</td>\n      <td>절도범죄</td>\n    </tr>\n    <tr>\n      <th>406</th>\n      <td>406</td>\n      <td>4.폭력범죄_866862_label</td>\n      <td>/Users/yoohajun/Desktop/grad_audio/diffusion/t...</td>\n      <td>아 그만하세요</td>\n      <td>폭력범죄</td>\n    </tr>\n  </tbody>\n</table>\n<p>407 rows × 5 columns</p>\n</div>"
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "# fill NaN values with empty string\n",
    "df = df.fillna('empty')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/407 [00:00<?, ?it/s][W NNPACK.cpp:79] Could not initialize NNPACK! Reason: Unsupported hardware.\n",
      "  1%|          | 5/407 [00:03<03:26,  1.94it/s]/var/folders/3p/vhd92h0x7cb73w5m2xzsn2jr0000gn/T/ipykernel_41525/3544776722.py:23: RuntimeWarning: invalid value encountered in divide\n",
      "  spec_resized = (spec_resized - mean) / std\n",
      "  5%|▍         | 19/407 [00:08<02:30,  2.58it/s]/var/folders/3p/vhd92h0x7cb73w5m2xzsn2jr0000gn/T/ipykernel_41525/3544776722.py:3: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  audio_data, sr = librosa.load(file_location, sr=44100, duration=5)\n",
      "/opt/anaconda3/envs/pytorch-grad/lib/python3.8/site-packages/librosa/core/audio.py:184: FutureWarning: librosa.core.audio.__audioread_load\n",
      "\tDeprecated as of librosa version 0.10.0.\n",
      "\tIt will be removed in librosa version 1.0.\n",
      "  y, sr_native = __audioread_load(path, offset, duration, dtype)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: [Errno 2] No such file or directory: '/Users/yoohajun/Desktop/grad_audio/diffusion/train/15.실내_688645_label.wav'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 407/407 [02:35<00:00,  2.61it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "tqdm.pandas()\n",
    "# apply the add_prediction function to each row of the DataFrame\n",
    "df = df.progress_apply(add_prediction, axis=1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "data": {
      "text/plain": "   Unnamed: 0            audio_id  \\\n0           0  15.실내_906628_label   \n1           1  15.실내_903897_label   \n2           2  15.실내_918134_label   \n3           3  15.실내_654528_label   \n4           4  15.실내_661859_label   \n\n                                           audio_dir   note category_02  \\\n0  /Users/yoohajun/Desktop/grad_audio/diffusion/t...  empty          실내   \n1  /Users/yoohajun/Desktop/grad_audio/diffusion/t...  empty          실내   \n2  /Users/yoohajun/Desktop/grad_audio/diffusion/t...  empty          실내   \n3  /Users/yoohajun/Desktop/grad_audio/diffusion/t...  empty          실내   \n4  /Users/yoohajun/Desktop/grad_audio/diffusion/t...  empty          실내   \n\n                                    audio_prediction  \\\n0  [-11.508453369140625, -8.252114295959473, -23....   \n1  [17.464433670043945, -21.854764938354492, -7.6...   \n2  [3.1379899978637695, 1.7926372289657593, -12.4...   \n3  [28.44495964050293, -16.67407989501953, -4.198...   \n4                     [nan, nan, nan, nan, nan, nan]   \n\n                                     text_prediction  \n0  [1.985169768333435, -1.2518784999847412, 1.072...  \n1  [1.985169768333435, -1.2518784999847412, 1.072...  \n2  [1.985169768333435, -1.2518784999847412, 1.072...  \n3  [1.985169768333435, -1.2518784999847412, 1.072...  \n4  [1.985169768333435, -1.2518784999847412, 1.072...  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Unnamed: 0</th>\n      <th>audio_id</th>\n      <th>audio_dir</th>\n      <th>note</th>\n      <th>category_02</th>\n      <th>audio_prediction</th>\n      <th>text_prediction</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>15.실내_906628_label</td>\n      <td>/Users/yoohajun/Desktop/grad_audio/diffusion/t...</td>\n      <td>empty</td>\n      <td>실내</td>\n      <td>[-11.508453369140625, -8.252114295959473, -23....</td>\n      <td>[1.985169768333435, -1.2518784999847412, 1.072...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>15.실내_903897_label</td>\n      <td>/Users/yoohajun/Desktop/grad_audio/diffusion/t...</td>\n      <td>empty</td>\n      <td>실내</td>\n      <td>[17.464433670043945, -21.854764938354492, -7.6...</td>\n      <td>[1.985169768333435, -1.2518784999847412, 1.072...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>15.실내_918134_label</td>\n      <td>/Users/yoohajun/Desktop/grad_audio/diffusion/t...</td>\n      <td>empty</td>\n      <td>실내</td>\n      <td>[3.1379899978637695, 1.7926372289657593, -12.4...</td>\n      <td>[1.985169768333435, -1.2518784999847412, 1.072...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>15.실내_654528_label</td>\n      <td>/Users/yoohajun/Desktop/grad_audio/diffusion/t...</td>\n      <td>empty</td>\n      <td>실내</td>\n      <td>[28.44495964050293, -16.67407989501953, -4.198...</td>\n      <td>[1.985169768333435, -1.2518784999847412, 1.072...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>15.실내_661859_label</td>\n      <td>/Users/yoohajun/Desktop/grad_audio/diffusion/t...</td>\n      <td>empty</td>\n      <td>실내</td>\n      <td>[nan, nan, nan, nan, nan, nan]</td>\n      <td>[1.985169768333435, -1.2518784999847412, 1.072...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print the resulting DataFrame with the new 'prediction' column\n",
    "df.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [],
   "source": [
    "df.to_csv('./audio_text_label.csv')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "data": {
      "text/plain": "     Unnamed: 0              audio_id  \\\n0             0    15.실내_906628_label   \n1             1    15.실내_903897_label   \n2             2    15.실내_918134_label   \n3             3    15.실내_654528_label   \n4             4    15.실내_661859_label   \n..          ...                   ...   \n402         402  3.절도범죄_1240207_label   \n403         403  3.절도범죄_1240211_label   \n404         404  3.절도범죄_1240983_label   \n405         405  3.절도범죄_1240989_label   \n406         406   4.폭력범죄_866862_label   \n\n                                             audio_dir       note category_02  \\\n0    /Users/yoohajun/Desktop/grad_audio/diffusion/t...      empty          실내   \n1    /Users/yoohajun/Desktop/grad_audio/diffusion/t...      empty          실내   \n2    /Users/yoohajun/Desktop/grad_audio/diffusion/t...      empty          실내   \n3    /Users/yoohajun/Desktop/grad_audio/diffusion/t...      empty          실내   \n4    /Users/yoohajun/Desktop/grad_audio/diffusion/t...      empty          실내   \n..                                                 ...        ...         ...   \n402  /Users/yoohajun/Desktop/grad_audio/diffusion/t...  소매치기 잡아라         절도범죄   \n403  /Users/yoohajun/Desktop/grad_audio/diffusion/t...   소매치기 잡아라        절도범죄   \n404  /Users/yoohajun/Desktop/grad_audio/diffusion/t...    저 놈 잡아라        절도범죄   \n405  /Users/yoohajun/Desktop/grad_audio/diffusion/t...   저 놈 잡아라         절도범죄   \n406  /Users/yoohajun/Desktop/grad_audio/diffusion/t...    아 그만하세요        폭력범죄   \n\n                                      audio_prediction  \\\n0    [-11.508453369140625, -8.252114295959473, -23....   \n1    [17.464433670043945, -21.854764938354492, -7.6...   \n2    [3.1379899978637695, 1.7926372289657593, -12.4...   \n3    [28.44495964050293, -16.67407989501953, -4.198...   \n4                       [nan, nan, nan, nan, nan, nan]   \n..                                                 ...   \n402  [-1.3769102096557617, 4.8432111740112305, -11....   \n403  [-4.723093509674072, -8.860213279724121, -11.5...   \n404  [-4.010353088378906, -3.603227138519287, -10.2...   \n405  [-15.072626113891602, 3.24332594871521, -8.771...   \n406  [17.879575729370117, -11.716965675354004, -6.4...   \n\n                                       text_prediction  \n0    [1.985169768333435, -1.2518784999847412, 1.072...  \n1    [1.985169768333435, -1.2518784999847412, 1.072...  \n2    [1.985169768333435, -1.2518784999847412, 1.072...  \n3    [1.985169768333435, -1.2518784999847412, 1.072...  \n4    [1.985169768333435, -1.2518784999847412, 1.072...  \n..                                                 ...  \n402  [-0.8364552855491638, -0.4790562391281128, -0....  \n403  [-0.8364552855491638, -0.4790562391281128, -0....  \n404  [-1.1488778591156006, 0.18310293555259705, -0....  \n405  [-1.1488778591156006, 0.18310293555259705, -0....  \n406  [-1.759752631187439, -0.9184098839759827, -0.3...  \n\n[407 rows x 7 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Unnamed: 0</th>\n      <th>audio_id</th>\n      <th>audio_dir</th>\n      <th>note</th>\n      <th>category_02</th>\n      <th>audio_prediction</th>\n      <th>text_prediction</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>15.실내_906628_label</td>\n      <td>/Users/yoohajun/Desktop/grad_audio/diffusion/t...</td>\n      <td>empty</td>\n      <td>실내</td>\n      <td>[-11.508453369140625, -8.252114295959473, -23....</td>\n      <td>[1.985169768333435, -1.2518784999847412, 1.072...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>15.실내_903897_label</td>\n      <td>/Users/yoohajun/Desktop/grad_audio/diffusion/t...</td>\n      <td>empty</td>\n      <td>실내</td>\n      <td>[17.464433670043945, -21.854764938354492, -7.6...</td>\n      <td>[1.985169768333435, -1.2518784999847412, 1.072...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>15.실내_918134_label</td>\n      <td>/Users/yoohajun/Desktop/grad_audio/diffusion/t...</td>\n      <td>empty</td>\n      <td>실내</td>\n      <td>[3.1379899978637695, 1.7926372289657593, -12.4...</td>\n      <td>[1.985169768333435, -1.2518784999847412, 1.072...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>15.실내_654528_label</td>\n      <td>/Users/yoohajun/Desktop/grad_audio/diffusion/t...</td>\n      <td>empty</td>\n      <td>실내</td>\n      <td>[28.44495964050293, -16.67407989501953, -4.198...</td>\n      <td>[1.985169768333435, -1.2518784999847412, 1.072...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>15.실내_661859_label</td>\n      <td>/Users/yoohajun/Desktop/grad_audio/diffusion/t...</td>\n      <td>empty</td>\n      <td>실내</td>\n      <td>[nan, nan, nan, nan, nan, nan]</td>\n      <td>[1.985169768333435, -1.2518784999847412, 1.072...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>402</th>\n      <td>402</td>\n      <td>3.절도범죄_1240207_label</td>\n      <td>/Users/yoohajun/Desktop/grad_audio/diffusion/t...</td>\n      <td>소매치기 잡아라</td>\n      <td>절도범죄</td>\n      <td>[-1.3769102096557617, 4.8432111740112305, -11....</td>\n      <td>[-0.8364552855491638, -0.4790562391281128, -0....</td>\n    </tr>\n    <tr>\n      <th>403</th>\n      <td>403</td>\n      <td>3.절도범죄_1240211_label</td>\n      <td>/Users/yoohajun/Desktop/grad_audio/diffusion/t...</td>\n      <td>소매치기 잡아라</td>\n      <td>절도범죄</td>\n      <td>[-4.723093509674072, -8.860213279724121, -11.5...</td>\n      <td>[-0.8364552855491638, -0.4790562391281128, -0....</td>\n    </tr>\n    <tr>\n      <th>404</th>\n      <td>404</td>\n      <td>3.절도범죄_1240983_label</td>\n      <td>/Users/yoohajun/Desktop/grad_audio/diffusion/t...</td>\n      <td>저 놈 잡아라</td>\n      <td>절도범죄</td>\n      <td>[-4.010353088378906, -3.603227138519287, -10.2...</td>\n      <td>[-1.1488778591156006, 0.18310293555259705, -0....</td>\n    </tr>\n    <tr>\n      <th>405</th>\n      <td>405</td>\n      <td>3.절도범죄_1240989_label</td>\n      <td>/Users/yoohajun/Desktop/grad_audio/diffusion/t...</td>\n      <td>저 놈 잡아라</td>\n      <td>절도범죄</td>\n      <td>[-15.072626113891602, 3.24332594871521, -8.771...</td>\n      <td>[-1.1488778591156006, 0.18310293555259705, -0....</td>\n    </tr>\n    <tr>\n      <th>406</th>\n      <td>406</td>\n      <td>4.폭력범죄_866862_label</td>\n      <td>/Users/yoohajun/Desktop/grad_audio/diffusion/t...</td>\n      <td>아 그만하세요</td>\n      <td>폭력범죄</td>\n      <td>[17.879575729370117, -11.716965675354004, -6.4...</td>\n      <td>[-1.759752631187439, -0.9184098839759827, -0.3...</td>\n    </tr>\n  </tbody>\n</table>\n<p>407 rows × 7 columns</p>\n</div>"
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Decision Diffusion Method with ML"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import ast"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [],
   "source": [
    "df = pd.read_csv('./audio_text_label.csv', encoding='utf8')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [
    {
     "data": {
      "text/plain": "   Unnamed: 0.1  Unnamed: 0            audio_id  \\\n0             0           0  15.실내_906628_label   \n1             1           1  15.실내_903897_label   \n2             2           2  15.실내_918134_label   \n3             3           3  15.실내_654528_label   \n4             4           4  15.실내_661859_label   \n\n                                           audio_dir   note category_02  \\\n0  /Users/yoohajun/Desktop/grad_audio/diffusion/t...  empty          실내   \n1  /Users/yoohajun/Desktop/grad_audio/diffusion/t...  empty          실내   \n2  /Users/yoohajun/Desktop/grad_audio/diffusion/t...  empty          실내   \n3  /Users/yoohajun/Desktop/grad_audio/diffusion/t...  empty          실내   \n4  /Users/yoohajun/Desktop/grad_audio/diffusion/t...  empty          실내   \n\n                                    audio_prediction  \\\n0  [-11.508453369140625, -8.252114295959473, -23....   \n1  [17.464433670043945, -21.854764938354492, -7.6...   \n2  [3.1379899978637695, 1.7926372289657593, -12.4...   \n3  [28.44495964050293, -16.67407989501953, -4.198...   \n4                     [nan, nan, nan, nan, nan, nan]   \n\n                                     text_prediction  \n0  [1.985169768333435, -1.2518784999847412, 1.072...  \n1  [1.985169768333435, -1.2518784999847412, 1.072...  \n2  [1.985169768333435, -1.2518784999847412, 1.072...  \n3  [1.985169768333435, -1.2518784999847412, 1.072...  \n4  [1.985169768333435, -1.2518784999847412, 1.072...  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Unnamed: 0.1</th>\n      <th>Unnamed: 0</th>\n      <th>audio_id</th>\n      <th>audio_dir</th>\n      <th>note</th>\n      <th>category_02</th>\n      <th>audio_prediction</th>\n      <th>text_prediction</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>0</td>\n      <td>15.실내_906628_label</td>\n      <td>/Users/yoohajun/Desktop/grad_audio/diffusion/t...</td>\n      <td>empty</td>\n      <td>실내</td>\n      <td>[-11.508453369140625, -8.252114295959473, -23....</td>\n      <td>[1.985169768333435, -1.2518784999847412, 1.072...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>1</td>\n      <td>15.실내_903897_label</td>\n      <td>/Users/yoohajun/Desktop/grad_audio/diffusion/t...</td>\n      <td>empty</td>\n      <td>실내</td>\n      <td>[17.464433670043945, -21.854764938354492, -7.6...</td>\n      <td>[1.985169768333435, -1.2518784999847412, 1.072...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>2</td>\n      <td>15.실내_918134_label</td>\n      <td>/Users/yoohajun/Desktop/grad_audio/diffusion/t...</td>\n      <td>empty</td>\n      <td>실내</td>\n      <td>[3.1379899978637695, 1.7926372289657593, -12.4...</td>\n      <td>[1.985169768333435, -1.2518784999847412, 1.072...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>3</td>\n      <td>15.실내_654528_label</td>\n      <td>/Users/yoohajun/Desktop/grad_audio/diffusion/t...</td>\n      <td>empty</td>\n      <td>실내</td>\n      <td>[28.44495964050293, -16.67407989501953, -4.198...</td>\n      <td>[1.985169768333435, -1.2518784999847412, 1.072...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>4</td>\n      <td>15.실내_661859_label</td>\n      <td>/Users/yoohajun/Desktop/grad_audio/diffusion/t...</td>\n      <td>empty</td>\n      <td>실내</td>\n      <td>[nan, nan, nan, nan, nan, nan]</td>\n      <td>[1.985169768333435, -1.2518784999847412, 1.072...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [
    {
     "data": {
      "text/plain": "0    [-11.508453369140625, -8.252114295959473, -23....\n1    [17.464433670043945, -21.854764938354492, -7.6...\n2    [3.1379899978637695, 1.7926372289657593, -12.4...\n3    [28.44495964050293, -16.67407989501953, -4.198...\n4                       [nan, nan, nan, nan, nan, nan]\nName: audio_prediction, dtype: object"
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['audio_prediction'].head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [
    {
     "data": {
      "text/plain": "'[-11.508453369140625, -8.252114295959473, -23.207284927368164, 3.5422844886779785, 8.454593658447266, -5.967389106750488]'"
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['audio_prediction'][0]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [],
   "source": [
    "df['audio_prediction'] = df['audio_prediction'].apply(lambda x: ast.literal_eval(str(x).replace('nan', 'None')))\n",
    "df['text_prediction'] = df['text_prediction'].apply(lambda x: ast.literal_eval(str(x).replace('nan', 'None')))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [],
   "source": [
    "del df['Unnamed: 0']\n",
    "del df['Unnamed: 0.1']"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [
    {
     "data": {
      "text/plain": "                 audio_id                                          audio_dir  \\\n0      15.실내_906628_label  /Users/yoohajun/Desktop/grad_audio/diffusion/t...   \n1      15.실내_903897_label  /Users/yoohajun/Desktop/grad_audio/diffusion/t...   \n2      15.실내_918134_label  /Users/yoohajun/Desktop/grad_audio/diffusion/t...   \n3      15.실내_654528_label  /Users/yoohajun/Desktop/grad_audio/diffusion/t...   \n4      15.실내_661859_label  /Users/yoohajun/Desktop/grad_audio/diffusion/t...   \n..                    ...                                                ...   \n402  3.절도범죄_1240207_label  /Users/yoohajun/Desktop/grad_audio/diffusion/t...   \n403  3.절도범죄_1240211_label  /Users/yoohajun/Desktop/grad_audio/diffusion/t...   \n404  3.절도범죄_1240983_label  /Users/yoohajun/Desktop/grad_audio/diffusion/t...   \n405  3.절도범죄_1240989_label  /Users/yoohajun/Desktop/grad_audio/diffusion/t...   \n406   4.폭력범죄_866862_label  /Users/yoohajun/Desktop/grad_audio/diffusion/t...   \n\n          note category_02                                   audio_prediction  \\\n0        empty          실내  [-11.508453369140625, -8.252114295959473, -23....   \n1        empty          실내  [17.464433670043945, -21.854764938354492, -7.6...   \n2        empty          실내  [3.1379899978637695, 1.7926372289657593, -12.4...   \n3        empty          실내  [28.44495964050293, -16.67407989501953, -4.198...   \n4        empty          실내               [None, None, None, None, None, None]   \n..         ...         ...                                                ...   \n402  소매치기 잡아라         절도범죄  [-1.3769102096557617, 4.8432111740112305, -11....   \n403   소매치기 잡아라        절도범죄  [-4.723093509674072, -8.860213279724121, -11.5...   \n404    저 놈 잡아라        절도범죄  [-4.010353088378906, -3.603227138519287, -10.2...   \n405   저 놈 잡아라         절도범죄  [-15.072626113891602, 3.24332594871521, -8.771...   \n406    아 그만하세요        폭력범죄  [17.879575729370117, -11.716965675354004, -6.4...   \n\n                                       text_prediction  \n0    [1.985169768333435, -1.2518784999847412, 1.072...  \n1    [1.985169768333435, -1.2518784999847412, 1.072...  \n2    [1.985169768333435, -1.2518784999847412, 1.072...  \n3    [1.985169768333435, -1.2518784999847412, 1.072...  \n4    [1.985169768333435, -1.2518784999847412, 1.072...  \n..                                                 ...  \n402  [-0.8364552855491638, -0.4790562391281128, -0....  \n403  [-0.8364552855491638, -0.4790562391281128, -0....  \n404  [-1.1488778591156006, 0.18310293555259705, -0....  \n405  [-1.1488778591156006, 0.18310293555259705, -0....  \n406  [-1.759752631187439, -0.9184098839759827, -0.3...  \n\n[407 rows x 6 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>audio_id</th>\n      <th>audio_dir</th>\n      <th>note</th>\n      <th>category_02</th>\n      <th>audio_prediction</th>\n      <th>text_prediction</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>15.실내_906628_label</td>\n      <td>/Users/yoohajun/Desktop/grad_audio/diffusion/t...</td>\n      <td>empty</td>\n      <td>실내</td>\n      <td>[-11.508453369140625, -8.252114295959473, -23....</td>\n      <td>[1.985169768333435, -1.2518784999847412, 1.072...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>15.실내_903897_label</td>\n      <td>/Users/yoohajun/Desktop/grad_audio/diffusion/t...</td>\n      <td>empty</td>\n      <td>실내</td>\n      <td>[17.464433670043945, -21.854764938354492, -7.6...</td>\n      <td>[1.985169768333435, -1.2518784999847412, 1.072...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>15.실내_918134_label</td>\n      <td>/Users/yoohajun/Desktop/grad_audio/diffusion/t...</td>\n      <td>empty</td>\n      <td>실내</td>\n      <td>[3.1379899978637695, 1.7926372289657593, -12.4...</td>\n      <td>[1.985169768333435, -1.2518784999847412, 1.072...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>15.실내_654528_label</td>\n      <td>/Users/yoohajun/Desktop/grad_audio/diffusion/t...</td>\n      <td>empty</td>\n      <td>실내</td>\n      <td>[28.44495964050293, -16.67407989501953, -4.198...</td>\n      <td>[1.985169768333435, -1.2518784999847412, 1.072...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>15.실내_661859_label</td>\n      <td>/Users/yoohajun/Desktop/grad_audio/diffusion/t...</td>\n      <td>empty</td>\n      <td>실내</td>\n      <td>[None, None, None, None, None, None]</td>\n      <td>[1.985169768333435, -1.2518784999847412, 1.072...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>402</th>\n      <td>3.절도범죄_1240207_label</td>\n      <td>/Users/yoohajun/Desktop/grad_audio/diffusion/t...</td>\n      <td>소매치기 잡아라</td>\n      <td>절도범죄</td>\n      <td>[-1.3769102096557617, 4.8432111740112305, -11....</td>\n      <td>[-0.8364552855491638, -0.4790562391281128, -0....</td>\n    </tr>\n    <tr>\n      <th>403</th>\n      <td>3.절도범죄_1240211_label</td>\n      <td>/Users/yoohajun/Desktop/grad_audio/diffusion/t...</td>\n      <td>소매치기 잡아라</td>\n      <td>절도범죄</td>\n      <td>[-4.723093509674072, -8.860213279724121, -11.5...</td>\n      <td>[-0.8364552855491638, -0.4790562391281128, -0....</td>\n    </tr>\n    <tr>\n      <th>404</th>\n      <td>3.절도범죄_1240983_label</td>\n      <td>/Users/yoohajun/Desktop/grad_audio/diffusion/t...</td>\n      <td>저 놈 잡아라</td>\n      <td>절도범죄</td>\n      <td>[-4.010353088378906, -3.603227138519287, -10.2...</td>\n      <td>[-1.1488778591156006, 0.18310293555259705, -0....</td>\n    </tr>\n    <tr>\n      <th>405</th>\n      <td>3.절도범죄_1240989_label</td>\n      <td>/Users/yoohajun/Desktop/grad_audio/diffusion/t...</td>\n      <td>저 놈 잡아라</td>\n      <td>절도범죄</td>\n      <td>[-15.072626113891602, 3.24332594871521, -8.771...</td>\n      <td>[-1.1488778591156006, 0.18310293555259705, -0....</td>\n    </tr>\n    <tr>\n      <th>406</th>\n      <td>4.폭력범죄_866862_label</td>\n      <td>/Users/yoohajun/Desktop/grad_audio/diffusion/t...</td>\n      <td>아 그만하세요</td>\n      <td>폭력범죄</td>\n      <td>[17.879575729370117, -11.716965675354004, -6.4...</td>\n      <td>[-1.759752631187439, -0.9184098839759827, -0.3...</td>\n    </tr>\n  </tbody>\n</table>\n<p>407 rows × 6 columns</p>\n</div>"
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [],
   "source": [
    "new_df = df[['audio_prediction', 'text_prediction', 'category_02']]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [
    {
     "data": {
      "text/plain": "[-11.508453369140625,\n -8.252114295959473,\n -23.207284927368164,\n 3.5422844886779785,\n 8.454593658447266,\n -5.967389106750488]"
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df['audio_prediction'][0]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [
    {
     "data": {
      "text/plain": "                                      audio_prediction  \\\n0    [-11.508453369140625, -8.252114295959473, -23....   \n1    [17.464433670043945, -21.854764938354492, -7.6...   \n2    [3.1379899978637695, 1.7926372289657593, -12.4...   \n3    [28.44495964050293, -16.67407989501953, -4.198...   \n4                 [None, None, None, None, None, None]   \n..                                                 ...   \n402  [-1.3769102096557617, 4.8432111740112305, -11....   \n403  [-4.723093509674072, -8.860213279724121, -11.5...   \n404  [-4.010353088378906, -3.603227138519287, -10.2...   \n405  [-15.072626113891602, 3.24332594871521, -8.771...   \n406  [17.879575729370117, -11.716965675354004, -6.4...   \n\n                                       text_prediction category_02  \n0    [1.985169768333435, -1.2518784999847412, 1.072...          실내  \n1    [1.985169768333435, -1.2518784999847412, 1.072...          실내  \n2    [1.985169768333435, -1.2518784999847412, 1.072...          실내  \n3    [1.985169768333435, -1.2518784999847412, 1.072...          실내  \n4    [1.985169768333435, -1.2518784999847412, 1.072...          실내  \n..                                                 ...         ...  \n402  [-0.8364552855491638, -0.4790562391281128, -0....        절도범죄  \n403  [-0.8364552855491638, -0.4790562391281128, -0....        절도범죄  \n404  [-1.1488778591156006, 0.18310293555259705, -0....        절도범죄  \n405  [-1.1488778591156006, 0.18310293555259705, -0....        절도범죄  \n406  [-1.759752631187439, -0.9184098839759827, -0.3...        폭력범죄  \n\n[407 rows x 3 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>audio_prediction</th>\n      <th>text_prediction</th>\n      <th>category_02</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>[-11.508453369140625, -8.252114295959473, -23....</td>\n      <td>[1.985169768333435, -1.2518784999847412, 1.072...</td>\n      <td>실내</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>[17.464433670043945, -21.854764938354492, -7.6...</td>\n      <td>[1.985169768333435, -1.2518784999847412, 1.072...</td>\n      <td>실내</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>[3.1379899978637695, 1.7926372289657593, -12.4...</td>\n      <td>[1.985169768333435, -1.2518784999847412, 1.072...</td>\n      <td>실내</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>[28.44495964050293, -16.67407989501953, -4.198...</td>\n      <td>[1.985169768333435, -1.2518784999847412, 1.072...</td>\n      <td>실내</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>[None, None, None, None, None, None]</td>\n      <td>[1.985169768333435, -1.2518784999847412, 1.072...</td>\n      <td>실내</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>402</th>\n      <td>[-1.3769102096557617, 4.8432111740112305, -11....</td>\n      <td>[-0.8364552855491638, -0.4790562391281128, -0....</td>\n      <td>절도범죄</td>\n    </tr>\n    <tr>\n      <th>403</th>\n      <td>[-4.723093509674072, -8.860213279724121, -11.5...</td>\n      <td>[-0.8364552855491638, -0.4790562391281128, -0....</td>\n      <td>절도범죄</td>\n    </tr>\n    <tr>\n      <th>404</th>\n      <td>[-4.010353088378906, -3.603227138519287, -10.2...</td>\n      <td>[-1.1488778591156006, 0.18310293555259705, -0....</td>\n      <td>절도범죄</td>\n    </tr>\n    <tr>\n      <th>405</th>\n      <td>[-15.072626113891602, 3.24332594871521, -8.771...</td>\n      <td>[-1.1488778591156006, 0.18310293555259705, -0....</td>\n      <td>절도범죄</td>\n    </tr>\n    <tr>\n      <th>406</th>\n      <td>[17.879575729370117, -11.716965675354004, -6.4...</td>\n      <td>[-1.759752631187439, -0.9184098839759827, -0.3...</td>\n      <td>폭력범죄</td>\n    </tr>\n  </tbody>\n</table>\n<p>407 rows × 3 columns</p>\n</div>"
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [],
   "source": [
    "target = new_df['category_02']"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [],
   "source": [
    "# audio_prob_df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/3p/vhd92h0x7cb73w5m2xzsn2jr0000gn/T/ipykernel_41525/1414785187.py:1: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  audio_prob_df = new_df['audio_prediction'].apply(pd.Series)\n"
     ]
    }
   ],
   "source": [
    "audio_prob_df = new_df['audio_prediction'].apply(pd.Series)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [
    {
     "data": {
      "text/plain": "             0          1          2          3          4          5\n0   -11.508453  -8.252114 -23.207285   3.542284   8.454594  -5.967389\n1    17.464434 -21.854765  -7.678674  -4.887698 -21.380985  -1.747072\n2     3.137990   1.792637 -12.433538 -23.451603   1.165656   8.441647\n3    28.444960 -16.674080  -4.198120 -16.081032 -18.207804  -3.304222\n4          NaN        NaN        NaN        NaN        NaN        NaN\n..         ...        ...        ...        ...        ...        ...\n402  -1.376910   4.843211 -11.274698 -16.632980   2.652317   3.715904\n403  -4.723094  -8.860213 -11.551517 -16.616116  -9.978647  20.510338\n404  -4.010353  -3.603227 -10.285007 -21.263302  -0.790818  12.896317\n405 -15.072626   3.243326  -8.771307 -17.382805   6.553047   4.722164\n406  17.879576 -11.716966  -6.413388 -27.405533  -9.853685   8.591928\n\n[407 rows x 6 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n      <th>5</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>-11.508453</td>\n      <td>-8.252114</td>\n      <td>-23.207285</td>\n      <td>3.542284</td>\n      <td>8.454594</td>\n      <td>-5.967389</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>17.464434</td>\n      <td>-21.854765</td>\n      <td>-7.678674</td>\n      <td>-4.887698</td>\n      <td>-21.380985</td>\n      <td>-1.747072</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3.137990</td>\n      <td>1.792637</td>\n      <td>-12.433538</td>\n      <td>-23.451603</td>\n      <td>1.165656</td>\n      <td>8.441647</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>28.444960</td>\n      <td>-16.674080</td>\n      <td>-4.198120</td>\n      <td>-16.081032</td>\n      <td>-18.207804</td>\n      <td>-3.304222</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>402</th>\n      <td>-1.376910</td>\n      <td>4.843211</td>\n      <td>-11.274698</td>\n      <td>-16.632980</td>\n      <td>2.652317</td>\n      <td>3.715904</td>\n    </tr>\n    <tr>\n      <th>403</th>\n      <td>-4.723094</td>\n      <td>-8.860213</td>\n      <td>-11.551517</td>\n      <td>-16.616116</td>\n      <td>-9.978647</td>\n      <td>20.510338</td>\n    </tr>\n    <tr>\n      <th>404</th>\n      <td>-4.010353</td>\n      <td>-3.603227</td>\n      <td>-10.285007</td>\n      <td>-21.263302</td>\n      <td>-0.790818</td>\n      <td>12.896317</td>\n    </tr>\n    <tr>\n      <th>405</th>\n      <td>-15.072626</td>\n      <td>3.243326</td>\n      <td>-8.771307</td>\n      <td>-17.382805</td>\n      <td>6.553047</td>\n      <td>4.722164</td>\n    </tr>\n    <tr>\n      <th>406</th>\n      <td>17.879576</td>\n      <td>-11.716966</td>\n      <td>-6.413388</td>\n      <td>-27.405533</td>\n      <td>-9.853685</td>\n      <td>8.591928</td>\n    </tr>\n  </tbody>\n</table>\n<p>407 rows × 6 columns</p>\n</div>"
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "audio_prob_df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [
    {
     "data": {
      "text/plain": "     audio_prob_0  audio_prob_1  audio_prob_2  audio_prob_3  audio_prob_4  \\\n0      -11.508453     -8.252114    -23.207285      3.542284      8.454594   \n1       17.464434    -21.854765     -7.678674     -4.887698    -21.380985   \n2        3.137990      1.792637    -12.433538    -23.451603      1.165656   \n3       28.444960    -16.674080     -4.198120    -16.081032    -18.207804   \n4             NaN           NaN           NaN           NaN           NaN   \n..            ...           ...           ...           ...           ...   \n402     -1.376910      4.843211    -11.274698    -16.632980      2.652317   \n403     -4.723094     -8.860213    -11.551517    -16.616116     -9.978647   \n404     -4.010353     -3.603227    -10.285007    -21.263302     -0.790818   \n405    -15.072626      3.243326     -8.771307    -17.382805      6.553047   \n406     17.879576    -11.716966     -6.413388    -27.405533     -9.853685   \n\n     audio_prob_5  \n0       -5.967389  \n1       -1.747072  \n2        8.441647  \n3       -3.304222  \n4             NaN  \n..            ...  \n402      3.715904  \n403     20.510338  \n404     12.896317  \n405      4.722164  \n406      8.591928  \n\n[407 rows x 6 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>audio_prob_0</th>\n      <th>audio_prob_1</th>\n      <th>audio_prob_2</th>\n      <th>audio_prob_3</th>\n      <th>audio_prob_4</th>\n      <th>audio_prob_5</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>-11.508453</td>\n      <td>-8.252114</td>\n      <td>-23.207285</td>\n      <td>3.542284</td>\n      <td>8.454594</td>\n      <td>-5.967389</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>17.464434</td>\n      <td>-21.854765</td>\n      <td>-7.678674</td>\n      <td>-4.887698</td>\n      <td>-21.380985</td>\n      <td>-1.747072</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3.137990</td>\n      <td>1.792637</td>\n      <td>-12.433538</td>\n      <td>-23.451603</td>\n      <td>1.165656</td>\n      <td>8.441647</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>28.444960</td>\n      <td>-16.674080</td>\n      <td>-4.198120</td>\n      <td>-16.081032</td>\n      <td>-18.207804</td>\n      <td>-3.304222</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>402</th>\n      <td>-1.376910</td>\n      <td>4.843211</td>\n      <td>-11.274698</td>\n      <td>-16.632980</td>\n      <td>2.652317</td>\n      <td>3.715904</td>\n    </tr>\n    <tr>\n      <th>403</th>\n      <td>-4.723094</td>\n      <td>-8.860213</td>\n      <td>-11.551517</td>\n      <td>-16.616116</td>\n      <td>-9.978647</td>\n      <td>20.510338</td>\n    </tr>\n    <tr>\n      <th>404</th>\n      <td>-4.010353</td>\n      <td>-3.603227</td>\n      <td>-10.285007</td>\n      <td>-21.263302</td>\n      <td>-0.790818</td>\n      <td>12.896317</td>\n    </tr>\n    <tr>\n      <th>405</th>\n      <td>-15.072626</td>\n      <td>3.243326</td>\n      <td>-8.771307</td>\n      <td>-17.382805</td>\n      <td>6.553047</td>\n      <td>4.722164</td>\n    </tr>\n    <tr>\n      <th>406</th>\n      <td>17.879576</td>\n      <td>-11.716966</td>\n      <td>-6.413388</td>\n      <td>-27.405533</td>\n      <td>-9.853685</td>\n      <td>8.591928</td>\n    </tr>\n  </tbody>\n</table>\n<p>407 rows × 6 columns</p>\n</div>"
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c = ['audio_prob_{}'.format(i) for i in range(6)]\n",
    "audio_prob_df.columns = c\n",
    "audio_prob_df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [],
   "source": [
    "audio_means = audio_prob_df.mean()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [],
   "source": [
    "audio_prob_df = audio_prob_df.fillna(value=audio_means)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/pytorch-grad/lib/python3.8/site-packages/numpy/lib/shape_base.py:652: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  arr = asanyarray(v)\n"
     ]
    },
    {
     "data": {
      "text/plain": "[-11.508453369140625,\n -8.252114295959473,\n -23.207284927368164,\n 3.5422844886779785,\n 8.454593658447266,\n -5.967389106750488]"
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v = np.column_stack([df.audio_prediction.values.tolist()])\n",
    "v[0][0]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "outputs": [
    {
     "data": {
      "text/plain": "     text_prob_0  text_prob_1  text_prob_2  text_prob_3  text_prob_4  \\\n0       1.985170    -1.251878     1.072886    -1.533072    -1.373477   \n1       1.985170    -1.251878     1.072886    -1.533072    -1.373477   \n2       1.985170    -1.251878     1.072886    -1.533072    -1.373477   \n3       1.985170    -1.251878     1.072886    -1.533072    -1.373477   \n4       1.985170    -1.251878     1.072886    -1.533072    -1.373477   \n..           ...          ...          ...          ...          ...   \n402    -0.836455    -0.479056    -0.917581    -0.670842     3.972445   \n403    -0.836455    -0.479056    -0.917581    -0.670842     3.972445   \n404    -1.148878     0.183103    -0.968534    -0.681608     3.823746   \n405    -1.148878     0.183103    -0.968534    -0.681608     3.823746   \n406    -1.759753    -0.918410    -0.340287    -0.060154    -1.222856   \n\n     text_prob_5  \n0       1.073765  \n1       1.073765  \n2       1.073765  \n3       1.073765  \n4       1.073765  \n..           ...  \n402    -0.816911  \n403    -0.816911  \n404    -0.802174  \n405    -0.802174  \n406     3.638456  \n\n[407 rows x 6 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text_prob_0</th>\n      <th>text_prob_1</th>\n      <th>text_prob_2</th>\n      <th>text_prob_3</th>\n      <th>text_prob_4</th>\n      <th>text_prob_5</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1.985170</td>\n      <td>-1.251878</td>\n      <td>1.072886</td>\n      <td>-1.533072</td>\n      <td>-1.373477</td>\n      <td>1.073765</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1.985170</td>\n      <td>-1.251878</td>\n      <td>1.072886</td>\n      <td>-1.533072</td>\n      <td>-1.373477</td>\n      <td>1.073765</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1.985170</td>\n      <td>-1.251878</td>\n      <td>1.072886</td>\n      <td>-1.533072</td>\n      <td>-1.373477</td>\n      <td>1.073765</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1.985170</td>\n      <td>-1.251878</td>\n      <td>1.072886</td>\n      <td>-1.533072</td>\n      <td>-1.373477</td>\n      <td>1.073765</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1.985170</td>\n      <td>-1.251878</td>\n      <td>1.072886</td>\n      <td>-1.533072</td>\n      <td>-1.373477</td>\n      <td>1.073765</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>402</th>\n      <td>-0.836455</td>\n      <td>-0.479056</td>\n      <td>-0.917581</td>\n      <td>-0.670842</td>\n      <td>3.972445</td>\n      <td>-0.816911</td>\n    </tr>\n    <tr>\n      <th>403</th>\n      <td>-0.836455</td>\n      <td>-0.479056</td>\n      <td>-0.917581</td>\n      <td>-0.670842</td>\n      <td>3.972445</td>\n      <td>-0.816911</td>\n    </tr>\n    <tr>\n      <th>404</th>\n      <td>-1.148878</td>\n      <td>0.183103</td>\n      <td>-0.968534</td>\n      <td>-0.681608</td>\n      <td>3.823746</td>\n      <td>-0.802174</td>\n    </tr>\n    <tr>\n      <th>405</th>\n      <td>-1.148878</td>\n      <td>0.183103</td>\n      <td>-0.968534</td>\n      <td>-0.681608</td>\n      <td>3.823746</td>\n      <td>-0.802174</td>\n    </tr>\n    <tr>\n      <th>406</th>\n      <td>-1.759753</td>\n      <td>-0.918410</td>\n      <td>-0.340287</td>\n      <td>-0.060154</td>\n      <td>-1.222856</td>\n      <td>3.638456</td>\n    </tr>\n  </tbody>\n</table>\n<p>407 rows × 6 columns</p>\n</div>"
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_prob_df = new_df['text_prediction'].apply(pd.Series)\n",
    "c = ['text_prob_{}'.format(i) for i in range(6)]\n",
    "text_prob_df.columns = c\n",
    "text_prob_df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "outputs": [],
   "source": [
    "text_means = text_prob_df.mean()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "outputs": [],
   "source": [
    "text_prob_df = text_prob_df.fillna(value=text_means)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "outputs": [],
   "source": [
    "# 데이터프레임을 병렬로 연결하기\n",
    "result = pd.concat([audio_prob_df, text_prob_df, target], axis=1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "outputs": [
    {
     "data": {
      "text/plain": "     audio_prob_0  audio_prob_1  audio_prob_2  audio_prob_3  audio_prob_4  \\\n0      -11.508453     -8.252114    -23.207285      3.542284      8.454594   \n1       17.464434    -21.854765     -7.678674     -4.887698    -21.380985   \n2        3.137990      1.792637    -12.433538    -23.451603      1.165656   \n3       28.444960    -16.674080     -4.198120    -16.081032    -18.207804   \n4       -0.446208     -3.118892    -10.164642    -16.763775     -2.070044   \n..            ...           ...           ...           ...           ...   \n402     -1.376910      4.843211    -11.274698    -16.632980      2.652317   \n403     -4.723094     -8.860213    -11.551517    -16.616116     -9.978647   \n404     -4.010353     -3.603227    -10.285007    -21.263302     -0.790818   \n405    -15.072626      3.243326     -8.771307    -17.382805      6.553047   \n406     17.879576    -11.716966     -6.413388    -27.405533     -9.853685   \n\n     audio_prob_5  text_prob_0  text_prob_1  text_prob_2  text_prob_3  \\\n0       -5.967389     1.985170    -1.251878     1.072886    -1.533072   \n1       -1.747072     1.985170    -1.251878     1.072886    -1.533072   \n2        8.441647     1.985170    -1.251878     1.072886    -1.533072   \n3       -3.304222     1.985170    -1.251878     1.072886    -1.533072   \n4        6.610947     1.985170    -1.251878     1.072886    -1.533072   \n..            ...          ...          ...          ...          ...   \n402      3.715904    -0.836455    -0.479056    -0.917581    -0.670842   \n403     20.510338    -0.836455    -0.479056    -0.917581    -0.670842   \n404     12.896317    -1.148878     0.183103    -0.968534    -0.681608   \n405      4.722164    -1.148878     0.183103    -0.968534    -0.681608   \n406      8.591928    -1.759753    -0.918410    -0.340287    -0.060154   \n\n     text_prob_4  text_prob_5 category_02  \n0      -1.373477     1.073765          실내  \n1      -1.373477     1.073765          실내  \n2      -1.373477     1.073765          실내  \n3      -1.373477     1.073765          실내  \n4      -1.373477     1.073765          실내  \n..           ...          ...         ...  \n402     3.972445    -0.816911        절도범죄  \n403     3.972445    -0.816911        절도범죄  \n404     3.823746    -0.802174        절도범죄  \n405     3.823746    -0.802174        절도범죄  \n406    -1.222856     3.638456        폭력범죄  \n\n[407 rows x 13 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>audio_prob_0</th>\n      <th>audio_prob_1</th>\n      <th>audio_prob_2</th>\n      <th>audio_prob_3</th>\n      <th>audio_prob_4</th>\n      <th>audio_prob_5</th>\n      <th>text_prob_0</th>\n      <th>text_prob_1</th>\n      <th>text_prob_2</th>\n      <th>text_prob_3</th>\n      <th>text_prob_4</th>\n      <th>text_prob_5</th>\n      <th>category_02</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>-11.508453</td>\n      <td>-8.252114</td>\n      <td>-23.207285</td>\n      <td>3.542284</td>\n      <td>8.454594</td>\n      <td>-5.967389</td>\n      <td>1.985170</td>\n      <td>-1.251878</td>\n      <td>1.072886</td>\n      <td>-1.533072</td>\n      <td>-1.373477</td>\n      <td>1.073765</td>\n      <td>실내</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>17.464434</td>\n      <td>-21.854765</td>\n      <td>-7.678674</td>\n      <td>-4.887698</td>\n      <td>-21.380985</td>\n      <td>-1.747072</td>\n      <td>1.985170</td>\n      <td>-1.251878</td>\n      <td>1.072886</td>\n      <td>-1.533072</td>\n      <td>-1.373477</td>\n      <td>1.073765</td>\n      <td>실내</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3.137990</td>\n      <td>1.792637</td>\n      <td>-12.433538</td>\n      <td>-23.451603</td>\n      <td>1.165656</td>\n      <td>8.441647</td>\n      <td>1.985170</td>\n      <td>-1.251878</td>\n      <td>1.072886</td>\n      <td>-1.533072</td>\n      <td>-1.373477</td>\n      <td>1.073765</td>\n      <td>실내</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>28.444960</td>\n      <td>-16.674080</td>\n      <td>-4.198120</td>\n      <td>-16.081032</td>\n      <td>-18.207804</td>\n      <td>-3.304222</td>\n      <td>1.985170</td>\n      <td>-1.251878</td>\n      <td>1.072886</td>\n      <td>-1.533072</td>\n      <td>-1.373477</td>\n      <td>1.073765</td>\n      <td>실내</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>-0.446208</td>\n      <td>-3.118892</td>\n      <td>-10.164642</td>\n      <td>-16.763775</td>\n      <td>-2.070044</td>\n      <td>6.610947</td>\n      <td>1.985170</td>\n      <td>-1.251878</td>\n      <td>1.072886</td>\n      <td>-1.533072</td>\n      <td>-1.373477</td>\n      <td>1.073765</td>\n      <td>실내</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>402</th>\n      <td>-1.376910</td>\n      <td>4.843211</td>\n      <td>-11.274698</td>\n      <td>-16.632980</td>\n      <td>2.652317</td>\n      <td>3.715904</td>\n      <td>-0.836455</td>\n      <td>-0.479056</td>\n      <td>-0.917581</td>\n      <td>-0.670842</td>\n      <td>3.972445</td>\n      <td>-0.816911</td>\n      <td>절도범죄</td>\n    </tr>\n    <tr>\n      <th>403</th>\n      <td>-4.723094</td>\n      <td>-8.860213</td>\n      <td>-11.551517</td>\n      <td>-16.616116</td>\n      <td>-9.978647</td>\n      <td>20.510338</td>\n      <td>-0.836455</td>\n      <td>-0.479056</td>\n      <td>-0.917581</td>\n      <td>-0.670842</td>\n      <td>3.972445</td>\n      <td>-0.816911</td>\n      <td>절도범죄</td>\n    </tr>\n    <tr>\n      <th>404</th>\n      <td>-4.010353</td>\n      <td>-3.603227</td>\n      <td>-10.285007</td>\n      <td>-21.263302</td>\n      <td>-0.790818</td>\n      <td>12.896317</td>\n      <td>-1.148878</td>\n      <td>0.183103</td>\n      <td>-0.968534</td>\n      <td>-0.681608</td>\n      <td>3.823746</td>\n      <td>-0.802174</td>\n      <td>절도범죄</td>\n    </tr>\n    <tr>\n      <th>405</th>\n      <td>-15.072626</td>\n      <td>3.243326</td>\n      <td>-8.771307</td>\n      <td>-17.382805</td>\n      <td>6.553047</td>\n      <td>4.722164</td>\n      <td>-1.148878</td>\n      <td>0.183103</td>\n      <td>-0.968534</td>\n      <td>-0.681608</td>\n      <td>3.823746</td>\n      <td>-0.802174</td>\n      <td>절도범죄</td>\n    </tr>\n    <tr>\n      <th>406</th>\n      <td>17.879576</td>\n      <td>-11.716966</td>\n      <td>-6.413388</td>\n      <td>-27.405533</td>\n      <td>-9.853685</td>\n      <td>8.591928</td>\n      <td>-1.759753</td>\n      <td>-0.918410</td>\n      <td>-0.340287</td>\n      <td>-0.060154</td>\n      <td>-1.222856</td>\n      <td>3.638456</td>\n      <td>폭력범죄</td>\n    </tr>\n  </tbody>\n</table>\n<p>407 rows × 13 columns</p>\n</div>"
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "outputs": [],
   "source": [
    "result.to_csv('./result_probability.csv')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "outputs": [],
   "source": [
    "X = result.drop('category_02', axis=1)\n",
    "y = result['category_02']"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "outputs": [],
   "source": [
    "# 탐색할 매개변수들을 딕셔너리 형태로 정의\n",
    "param_grid = {\n",
    "    'criterion': ['gini', 'entropy'],\n",
    "    'max_depth': [2, 3, 4, 5, 6, 7, 8, 9, 10],\n",
    "    'min_samples_split': [2, 3, 4, 5],\n",
    "    'min_samples_leaf': [1, 2, 3, 4, 5],\n",
    "}\n",
    "# 분류 알고리즘 생성하기\n",
    "clf = DecisionTreeClassifier()\n",
    "\n",
    "# GridSearchCV 객체 생성\n",
    "grid_search = GridSearchCV(estimator=clf, param_grid=param_grid, cv=5)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "outputs": [
    {
     "data": {
      "text/plain": "GridSearchCV(cv=5, estimator=DecisionTreeClassifier(),\n             param_grid={'criterion': ['gini', 'entropy'],\n                         'max_depth': [2, 3, 4, 5, 6, 7, 8, 9, 10],\n                         'min_samples_leaf': [1, 2, 3, 4, 5],\n                         'min_samples_split': [2, 3, 4, 5]})",
      "text/html": "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=5, estimator=DecisionTreeClassifier(),\n             param_grid={&#x27;criterion&#x27;: [&#x27;gini&#x27;, &#x27;entropy&#x27;],\n                         &#x27;max_depth&#x27;: [2, 3, 4, 5, 6, 7, 8, 9, 10],\n                         &#x27;min_samples_leaf&#x27;: [1, 2, 3, 4, 5],\n                         &#x27;min_samples_split&#x27;: [2, 3, 4, 5]})</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=5, estimator=DecisionTreeClassifier(),\n             param_grid={&#x27;criterion&#x27;: [&#x27;gini&#x27;, &#x27;entropy&#x27;],\n                         &#x27;max_depth&#x27;: [2, 3, 4, 5, 6, 7, 8, 9, 10],\n                         &#x27;min_samples_leaf&#x27;: [1, 2, 3, 4, 5],\n                         &#x27;min_samples_split&#x27;: [2, 3, 4, 5]})</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: DecisionTreeClassifier</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeClassifier()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DecisionTreeClassifier</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeClassifier()</pre></div></div></div></div></div></div></div></div></div></div>"
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 분류 알고리즘 학습시키기\n",
    "grid_search.fit(X_train, y_train)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8902439024390244\n"
     ]
    }
   ],
   "source": [
    "# 테스트 데이터로 성능 평가하기\n",
    "accuracy = grid_search.score(X_test, y_test)\n",
    "print(\"Accuracy:\", accuracy)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "pickle.dump(grid_search, open('./DT_model.pkl', 'wb'))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['실내' '강제추행(성범죄)' '실내']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/pytorch-grad/lib/python3.8/site-packages/sklearn/base.py:420: UserWarning: X does not have valid feature names, but DecisionTreeClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# 예측하기\n",
    "new_data = [[-9.0, 3.0, -5.0, 2.0, 1.0, 0.0, 10.0, -5.0, 2.0, -3.0, 4.0, -1.0],\n",
    "            [15.2371187210083, -2.6208269596099854, -12.99371337890625, -14.600499153137207, -12.526419639587402, 5.471261501312256, -1.2606452703475952, -1.0324167013168335, -1.0932425260543823, 4.17419958114624, -0.9211591482162476, -0.3627887964248657],\n",
    "            [-5.0, -10.0, -2.0, 2.0, -1.0, 3.0, 10.0, -5.0, 2.0, -3.0, 4.0, -1.0]]\n",
    "\n",
    "prediction = grid_search.predict(new_data)\n",
    "\n",
    "print(prediction)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "pytorch-grad",
   "language": "python",
   "display_name": "Python3.8(tc1.10)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}