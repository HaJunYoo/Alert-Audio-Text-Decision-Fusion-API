{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-22T10:19:22.269112Z",
     "start_time": "2023-03-22T10:19:18.999770Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import librosa\n",
    "import numpy as np\n",
    "\n",
    "import os\n",
    "import time\n",
    "\n",
    "import boto3\n",
    "from botocore.exceptions import ClientError\n",
    "\n",
    "import gluonnlp as nlp\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from transformers import AutoTokenizer\n",
    "from kobert.pytorch_kobert import get_pytorch_kobert_model\n",
    "from kobert.utils import get_tokenizer\n",
    "\n",
    "from torchvision.models.resnet import ResNet, BasicBlock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-22T10:19:25.296841Z",
     "start_time": "2023-03-22T10:19:25.275654Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# BERT 모델, Vocabulary 불러오기\n",
    "class BERTClassifier(nn.Module):\n",
    "    def __init__(self,\n",
    "                 bert,\n",
    "                 hidden_size=768,\n",
    "                 num_classes=6,  ##클래스 수 조정##\n",
    "                 dr_rate=None,\n",
    "                 params=None):\n",
    "        super(BERTClassifier, self).__init__()\n",
    "        self.bert = bert\n",
    "        self.dr_rate = dr_rate\n",
    "\n",
    "        self.classifier = nn.Linear(hidden_size, num_classes)\n",
    "        if dr_rate:\n",
    "            self.dropout = nn.Dropout(p=dr_rate)\n",
    "\n",
    "    def gen_attention_mask(self, token_ids, valid_length):\n",
    "        attention_mask = torch.zeros_like(token_ids)\n",
    "        for i, v in enumerate(valid_length):\n",
    "            attention_mask[i][:v] = 1\n",
    "        return attention_mask.float()\n",
    "\n",
    "    def forward(self, token_ids, valid_length, segment_ids):\n",
    "        attention_mask = self.gen_attention_mask(token_ids, valid_length)\n",
    "\n",
    "        _, pooler = self.bert(input_ids=token_ids, token_type_ids=segment_ids.long(),\n",
    "                              attention_mask=attention_mask.float().to(token_ids.device), return_dict=False)\n",
    "        if self.dr_rate:\n",
    "            out = self.dropout(pooler)\n",
    "        return self.classifier(out)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class BERTDataset(Dataset):\n",
    "    def __init__(self, dataset, sent_idx, label_idx, bert_tokenizer, vocab, max_len,\n",
    "                 pad, pair):\n",
    "        transform = nlp.data.BERTSentenceTransform(\n",
    "            bert_tokenizer, max_seq_length=max_len, vocab=vocab, pad=pad, pair=pair)\n",
    "\n",
    "        self.sentences = [transform([i[sent_idx]]) for i in dataset]\n",
    "        self.labels = [np.int32(i[label_idx]) for i in dataset]\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        return (self.sentences[i] + (self.labels[i],))\n",
    "\n",
    "    def __len__(self):\n",
    "        return (len(self.labels))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class ResNetModel(ResNet):\n",
    "    def __init__(self, num_classes=6):\n",
    "        super(ResNetModel, self).__init__(BasicBlock, [2, 2, 2, 2], num_classes=num_classes)\n",
    "        self.conv1 = nn.Conv2d(4, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool(x)\n",
    "\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "\n",
    "        x = self.avgpool(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "device = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading BERT model...\n",
      "using cached model. /Users/yoohajun/Library/Mobile Documents/com~apple~CloudDocs/Hajun/Graduate_project/fastapi/Diffusion/.cache/kobert_v1.zip\n",
      "using cached model. /Users/yoohajun/Library/Mobile Documents/com~apple~CloudDocs/Hajun/Graduate_project/fastapi/Diffusion/.cache/kobert_news_wiki_ko_cased-1087f8699e.spiece\n",
      "Loading BERT tokenizer...\n",
      "using cached model. /Users/yoohajun/Library/Mobile Documents/com~apple~CloudDocs/Hajun/Graduate_project/fastapi/Diffusion/.cache/kobert_news_wiki_ko_cased-1087f8699e.spiece\n"
     ]
    },
    {
     "data": {
      "text/plain": "<All keys matched successfully>"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Setting prediction parameters\n",
    "max_len = 60\n",
    "batch_size = 64\n",
    "learning_rate = 5e-5\n",
    "\n",
    "print(\"Loading BERT model...\")\n",
    "# Load pre-trained model (weights)\n",
    "bertmodel, vocab = get_pytorch_kobert_model()\n",
    "\n",
    "# Load tokenizer from a local directory\n",
    "# kobert_tokenizer = AutoTokenizer.from_pretrained(\"kobert_tokenizer\", use_fast=False)\n",
    "# tok = kobert_tokenizer.tokenize\n",
    "print(\"Loading BERT tokenizer...\")\n",
    "tokenizer = get_tokenizer()\n",
    "tok = nlp.data.BERTSPTokenizer(tokenizer, vocab, lower=False)\n",
    "\n",
    "PATH = '/Users/yoohajun/Library/Mobile Documents/com~apple~CloudDocs/Hajun/Graduate_project/fastapi/KoBERT/'\n",
    "kobert_model = BERTClassifier(bertmodel, dr_rate=0.5)\n",
    "kobert_model.load_state_dict(torch.load(PATH + 'model_state_dict.pt', map_location=device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "<All keys matched successfully>"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the path to the saved model\n",
    "model_path = '/Users/yoohajun/Library/Mobile Documents/com~apple~CloudDocs/Hajun/Graduate_project/fastapi/resnet-model/pytorch_resnet.pt'\n",
    "# Load the saved model\n",
    "checkpoint = torch.load(model_path, map_location=torch.device('cpu'))\n",
    "resnet_model = ResNetModel(num_classes=6)\n",
    "resnet_model.load_state_dict(checkpoint['model_state_dict'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def scale_to_range(arr, target_range=(0, 1)):\n",
    "    # Calculate exponential values for each element\n",
    "    exp_arr = np.exp(arr)\n",
    "\n",
    "    # Calculate the sum of all exponential values\n",
    "    exp_sum = np.sum(exp_arr)\n",
    "\n",
    "    # Calculate probability for each element by dividing its exponential value by the sum\n",
    "    probs = exp_arr / exp_sum\n",
    "\n",
    "    # Scale probabilities to target range\n",
    "    scaled = (probs * (target_range[1] - target_range[0])) + target_range[0]\n",
    "\n",
    "    return scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def softmax(vals, idx):\n",
    "    valscpu = vals.cpu().detach().squeeze(0)\n",
    "    a = 0\n",
    "    for i in valscpu:\n",
    "        a += np.exp(i)\n",
    "    return ((np.exp(valscpu[idx])) / a).item() * 100\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def text_predict(predict_sentence, model=kobert_model):\n",
    "    # print(\"predictsentence start:\", predict_sentence)\n",
    "    start = time.time()\n",
    "    text_label = ['regular', 'help', 'robbery', 'sexual', 'theft', 'violence']\n",
    "    data = [predict_sentence]\n",
    "    # dataset_another = [data]\n",
    "\n",
    "    transform = nlp.data.BERTSentenceTransform(tok, max_len, pad=True, pair=False)\n",
    "    tokenized = transform(data)\n",
    "    model.eval()\n",
    "\n",
    "    # print([tokenized[0]])\n",
    "    # token_ids = torch.tensor([tokenized[0]]).to(device)\n",
    "    # segment_ids = torch.tensor([tokenized[2]]).to(device)\n",
    "    token_ids = torch.tensor(np.array([tokenized[0]])).to(device)\n",
    "    valid_length = [tokenized[1]]\n",
    "    segment_ids = torch.tensor(np.array([tokenized[2]])).to(device)\n",
    "\n",
    "    result = model(token_ids, valid_length, segment_ids)\n",
    "    # print(result)\n",
    "    idx = result.argmax().cpu().item()\n",
    "    out_prob = result.detach().cpu().numpy()[0]\n",
    "    # print(out_prob)\n",
    "    # print(\"대사의 카테고리는:\", text_label[idx])\n",
    "    # print(\"대사 신뢰도는:\", \"{:.2f}%\".format(softmax(result, idx)))\n",
    "    end = time.time() - start\n",
    "    # print(\"text predict 걸린 시간:\", end)\n",
    "    return out_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def audio_predict(file_location, model=resnet_model):\n",
    "    try:\n",
    "        audio_data, sr = librosa.load(file_location, sr=44100, duration=5)\n",
    "\n",
    "        # Define label names\n",
    "        label_names = ['regular', 'help', 'robbery', 'sexual', 'theft', 'violence']\n",
    "\n",
    "        # Calculate the spectrogram of the audio data\n",
    "        spec = librosa.feature.melspectrogram(y=audio_data, sr=sr)\n",
    "\n",
    "        # Convert the spectrogram to decibels\n",
    "        spec_db = librosa.power_to_db(spec, ref=np.max)\n",
    "\n",
    "        # Add an additional channel to the spectrogram\n",
    "        spec_db = np.repeat(spec_db[:, :, np.newaxis], 4, axis=2)\n",
    "\n",
    "        # Resize the spectrogram to match the input shape of the model\n",
    "        spec_resized = np.resize(spec_db, (1, 4, 128, 128))\n",
    "\n",
    "        # Normalize the spectrogram by z-score\n",
    "        mean = np.mean(spec_resized)\n",
    "        std = np.std(spec_resized)\n",
    "        spec_resized = (spec_resized - mean) / std\n",
    "\n",
    "        # Convert the spectrogram to a tensor and move it to the device\n",
    "        spectrogram_tensor = torch.tensor(spec_resized, dtype=torch.float).to(device)\n",
    "\n",
    "        # Set the model to evaluation mode\n",
    "        model.eval()\n",
    "\n",
    "        # Predict the probabilities for each class\n",
    "        with torch.no_grad():\n",
    "            out = model(spectrogram_tensor)\n",
    "\n",
    "        # Get the index of the class with the highest probability\n",
    "        predicted_class_index = torch.argmax(out, dim=1)\n",
    "\n",
    "        label_index = predicted_class_index.item()\n",
    "\n",
    "        # print(\"음성의 카테고리는:\", label_names[label_index])\n",
    "        # print(\"음성 신뢰도는:\", \"{:.2f}%\".format(softmax(out, label_index)))\n",
    "\n",
    "        return out.detach().cpu().numpy()[0]\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f'Error: {e}')\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('./audio_text_diffusion_train.csv', encoding='utf8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": "     Unnamed: 0              audio_id  \\\n0             0    15.실내_906628_label   \n1             1    15.실내_903897_label   \n2             2    15.실내_918134_label   \n3             3    15.실내_654528_label   \n4             4    15.실내_661859_label   \n..          ...                   ...   \n402         402  3.절도범죄_1240207_label   \n403         403  3.절도범죄_1240211_label   \n404         404  3.절도범죄_1240983_label   \n405         405  3.절도범죄_1240989_label   \n406         406   4.폭력범죄_866862_label   \n\n                                             audio_dir       note category_02  \n0    /Users/yoohajun/Desktop/grad_audio/diffusion/t...        NaN          실내  \n1    /Users/yoohajun/Desktop/grad_audio/diffusion/t...        NaN          실내  \n2    /Users/yoohajun/Desktop/grad_audio/diffusion/t...        NaN          실내  \n3    /Users/yoohajun/Desktop/grad_audio/diffusion/t...        NaN          실내  \n4    /Users/yoohajun/Desktop/grad_audio/diffusion/t...        NaN          실내  \n..                                                 ...        ...         ...  \n402  /Users/yoohajun/Desktop/grad_audio/diffusion/t...  소매치기 잡아라         절도범죄  \n403  /Users/yoohajun/Desktop/grad_audio/diffusion/t...   소매치기 잡아라        절도범죄  \n404  /Users/yoohajun/Desktop/grad_audio/diffusion/t...    저 놈 잡아라        절도범죄  \n405  /Users/yoohajun/Desktop/grad_audio/diffusion/t...   저 놈 잡아라         절도범죄  \n406  /Users/yoohajun/Desktop/grad_audio/diffusion/t...    아 그만하세요        폭력범죄  \n\n[407 rows x 5 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Unnamed: 0</th>\n      <th>audio_id</th>\n      <th>audio_dir</th>\n      <th>note</th>\n      <th>category_02</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>15.실내_906628_label</td>\n      <td>/Users/yoohajun/Desktop/grad_audio/diffusion/t...</td>\n      <td>NaN</td>\n      <td>실내</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>15.실내_903897_label</td>\n      <td>/Users/yoohajun/Desktop/grad_audio/diffusion/t...</td>\n      <td>NaN</td>\n      <td>실내</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>15.실내_918134_label</td>\n      <td>/Users/yoohajun/Desktop/grad_audio/diffusion/t...</td>\n      <td>NaN</td>\n      <td>실내</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>15.실내_654528_label</td>\n      <td>/Users/yoohajun/Desktop/grad_audio/diffusion/t...</td>\n      <td>NaN</td>\n      <td>실내</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>15.실내_661859_label</td>\n      <td>/Users/yoohajun/Desktop/grad_audio/diffusion/t...</td>\n      <td>NaN</td>\n      <td>실내</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>402</th>\n      <td>402</td>\n      <td>3.절도범죄_1240207_label</td>\n      <td>/Users/yoohajun/Desktop/grad_audio/diffusion/t...</td>\n      <td>소매치기 잡아라</td>\n      <td>절도범죄</td>\n    </tr>\n    <tr>\n      <th>403</th>\n      <td>403</td>\n      <td>3.절도범죄_1240211_label</td>\n      <td>/Users/yoohajun/Desktop/grad_audio/diffusion/t...</td>\n      <td>소매치기 잡아라</td>\n      <td>절도범죄</td>\n    </tr>\n    <tr>\n      <th>404</th>\n      <td>404</td>\n      <td>3.절도범죄_1240983_label</td>\n      <td>/Users/yoohajun/Desktop/grad_audio/diffusion/t...</td>\n      <td>저 놈 잡아라</td>\n      <td>절도범죄</td>\n    </tr>\n    <tr>\n      <th>405</th>\n      <td>405</td>\n      <td>3.절도범죄_1240989_label</td>\n      <td>/Users/yoohajun/Desktop/grad_audio/diffusion/t...</td>\n      <td>저 놈 잡아라</td>\n      <td>절도범죄</td>\n    </tr>\n    <tr>\n      <th>406</th>\n      <td>406</td>\n      <td>4.폭력범죄_866862_label</td>\n      <td>/Users/yoohajun/Desktop/grad_audio/diffusion/t...</td>\n      <td>아 그만하세요</td>\n      <td>폭력범죄</td>\n    </tr>\n  </tbody>\n</table>\n<p>407 rows × 5 columns</p>\n</div>"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# 음성 파일 id, 음성 파일 경로, note, 음성 파일 븐류 -> 1차 csv\n",
    "\n",
    "# 오디오 확률 리스트, 텍스트 확률 리스트, 라벨\n",
    "\n",
    "# 리스트 nested 해제 , 라벨\n",
    "\n",
    "# diffusion layer ml 학습 - decision tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "# define a function to apply to each row of the DataFrame\n",
    "def add_prediction(row):\n",
    "    # call the audio_predict function with the audio_dir value\n",
    "    audio_prediction = audio_predict(row['audio_dir'])\n",
    "    # add the prediction values as a new column to the DataFrame\n",
    "    if audio_prediction is not None:\n",
    "        # add the prediction values as a new column to the DataFrame\n",
    "        row['audio_prediction'] = audio_prediction.tolist()\n",
    "    else:\n",
    "        row['audio_prediction'] = None\n",
    "\n",
    "    text_prediction = text_predict(row['note'])\n",
    "\n",
    "    if text_prediction is not None:\n",
    "        # add the prediction values as a new column to the DataFrame\n",
    "        row['text_prediction'] = text_prediction.tolist()\n",
    "    else:\n",
    "        row['text_prediction'] = None\n",
    "\n",
    "    return row\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "data": {
      "text/plain": "     Unnamed: 0              audio_id  \\\n0             0    15.실내_906628_label   \n1             1    15.실내_903897_label   \n2             2    15.실내_918134_label   \n3             3    15.실내_654528_label   \n4             4    15.실내_661859_label   \n..          ...                   ...   \n402         402  3.절도범죄_1240207_label   \n403         403  3.절도범죄_1240211_label   \n404         404  3.절도범죄_1240983_label   \n405         405  3.절도범죄_1240989_label   \n406         406   4.폭력범죄_866862_label   \n\n                                             audio_dir       note category_02  \n0    /Users/yoohajun/Desktop/grad_audio/diffusion/t...        NaN          실내  \n1    /Users/yoohajun/Desktop/grad_audio/diffusion/t...        NaN          실내  \n2    /Users/yoohajun/Desktop/grad_audio/diffusion/t...        NaN          실내  \n3    /Users/yoohajun/Desktop/grad_audio/diffusion/t...        NaN          실내  \n4    /Users/yoohajun/Desktop/grad_audio/diffusion/t...        NaN          실내  \n..                                                 ...        ...         ...  \n402  /Users/yoohajun/Desktop/grad_audio/diffusion/t...  소매치기 잡아라         절도범죄  \n403  /Users/yoohajun/Desktop/grad_audio/diffusion/t...   소매치기 잡아라        절도범죄  \n404  /Users/yoohajun/Desktop/grad_audio/diffusion/t...    저 놈 잡아라        절도범죄  \n405  /Users/yoohajun/Desktop/grad_audio/diffusion/t...   저 놈 잡아라         절도범죄  \n406  /Users/yoohajun/Desktop/grad_audio/diffusion/t...    아 그만하세요        폭력범죄  \n\n[407 rows x 5 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Unnamed: 0</th>\n      <th>audio_id</th>\n      <th>audio_dir</th>\n      <th>note</th>\n      <th>category_02</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>15.실내_906628_label</td>\n      <td>/Users/yoohajun/Desktop/grad_audio/diffusion/t...</td>\n      <td>NaN</td>\n      <td>실내</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>15.실내_903897_label</td>\n      <td>/Users/yoohajun/Desktop/grad_audio/diffusion/t...</td>\n      <td>NaN</td>\n      <td>실내</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>15.실내_918134_label</td>\n      <td>/Users/yoohajun/Desktop/grad_audio/diffusion/t...</td>\n      <td>NaN</td>\n      <td>실내</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>15.실내_654528_label</td>\n      <td>/Users/yoohajun/Desktop/grad_audio/diffusion/t...</td>\n      <td>NaN</td>\n      <td>실내</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>15.실내_661859_label</td>\n      <td>/Users/yoohajun/Desktop/grad_audio/diffusion/t...</td>\n      <td>NaN</td>\n      <td>실내</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>402</th>\n      <td>402</td>\n      <td>3.절도범죄_1240207_label</td>\n      <td>/Users/yoohajun/Desktop/grad_audio/diffusion/t...</td>\n      <td>소매치기 잡아라</td>\n      <td>절도범죄</td>\n    </tr>\n    <tr>\n      <th>403</th>\n      <td>403</td>\n      <td>3.절도범죄_1240211_label</td>\n      <td>/Users/yoohajun/Desktop/grad_audio/diffusion/t...</td>\n      <td>소매치기 잡아라</td>\n      <td>절도범죄</td>\n    </tr>\n    <tr>\n      <th>404</th>\n      <td>404</td>\n      <td>3.절도범죄_1240983_label</td>\n      <td>/Users/yoohajun/Desktop/grad_audio/diffusion/t...</td>\n      <td>저 놈 잡아라</td>\n      <td>절도범죄</td>\n    </tr>\n    <tr>\n      <th>405</th>\n      <td>405</td>\n      <td>3.절도범죄_1240989_label</td>\n      <td>/Users/yoohajun/Desktop/grad_audio/diffusion/t...</td>\n      <td>저 놈 잡아라</td>\n      <td>절도범죄</td>\n    </tr>\n    <tr>\n      <th>406</th>\n      <td>406</td>\n      <td>4.폭력범죄_866862_label</td>\n      <td>/Users/yoohajun/Desktop/grad_audio/diffusion/t...</td>\n      <td>아 그만하세요</td>\n      <td>폭력범죄</td>\n    </tr>\n  </tbody>\n</table>\n<p>407 rows × 5 columns</p>\n</div>"
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [
    "# fill NaN values with empty string\n",
    "df = df.fillna('empty')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/407 [00:00<?, ?it/s][W NNPACK.cpp:79] Could not initialize NNPACK! Reason: Unsupported hardware.\n",
      "  1%|          | 5/407 [00:02<03:19,  2.02it/s]/var/folders/3p/vhd92h0x7cb73w5m2xzsn2jr0000gn/T/ipykernel_18169/1743214241.py:23: RuntimeWarning: invalid value encountered in divide\n",
      "  spec_resized = (spec_resized - mean) / std\n",
      "  5%|▍         | 19/407 [00:08<02:23,  2.70it/s]/var/folders/3p/vhd92h0x7cb73w5m2xzsn2jr0000gn/T/ipykernel_18169/1743214241.py:3: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  audio_data, sr = librosa.load(file_location, sr=44100, duration=5)\n",
      "/opt/anaconda3/envs/pytorch-grad/lib/python3.8/site-packages/librosa/core/audio.py:184: FutureWarning: librosa.core.audio.__audioread_load\n",
      "\tDeprecated as of librosa version 0.10.0.\n",
      "\tIt will be removed in librosa version 1.0.\n",
      "  y, sr_native = __audioread_load(path, offset, duration, dtype)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: [Errno 2] No such file or directory: '/Users/yoohajun/Desktop/grad_audio/diffusion/train/15.실내_688645_label.wav'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 407/407 [02:32<00:00,  2.67it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "tqdm.pandas()\n",
    "# apply the add_prediction function to each row of the DataFrame\n",
    "df = df.progress_apply(add_prediction, axis=1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "data": {
      "text/plain": "   Unnamed: 0            audio_id  \\\n0           0  15.실내_906628_label   \n1           1  15.실내_903897_label   \n2           2  15.실내_918134_label   \n3           3  15.실내_654528_label   \n4           4  15.실내_661859_label   \n\n                                           audio_dir   note category_02  \\\n0  /Users/yoohajun/Desktop/grad_audio/diffusion/t...  empty          실내   \n1  /Users/yoohajun/Desktop/grad_audio/diffusion/t...  empty          실내   \n2  /Users/yoohajun/Desktop/grad_audio/diffusion/t...  empty          실내   \n3  /Users/yoohajun/Desktop/grad_audio/diffusion/t...  empty          실내   \n4  /Users/yoohajun/Desktop/grad_audio/diffusion/t...  empty          실내   \n\n                                    audio_prediction  \\\n0  [-11.508453369140625, -8.252114295959473, -23....   \n1  [17.464433670043945, -21.854764938354492, -7.6...   \n2  [3.1379899978637695, 1.7926372289657593, -12.4...   \n3  [28.44495964050293, -16.67407989501953, -4.198...   \n4                     [nan, nan, nan, nan, nan, nan]   \n\n                                     text_prediction  \n0  [1.985169768333435, -1.2518784999847412, 1.072...  \n1  [1.985169768333435, -1.2518784999847412, 1.072...  \n2  [1.985169768333435, -1.2518784999847412, 1.072...  \n3  [1.985169768333435, -1.2518784999847412, 1.072...  \n4  [1.985169768333435, -1.2518784999847412, 1.072...  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Unnamed: 0</th>\n      <th>audio_id</th>\n      <th>audio_dir</th>\n      <th>note</th>\n      <th>category_02</th>\n      <th>audio_prediction</th>\n      <th>text_prediction</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>15.실내_906628_label</td>\n      <td>/Users/yoohajun/Desktop/grad_audio/diffusion/t...</td>\n      <td>empty</td>\n      <td>실내</td>\n      <td>[-11.508453369140625, -8.252114295959473, -23....</td>\n      <td>[1.985169768333435, -1.2518784999847412, 1.072...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>15.실내_903897_label</td>\n      <td>/Users/yoohajun/Desktop/grad_audio/diffusion/t...</td>\n      <td>empty</td>\n      <td>실내</td>\n      <td>[17.464433670043945, -21.854764938354492, -7.6...</td>\n      <td>[1.985169768333435, -1.2518784999847412, 1.072...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>15.실내_918134_label</td>\n      <td>/Users/yoohajun/Desktop/grad_audio/diffusion/t...</td>\n      <td>empty</td>\n      <td>실내</td>\n      <td>[3.1379899978637695, 1.7926372289657593, -12.4...</td>\n      <td>[1.985169768333435, -1.2518784999847412, 1.072...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>15.실내_654528_label</td>\n      <td>/Users/yoohajun/Desktop/grad_audio/diffusion/t...</td>\n      <td>empty</td>\n      <td>실내</td>\n      <td>[28.44495964050293, -16.67407989501953, -4.198...</td>\n      <td>[1.985169768333435, -1.2518784999847412, 1.072...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>15.실내_661859_label</td>\n      <td>/Users/yoohajun/Desktop/grad_audio/diffusion/t...</td>\n      <td>empty</td>\n      <td>실내</td>\n      <td>[nan, nan, nan, nan, nan, nan]</td>\n      <td>[1.985169768333435, -1.2518784999847412, 1.072...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print the resulting DataFrame with the new 'prediction' column\n",
    "df.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [],
   "source": [
    "df.to_csv('./audio_text_label.csv')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "pytorch-grad",
   "language": "python",
   "display_name": "Python3.8(tc1.10)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}